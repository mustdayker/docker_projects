{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "797f1f2e-7776-487b-9831-7f83df98b9d1",
   "metadata": {},
   "source": [
    "### –°–µ—Å—Å–∏—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π MinIO –∏ —Å –∫–æ–Ω—Ñ–∏–≥–æ–º –∏–∑ `spark-defaults`\n",
    "\n",
    "–í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–æ–ø–∏—Å–∞–Ω—ã –≤ `\"\\etl_project_v1\\spark\\conf\\spark-defaults.conf\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cadd09e-ce00-42fe-a66e-c978fce28e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/29 18:30:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"MinIO Test\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars\", \n",
    "                 \"/home/jovyan/work/spark-jars/hadoop-aws-3.3.4.jar,\"\n",
    "                 \"/home/jovyan/work/spark-jars/aws-java-sdk-bundle-1.12.262.jar,\"\n",
    "                 \"/home/jovyan/work/spark-jars/wildfly-openssl-1.0.7.Final.jar\")\n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad5c0a5-6c00-4ea9-87ea-be77d1ab9be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ MinIO\n",
    "df = spark.range(10)\n",
    "df.write.mode(\"overwrite\").csv(\"s3a://learn-bucket/test_22\")\n",
    "print(\"‚úÖ –£—Å–ø–µ—à–Ω–æ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ebe17-da13-45a4-80ef-9f52aa7ba11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d796812-ef8f-45e4-aa1f-7cb7ae00e77e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b48f26e-3453-4755-a9f1-6d179b2fff54",
   "metadata": {},
   "source": [
    "# Spark —Å–µ—Å—Å–∏—è —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6abf2c84-cc02-44c4-8be7-d3c41904a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"Full Power\")\n",
    "         .master(\"spark://spark-master:7077\")\n",
    "         .config(\"spark.executor.instances\", \"2\")\n",
    "         .config(\"spark.executor.cores\", \"10\")\n",
    "         .config(\"spark.executor.memory\", \"16g\")\n",
    "         .config(\"spark.driver.memory\", \"4g\")\n",
    "         .config(\"spark.cores.max \", \"20\")\n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b95348-0d94-459e-911d-d97815d1e949",
   "metadata": {},
   "source": [
    "### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥ –∏–∑ `\"\\etl_project_v1\\spark\\conf\\spark-defaults.conf\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b59ac7-c074-4fb8-bef9-4fddf4dea952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id|count|\n",
      "+---+-----+\n",
      "|  0|    1|\n",
      "|  1|    1|\n",
      "|  2|    1|\n",
      "|  3|    1|\n",
      "|  4|    1|\n",
      "+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# –¢–µ—Å—Ç–æ–≤–∞—è –∑–∞–¥–∞—á–∞\n",
    "df = spark.range(10000000) \\\n",
    "    .selectExpr(\"id\", \"id * 2 as value\") \\\n",
    "    .groupBy(\"id\") \\\n",
    "    .count()\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4e92dad-a234-4a4a-b2b7-b0e38057a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7f2160-bba6-44a6-9f2e-b8a94d81a4c5",
   "metadata": {},
   "source": [
    "```python\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ SparkSession —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "spark = (SparkSession.builder\n",
    "         # –ò–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ Spark UI –∏ –ª–æ–≥–∞—Ö\n",
    "         .appName(\"Full Power\")\n",
    "         \n",
    "         # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Spark –∫–ª–∞—Å—Ç–µ—Ä—É\n",
    "         # spark-master:7077 - –≥–ª–∞–≤–Ω—ã–π —É–∑–µ–ª –∫–ª–∞—Å—Ç–µ—Ä–∞, –∫–æ—Ç–æ—Ä—ã–π —É–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è–º–∏\n",
    "         .master(\"spark://spark-master:7077\")\n",
    "         \n",
    "         # –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ò–°–ü–û–õ–ù–ò–¢–ï–õ–ï–ô (EXECUTORS)\n",
    "         # Executor - –ø—Ä–æ—Ü–µ—Å—Å, –≤—ã–ø–æ–ª–Ω—è—é—â–∏–π –∑–∞–¥–∞—á–∏ –Ω–∞ —Ä–∞–±–æ—á–∏—Ö —É–∑–ª–∞—Ö –∫–ª–∞—Å—Ç–µ—Ä–∞\n",
    "         \n",
    "         # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π –Ω–∞ —Ä–∞–±–æ—á–µ–º —É–∑–ª–µ\n",
    "         # 2 –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è –±—É–¥—É—Ç –∑–∞–ø—É—â–µ–Ω—ã –Ω–∞ –∫–∞–∂–¥–æ–º worker node\n",
    "         # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ª—É—á—à–µ –∏–∑–æ–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–∞—á–∏ –∏ —É–ø—Ä–∞–≤–ª—è—Ç—å –ø–∞–º—è—Ç—å—é\n",
    "         .config(\"spark.executor.instances\", \"2\")  \n",
    "         \n",
    "         # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ CPU —è–¥–µ—Ä –Ω–∞ –∫–∞–∂–¥—ã–π –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å\n",
    "         # 10 —è–¥–µ—Ä –ø–æ–∑–≤–æ–ª—è—é—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å –¥–æ 10 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á –≤ –∫–∞–∂–¥–æ–º executor\n",
    "         # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è —É–∑–ª–æ–≤ —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–Ω—ã—Ö —è–¥–µ—Ä\n",
    "         .config(\"spark.executor.cores\", \"10\")     \n",
    "         \n",
    "         # –û–±—ä–µ–º –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏ –Ω–∞ –∫–∞–∂–¥—ã–π –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å\n",
    "         # 16GB RAM –¥–ª—è –∫–∞–∂–¥–æ–≥–æ executor –ø—Ä–æ—Ü–µ—Å—Å–∞\n",
    "         # –í–∫–ª—é—á–∞–µ—Ç –ø–∞–º—è—Ç—å –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á –∏ —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ –ø–∞–º—è—Ç–∏\n",
    "         # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–º—è—Ç–∏ executor:\n",
    "         # - Execution Memory (—à–∞—Ñ—Ñ–ª–∏–Ω–≥, joins, –∞–≥—Ä–µ–≥–∞—Ü–∏–∏)\n",
    "         # - Storage Memory (–∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ DataFrame/RDD)\n",
    "         # - User Memory (–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö)\n",
    "         # - Reserved Memory (—Å–∏—Å—Ç–µ–º–Ω—ã–µ –Ω—É–∂–¥—ã Spark ~300MB)\n",
    "         .config(\"spark.executor.memory\", \"16g\")   \n",
    "         \n",
    "         # –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –î–†–ê–ô–í–ï–†–ê\n",
    "         # Driver - –≥–ª–∞–≤–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å, –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É—é—â–∏–π –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è\n",
    "         \n",
    "         # –ü–∞–º—è—Ç—å –¥—Ä–∞–π–≤–µ—Ä–∞ - 4GB –¥–ª—è:\n",
    "         # - –•—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è\n",
    "         # - –°–±–æ—Ä–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (collect())\n",
    "         # - Broadcast –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n",
    "         # - –£–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–¥–∞—á–∞–º–∏ –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "         .config(\"spark.driver.memory\", \"4g\")      \n",
    "         \n",
    "         # –°–æ–∑–¥–∞–Ω–∏–µ –∏–ª–∏ –ø–æ–ª—É—á–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å–µ—Å—Å–∏–∏\n",
    "         .getOrCreate()\n",
    "        )\n",
    "```\n",
    "\n",
    "## –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:\n",
    "\n",
    "### **–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤:**\n",
    "```\n",
    "Worker Node (—Ñ–∏–∑–∏—á–µ—Å–∫–∞—è/–≤–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è –º–∞—à–∏–Ω–∞)\n",
    "‚îú‚îÄ‚îÄ Executor 1 (16GB RAM, 10 cores)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Task Slot 1\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Task Slot 2\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ... Task Slot 10\n",
    "‚îî‚îÄ‚îÄ Executor 2 (16GB RAM, 10 cores)\n",
    "    ‚îú‚îÄ‚îÄ Task Slot 1\n",
    "    ‚îú‚îÄ‚îÄ Task Slot 2\n",
    "    ‚îî‚îÄ‚îÄ ... Task Slot 10\n",
    "```\n",
    "\n",
    "### **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ:**\n",
    "\n",
    "1. **–ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º –∑–∞–¥–∞—á:**\n",
    "   - –í—Å–µ–≥–æ —Å–ª–æ—Ç–æ–≤ –¥–ª—è –∑–∞–¥–∞—á: `2 executors √ó 10 cores = 20 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á`\n",
    "   - –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –¥–æ 20 –ø–∞—Ä—Ç–∏—Ü–∏–π –¥–∞–Ω–Ω—ã—Ö –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ\n",
    "\n",
    "2. **–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏:**\n",
    "   ```python\n",
    "   # –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–º—è—Ç–∏ executor (16GB):\n",
    "   - Spark Memory: ~60% (9.6GB)\n",
    "     * Storage Memory: –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "     * Execution Memory: –æ–ø–µ—Ä–∞—Ü–∏–∏ —à–∞—Ñ—Ñ–ª–∏–Ω–≥–∞\n",
    "   - User Memory: ~25% (4GB) - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã\n",
    "   - Reserved: ~5% (0.8GB) - —Å–∏—Å—Ç–µ–º–Ω—ã–µ –Ω—É–∂–¥—ã\n",
    "   ```\n",
    "\n",
    "3. **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞:**\n",
    "   ```python\n",
    "   # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è \"Full Power\":\n",
    "   .config(\"spark.sql.adaptive.enabled\", \"true\")          # –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤\n",
    "   .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–∞—Ä—Ç–∏—Ü–∏–π\n",
    "   .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") # –ë—ã—Å—Ç—Ä–∞—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "   .config(\"spark.sql.shuffle.partitions\", \"200\")         # –ü–∞—Ä—Ç–∏—Ü–∏–∏ –¥–ª—è —à–∞—Ñ—Ñ–ª–∏–Ω–≥–∞\n",
    "   .config(\"spark.default.parallelism\", \"40\")             # –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
    "   ```\n",
    "\n",
    "### **–¢–∏–ø–∏—á–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**\n",
    "- **–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö** (—Å–æ—Ç–Ω–∏ GB - TB)\n",
    "- **–°–ª–æ–∂–Ω—ã–µ ETL-–ø–∞–π–ø–ª–∞–π–Ω—ã** —Å –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π\n",
    "- **–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö**\n",
    "- **–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏** —Å –≤—ã—Å–æ–∫–∏–º–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ –∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "\n",
    "–¢–∞–∫–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –º–æ—â–Ω—ã—Ö –ø—Ä–æ–¥–∞–∫—à–µ–Ω-–∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–º–∏ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55082922-4377-45ba-9ea9-3d2cbfe49355",
   "metadata": {},
   "source": [
    "–û—Ç–ª–∏—á–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è! –° –≤–∞—à–∏–º –∂–µ–ª–µ–∑–æ–º –∏ —Ç–µ–∫—É—â–∏–º setup –≤—ã –º–æ–∂–µ—Ç–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –æ–±—ä–µ–º—ã –¥–∞–Ω–Ω—ã—Ö. –î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ:\n",
    "\n",
    "## **–¢–µ–∫—É—â–∏–µ —Ä–µ—Å—É—Ä—Å—ã –∫–ª–∞—Å—Ç–µ—Ä–∞:**\n",
    "\n",
    "### –í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–∞—è –º–æ—â–Ω–æ—Å—Ç—å:\n",
    "```\n",
    "–í—Å–µ–≥–æ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ:\n",
    "- 2 worker √ó 10 cores = 20 CPU —è–¥–µ—Ä\n",
    "- 2 worker √ó 18GB RAM = 36GB –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏\n",
    "```\n",
    "\n",
    "### –ü–∞–º—è—Ç—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö:\n",
    "```python\n",
    "# –î–æ—Å—Ç—É–ø–Ω–∞—è –ø–∞–º—è—Ç—å –¥–ª—è –¥–∞–Ω–Ω—ã—Ö (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ):\n",
    "–û–±—â–∞—è RAM: 36GB\n",
    "- –°–∏—Å—Ç–µ–º–Ω—ã–µ –Ω—É–∂–¥—ã Spark: ~2GB\n",
    "- –†–µ–∑–µ—Ä–≤: ~4GB\n",
    "= –î–æ—Å—Ç—É–ø–Ω–æ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö: ~30GB\n",
    "```\n",
    "\n",
    "## **–û–±—ä–µ–º—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:**\n",
    "\n",
    "### **1. –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–º—ã (–∫–æ–º—Ñ–æ—Ä—Ç–Ω–∞—è —Ä–∞–±–æ—Ç–∞):**\n",
    "- **–í –ø–∞–º—è—Ç–∏:** 15-25 GB –¥–∞–Ω–Ω—ã—Ö\n",
    "- **–ù–∞ –¥–∏—Å–∫–µ (—Å —à–∞—Ñ—Ñ–ª–∏–Ω–≥–æ–º):** 50-100 GB –¥–∞–Ω–Ω—ã—Ö\n",
    "- **–ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞:** 200-500 GB (—Å —Ä–∞–∑–±–∏–≤–∫–æ–π –Ω–∞ –±–∞—Ç—á–∏)\n",
    "\n",
    "### **2. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–º—ã (—Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π):**\n",
    "- **–ï–¥–∏–Ω–æ—Ä–∞–∑–æ–≤–æ –≤ –ø–∞–º—è—Ç–∏:** –¥–æ 30 GB\n",
    "- **–° –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–π –∑–∞–ø–∏—Å—å—é –Ω–∞ –¥–∏—Å–∫:** 200-300 GB\n",
    "- **–ï–∂–µ–¥–Ω–µ–≤–Ω–æ:** 1-2 TB (—Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º)\n",
    "\n",
    "## **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:**\n",
    "\n",
    "### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Spark –¥–ª—è –≤–∞—à–µ–≥–æ –∂–µ–ª–µ–∑–∞:\n",
    "```python\n",
    "spark = (SparkSession.builder\n",
    "    .appName(\"Optimized for i5-14600K\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .config(\"spark.executor.instances\", \"2\")  \n",
    "    .config(\"spark.executor.cores\", \"8\")      # –û—Å—Ç–∞–≤–ª—è–µ–º 2 —è–¥—Ä–∞ –Ω–∞ —Å–∏—Å—Ç–µ–º—É\n",
    "    .config(\"spark.executor.memory\", \"14g\")   # –û—Å—Ç–∞–≤–ª—è–µ–º 4GB –Ω–∞ —Å–∏—Å—Ç–µ–º—É\n",
    "    .config(\"spark.driver.memory\", \"8g\")      # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –±–æ–ª—å—à–∏—Ö collect()\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "    .config(\"spark.sql.adaptive.advisoryPartitionSizeInBytes\", \"128MB\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"100\")  # 8 cores √ó 2 workers √ó 6 = 96\n",
    "    .config(\"spark.default.parallelism\", \"96\")\n",
    "    .config(\"spark.memory.fraction\", \"0.8\")\n",
    "    .config(\"spark.memory.storageFraction\", \"0.3\")\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "```\n",
    "\n",
    "## **–¢–∏–ø–∏—á–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏:**\n",
    "\n",
    "### **1. –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã:**\n",
    "```python\n",
    "# –ú–≥–Ω–æ–≤–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: 5-10 GB\n",
    "# –ó–∞–ø—Ä–æ—Å—ã –¥–æ 1 –º–∏–Ω—É—Ç—ã: 10-20 GB  \n",
    "# –î–ª–∏—Ç–µ–ª—å–Ω—ã–µ ETL: 50-100 GB –∑–∞ –∑–∞–ø—É—Å–∫\n",
    "```\n",
    "\n",
    "### **2. –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ:**\n",
    "```python\n",
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π:\n",
    "# - –î–æ 10M —Å—Ç—Ä–æ–∫ √ó 100 —Ñ–∏—á: –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ\n",
    "# - –î–æ 50M —Å—Ç—Ä–æ–∫ √ó 50 —Ñ–∏—á: —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π\n",
    "# - Feature engineering: 20-30 GB –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö\n",
    "```\n",
    "\n",
    "### **3. –°—Ç—Ä–∏–º–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö:**\n",
    "```python\n",
    "# –ü–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞:\n",
    "# - –î–æ 50,000 —Å–æ–±—ã—Ç–∏–π/—Å–µ–∫—É–Ω–¥—É\n",
    "# - –ú–∏–∫—Ä–æ–±–∞—Ç—á–∏ –ø–æ 10-30 —Å–µ–∫—É–Ω–¥\n",
    "# - –û–∫–Ω–∞ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏: 1-60 –º–∏–Ω—É—Ç\n",
    "```\n",
    "\n",
    "## **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:**\n",
    "\n",
    "### –ü—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ—Ö–≤–∞—Ç–∫–∏ —Ä–µ—Å—É—Ä—Å–æ–≤:\n",
    "```python\n",
    "# –¢—Ä–µ–≤–æ–∂–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã:\n",
    "- Frequent GC pauses (> 10% –≤—Ä–µ–º–µ–Ω–∏)\n",
    "- Spill –Ω–∞ –¥–∏—Å–∫ (Disk spill bytes > 0)\n",
    "- OOM errors\n",
    "- Tasks taking > 5-10 minutes\n",
    "```\n",
    "\n",
    "### –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã –æ–±—ä–µ–º–æ–≤:\n",
    "```\n",
    "‚úÖ –õ–µ–≥–∫–æ:     –ê–Ω–∞–ª–∏–∑ 10GB CSV (~100M —Å—Ç—Ä–æ–∫)\n",
    "‚úÖ –ö–æ–º—Ñ–æ—Ä—Ç–Ω–æ: ETL 50GB –¥–∞–Ω–Ω—ã—Ö –µ–∂–µ–¥–Ω–µ–≤–Ω–æ  \n",
    "‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω–æ:  –û–±—Ä–∞–±–æ—Ç–∫–∞ 150GB —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π\n",
    "‚ùå –°–ª–æ–∂–Ω–æ:    –ï–¥–∏–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ >200GB\n",
    "```\n",
    "\n",
    "## **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –≤–∞—à–µ–≥–æ setup:**\n",
    "\n",
    "1. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ** –¥–ª—è –±–æ–ª—å—à–∏—Ö datasets\n",
    "2. **–ö—ç—à–∏—Ä—É–π—Ç–µ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ DataFrames**\n",
    "3. **–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö** (–º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏)\n",
    "4. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–æ—Ä–º–∞—Ç Parquet/ORC** –≤–º–µ—Å—Ç–æ CSV/JSON\n",
    "5. **–ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ Spark UI** –Ω–∞ –ø–æ—Ä—Ç–∞—Ö 8085-8087\n",
    "\n",
    "–í–∞—à–∞ —Å–∏—Å—Ç–µ–º–∞ –æ—Ç–ª–∏—á–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Å–µ—Ä—å–µ–∑–Ω—ã—Ö data engineering –∑–∞–¥–∞—á –∏ –º–æ–∂–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –≥–∏–≥–∞–±–∞–π—Ç—ã –¥–∞–Ω–Ω—ã—Ö –µ–∂–µ–¥–Ω–µ–≤–Ω–æ!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0727377-116f-4aad-912e-bb97193bcfb4",
   "metadata": {},
   "source": [
    "# –ö–æ–Ω–Ω–µ–∫—Ç–æ—Ä –∫ `MinIO`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d3da70-4079-403f-92f1-e24ea018886c",
   "metadata": {},
   "source": [
    "### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥ –∏–∑ `\"\\etl_project_v1\\spark\\conf\\spark-defaults.conf\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f13db5-47f5-441d-b635-71ae5f9781e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"MinIO Test\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars\", \n",
    "                 \"/home/jovyan/work/spark-jars/hadoop-aws-3.3.4.jar,\"\n",
    "                 \"/home/jovyan/work/spark-jars/aws-java-sdk-bundle-1.12.262.jar,\"\n",
    "                 \"/home/jovyan/work/spark-jars/wildfly-openssl-1.0.7.Final.jar\")\n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50bb7f0-f3ce-4037-b894-188ae905cfdc",
   "metadata": {},
   "source": [
    "### –°–∫–∞—á–∞—Ç—å –¥—Ä–∞–≤–µ—Ä–∞ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2585304-472f-48a7-9831-e3084336194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName(\"MinIO Test\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars.packages\", \n",
    "                 \"org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262\")     \n",
    "         .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\")\n",
    "         .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
    "         .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "         .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \n",
    "         .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \n",
    "         .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295f0738-f099-4383-a4a6-ad0e26707fef",
   "metadata": {},
   "source": [
    "### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∫–∞—á–∞–Ω–Ω–æ–µ –∏–∑ `\"/home/jovyan/work/spark-jars\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a360ee9-e85d-485e-a008-078161fa0e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"MinIO Test\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars\", \n",
    "                 \"/home/jovyan/work/spark-jars/hadoop-aws-3.3.4.jar,\"\n",
    "                 \"/home/jovyan/work/spark-jars/aws-java-sdk-bundle-1.12.262.jar,\"\n",
    "                 \"/home/jovyan/work/spark-jars/wildfly-openssl-1.0.7.Final.jar\")\n",
    "         .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\")\n",
    "         .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
    "         .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "         .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \n",
    "         .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \n",
    "         .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e9a8b7-2651-497e-98bf-c33ec912bba3",
   "metadata": {},
   "source": [
    "### –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–∞–ø–∏—Å—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6870b62-e099-4f26-805f-95b44631f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(10)\n",
    "df.write.mode(\"overwrite\").csv(\"s3a://learn-bucket/test_22\")\n",
    "print(\"‚úÖ –£—Å–ø–µ—à–Ω–æ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c6ed8-c68b-45a3-9070-95298a5acb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c79079f-a42e-4f56-8efa-c55946d3e797",
   "metadata": {},
   "source": [
    "```python\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ SparkSession - –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Spark\n",
    "spark = (SparkSession.builder\n",
    "         # –£–∫–∞–∑—ã–≤–∞–µ–º –∏–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è - –±—É–¥–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å—Å—è –≤ Spark UI\n",
    "         .appName(\"MinIO Test\")\n",
    "         \n",
    "         # –ó–∞–¥–∞–µ–º URL –º–∞—Å—Ç–µ—Ä-–Ω–æ–¥—ã Spark –∫–ª–∞—Å—Ç–µ—Ä–∞\n",
    "         # spark://spark-master:7077 - –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ Spark —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –∫–ª–∞—Å—Ç–µ—Ä–Ω–æ–º —Ä–µ–∂–∏–º–µ\n",
    "         # spark-master - –∏–º—è —Ö–æ—Å—Ç–∞ –º–∞—Å—Ç–µ—Ä-–Ω–æ–¥—ã (–æ–±—ã—á–Ω–æ –∑–∞–¥–∞–µ—Ç—Å—è –≤ Docker Compose –∏–ª–∏ Kubernetes)\n",
    "         # 7077 - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ—Ä—Ç –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –¥—Ä–∞–π–≤–µ—Ä–æ–≤ –∫ –∫–ª–∞—Å—Ç–µ—Ä—É\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         \n",
    "         # –£–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ JAR-–ø–∞–∫–µ—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å S3-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º–∏ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞–º–∏\n",
    "         # hadoop-aws:3.3.4 - –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ Hadoop –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å AWS S3\n",
    "         # aws-java-sdk-bundle:1.12.262 - AWS Java SDK –¥–ª—è –∫–ª–∏–µ–Ω—Ç—Å–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π\n",
    "         # Spark –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∫–∞—á–∞–µ—Ç —ç—Ç–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ\n",
    "         .config(\"spark.jars.packages\", \n",
    "                 \"org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262\")     \n",
    "         \n",
    "         # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ MinIO - –ª–æ–≥–∏–Ω (access key)\n",
    "         # MinIO –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç minioadmin/minioadmin\n",
    "         .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\")\n",
    "         \n",
    "         # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ MinIO - –ø–∞—Ä–æ–ª—å (secret key)\n",
    "         .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
    "         \n",
    "         # –£–∫–∞–∑—ã–≤–∞–µ–º endpoint MinIO —Å–µ—Ä–≤–µ—Ä–∞\n",
    "         # http://minio:9000 - MinIO —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ HTTP –Ω–∞ –ø–æ—Ä—Ç—É 9000\n",
    "         # 'minio' - –∏–º—è —Å–µ—Ä–≤–∏—Å–∞ –≤ Docker-—Å–µ—Ç–∏\n",
    "         .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "         \n",
    "         # –í–∫–ª—é—á–∞–µ–º path-style –¥–æ—Å—Ç—É–ø –∫ –±–∞–∫–µ—Ç–∞–º (—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è MinIO)\n",
    "         # –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç virtual-hosted style, –≥–¥–µ –±–∞–∫–µ—Ç –≤ –¥–æ–º–µ–Ω–µ: bucket.host.com\n",
    "         # Path-style: host.com/bucket/path/to/file\n",
    "         .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \n",
    "         \n",
    "         # –£–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –¥–ª—è S3\n",
    "         # S3AFileSystem - Hadoop —Ñ–∞–π–ª–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å S3-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º–∏ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞–º–∏\n",
    "         .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \n",
    "         \n",
    "         # –û—Ç–∫–ª—é—á–∞–µ–º SSL/TLS —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è\n",
    "         # –¢–∞–∫ –∫–∞–∫ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º HTTP (–Ω–µ HTTPS) –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ MinIO\n",
    "         .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \n",
    "         \n",
    "         # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –ø–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π SparkSession\n",
    "         # getOrCreate() –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Å–µ—Å—Å–∏–π\n",
    "         .getOrCreate()\n",
    "        )\n",
    "```\n",
    "\n",
    "## –ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:\n",
    "\n",
    "### 1. **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è**\n",
    "- Spark –¥—Ä–∞–π–≤–µ—Ä –ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ –∫–ª–∞—Å—Ç–µ—Ä—É —á–µ—Ä–µ–∑ –º–∞—Å—Ç–µ—Ä-–Ω–æ–¥—É\n",
    "- Executor'—ã –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ –ø–æ–ª—É—á–∞—Ç —Ç–µ –∂–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ S3/MinIO\n",
    "\n",
    "### 2. **–†–∞–±–æ—Ç–∞ —Å MinIO**\n",
    "- MinIO —ç–º—É–ª–∏—Ä—É–µ—Ç S3 API, –ø–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ–º S3A connector\n",
    "- Path-style access –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è MinIO\n",
    "- –û—Ç–∫–ª—é—á–µ–Ω SSL —Ç.–∫. –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è HTTP\n",
    "\n",
    "### 3. **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏**\n",
    "- `hadoop-aws` –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç S3A —Ñ–∞–π–ª–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É  \n",
    "- `aws-java-sdk` –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –Ω–∏–∑–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–µ S3 –æ–ø–µ—Ä–∞—Ü–∏–∏\n",
    "\n",
    "### 4. **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ**\n",
    "```python\n",
    "# –í —Ä–µ–∞–ª—å–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:\n",
    ".config(\"spark.hadoop.fs.s3a.access.key\", os.environ.get(\"AWS_ACCESS_KEY\"))\n",
    ".config(\"spark.hadoop.fs.s3a.secret.key\", os.environ.get(\"AWS_SECRET_KEY\"))\n",
    "```\n",
    "\n",
    "–ü–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è —Å–µ—Å—Å–∏–∏ –º–æ–∂–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å —Å MinIO –∫–∞–∫ —Å –æ–±—ã—á–Ω–æ–π S3 —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π:\n",
    "```python\n",
    "df = spark.read.parquet(\"s3a://my-bucket/data/\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c9ee36-b123-4d67-be37-f03f6c65f3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2182356-9c43-404b-9b0c-5d9baa2c1d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80024079-7bb5-49e0-bf6e-971a6ca3971b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50dbd37-1dea-4502-b0e1-565c9a57abcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f50c2f6-ecc4-4818-9f2c-c0336d510200",
   "metadata": {},
   "source": [
    "# –ú–æ–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å –¥—Ä–∞–π–≤–µ—Ä–∞ –æ–¥–∏–Ω —Ä–∞–∑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5afdb96-beff-46c9-b17e-7a87990fa559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def download_spark_jars():\n",
    "    \"\"\"–°–∫–∞—á–∏–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ JAR —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫—É spark-jars\"\"\"\n",
    "    \n",
    "    jars_dir = \"/home/jovyan/work/spark-jars\"\n",
    "    os.makedirs(jars_dir, exist_ok=True)\n",
    "    \n",
    "    jars = {\n",
    "        \"hadoop-aws-3.3.4.jar\": \"https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar\",\n",
    "        \"aws-java-sdk-bundle-1.12.262.jar\": \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar\",\n",
    "        \"wildfly-openssl-1.0.7.Final.jar\": \"https://repo1.maven.org/maven2/org/wildfly/openssl/wildfly-openssl/1.0.7.Final/wildfly-openssl-1.0.7.Final.jar\"\n",
    "    }\n",
    "    \n",
    "    for filename, url in jars.items():\n",
    "        filepath = os.path.join(jars_dir, filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"üì• –°–∫–∞—á–∏–≤–∞–µ–º {filename}...\")\n",
    "            response = requests.get(url)\n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"‚úÖ {filename} –∑–∞–≥—Ä—É–∂–µ–Ω\")\n",
    "        else:\n",
    "            print(f\"‚úÖ {filename} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\")\n",
    "\n",
    "# –ó–∞–ø—É—Å—Ç–∏—Ç–µ —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é –æ–¥–∏–Ω —Ä–∞–∑\n",
    "download_spark_jars()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eea1ca-60c4-4821-8228-f78625c5b9fd",
   "metadata": {},
   "source": [
    "### –í—ã–≤–µ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d899d725-48ac-4c28-b1d9-b8e823035d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = spark.sparkContext.getConf()\n",
    "print(\"Executor instances:\", conf.get(\"spark.executor.instances\"))  # ‚Üí 2\n",
    "print(\"Executor cores:\", conf.get(\"spark.executor.cores\"))          # ‚Üí 10\n",
    "print(\"Executor memory:\", conf.get(\"spark.executor.memory\"))        # ‚Üí 16g\n",
    "print(\"Driver memory:\", conf.get(\"spark.driver.memory\"))            # ‚Üí 4g\n",
    "print(\"Cores max:\", conf.get(\"spark.cores.max\"))                    # ‚Üí 20\n",
    "print(\"S3A endpoint:\", conf.get(\"spark.hadoop.fs.s3a.endpoint\"))    # ‚Üí http://minio:9000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
