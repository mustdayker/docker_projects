{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e17de36-c8e0-485e-bd0c-bb2cb68de93e",
   "metadata": {},
   "source": [
    "# Чтение Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f65ea4a-e659-47a6-b346-dbe748543ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/29 22:12:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"Read Session\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars\", \n",
    "                 \"/home/jovyan/work/spark-jars/hadoop-aws-3.3.4.jar,\"\n",
    "                 \"/home/jovyan/work/spark-jars/aws-java-sdk-bundle-1.12.262.jar,\"\n",
    "                 \"/home/jovyan/work/spark-jars/wildfly-openssl-1.0.7.Final.jar\")\n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb44935-f911-4ae2-ad5d-796fd9e4581f",
   "metadata": {},
   "source": [
    "## Чтение с локального диска `CSV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f20761-78be-41dc-b51a-bbdb60591acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/shared_data/bmw.csv\", \n",
    "                    header=True, \n",
    "                    inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e931d873-2afb-477e-a824-612f2c8f7a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение всех файлов из папки\n",
    "# ВАЖНО! Можно читать только одинаковые по структуре файлы\n",
    "\n",
    "df = spark.read.csv(\"/shared_data/*.csv\", \n",
    "                    header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20969f4e-8e40-4d49-aefc-8fcd2c46ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение с параметрами\n",
    "df = (spark.read\n",
    "      .option(\"header\", \"true\")\n",
    "      .option(\"delimiter\", \",\")\n",
    "      .option(\"inferSchema\", \"true\")\n",
    "      .option(\"encoding\", \"utf-8\")\n",
    "      .option(\"nullValue\", \"NULL\")\n",
    "      .csv(\"/shared_data/bmw.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f77d0e4-8da7-42a7-8187-1bfba895644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Использование формата\n",
    "df = (spark.read\n",
    "      .format(\"csv\")\n",
    "      .option(\"header\", \"true\")\n",
    "      .option(\"inferSchema\", \"true\")\n",
    "      .load(\"/shared_data/bmw.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca09457-f35f-454a-a994-f43f3a322162",
   "metadata": {},
   "source": [
    "## Чтение с указанием схемы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fdd168-4325-4f88-b637-7a35076a6ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение CSV с указанием схемы\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "# Определяем схему для CSV файла\n",
    "schema = StructType([\n",
    "    StructField(\"Model\",                StringType(),  True),\n",
    "    StructField(\"Year\",                 IntegerType(), True),\n",
    "    StructField(\"Region\",               StringType(),  True),\n",
    "    StructField(\"Color\",                StringType(),  True),\n",
    "    StructField(\"Fuel_Type\",            StringType(),  True),\n",
    "    StructField(\"Transmission\",         StringType(),  True),\n",
    "    StructField(\"Engine_Size_L\",        DoubleType(),  True),\n",
    "    StructField(\"Mileage_KM\",           IntegerType(), True),\n",
    "    StructField(\"Price_USD\",            IntegerType(), True),\n",
    "    StructField(\"Sales_Volume\",         IntegerType(), True),\n",
    "    StructField(\"Sales_Classification\", StringType(),  True)\n",
    "])\n",
    "            \n",
    "df = spark.read.csv(\"/shared_data/bmw.csv\",\n",
    "                    schema=schema,\n",
    "                    header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df40af-e9e8-4899-9d51-20afc738ce81",
   "metadata": {},
   "source": [
    "## Запись в MinIO `CSV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48d51e9-d39d-4597-9235-e61ab5f689b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "import json\n",
    "\n",
    "(df.write\n",
    "   .mode(\"overwrite\")\n",
    "   .option(\"header\", \"false\")\n",
    "   .csv(\"s3a://learn-bucket/draft/bmw_csv\"))\n",
    "\n",
    "# Спарк по умолчанию не пишет заголовки в CSV файлы\n",
    "# По этому можно сохранить схему прямо в MinIO\n",
    "\n",
    "schema_json = df.schema.json()\n",
    "schema_df = spark.createDataFrame([(schema_json,)], [\"schema\"])\n",
    "\n",
    "schema_df.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"compression\", \"none\") \\\n",
    "    .text(\"s3a://learn-bucket/draft/bmw_schema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f37bd7-bff9-445a-8845-9104bdd3c4a8",
   "metadata": {},
   "source": [
    "## Чтение из MinIO `CSV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08d117a-5fa0-4d65-82e6-69b8ab946bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Читаем схему напрямую из MinIO\n",
    "schema_rdd = spark.sparkContext.textFile(\"s3a://learn-bucket/draft/bmw_schema\")\n",
    "schema_json = schema_rdd.collect()[0]  # берем первую строку\n",
    "\n",
    "# Восстанавливаем схему\n",
    "restored_schema = StructType.fromJson(json.loads(schema_json))\n",
    "\n",
    "# Теперь читаем данные с этой схемой\n",
    "df = (spark.read\n",
    "           .schema(restored_schema)\n",
    "           .option(\"header\", \"false\")\n",
    "           .csv(\"s3a://learn-bucket/draft/bmw_csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bdec4-441f-457d-b0aa-b0b54f18d3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f369274c-cb22-45bf-bfa5-d41cd87b4512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47bf5d64-165f-4683-b147-969cde62e98d",
   "metadata": {},
   "source": [
    "# Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9193ca-91f9-4c0e-a902-a63b6004f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read.parquet(\"/shared_data/yellow_taxi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f56f745-ef78-40bd-8111-6772211fcfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"/shared_data/yellow_taxi/data_*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6843620b-a473-4c93-a43a-f77e3e22f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"/shared_data/yellow_taxi/single_file.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ea82bc-d306-42ef-9f65-9c5f21c58581",
   "metadata": {},
   "source": [
    "## Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16900153-e836-49da-9cac-7876ca647291",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Количество строк: {df.count()}\\n\")\n",
    "df.show(1)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d7395-84b7-4d9d-8601-d8be3e736ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a30340a-17ee-49ac-813d-b7f167ec05da",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb18af-2665-4166-a2e8-65ec17b23caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
