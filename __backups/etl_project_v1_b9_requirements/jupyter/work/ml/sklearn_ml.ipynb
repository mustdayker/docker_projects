{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac6e9a14-d0bc-412a-b4f1-93ce0c2f47e8",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection - SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae33f605-b107-4dff-a923-3ea563ae660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Sklearn пример для бинарной классификации на Credit Card Fraud Detection\n",
    "Запуск: python sklearn_example.py\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, classification_report)\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"SKLEARN ML ПАЙПЛАЙН - Credit Card Fraud Detection\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # === ЭТАП 1: ЗАГРУЗКА ДАННЫХ ===\n",
    "    print(\"\\n1. ЗАГРУЗКА ДАННЫХ...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Читаем CSV файл\n",
    "        df = pd.read_csv('/work/dataset.csv')\n",
    "        load_time = time.time() - start_time\n",
    "        print(f\"   ✓ Данные загружены за {load_time:.2f} секунд\")\n",
    "        print(f\"   ✓ Размер данных: {df.shape[0]:,} строк, {df.shape[1]} столбцов\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"   ✗ Ошибка: Файл '/work/dataset.csv' не найден!\")\n",
    "        print(\"   Скачайте датасет с Kaggle: https://www.kaggle.com/mlg-ulb/creditcardfraud\")\n",
    "        return\n",
    "    \n",
    "    # === ЭТАП 2: ПРОСМОТР ДАННЫХ ===\n",
    "    print(\"\\n2. АНАЛИЗ ДАННЫХ...\")\n",
    "    print(f\"   Столбцы: {list(df.columns)}\")\n",
    "    print(f\"   Целевая переменная 'Class': {df['Class'].value_counts().to_dict()}\")\n",
    "    print(f\"   Пропущенные значения: {df.isnull().sum().sum()}\")\n",
    "    \n",
    "    # === ЭТАП 3: ПОДГОТОВКА ДАННЫХ ===\n",
    "    print(\"\\n3. ПОДГОТОВКА ДАННЫХ...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # В sklearn мы просто разделяем данные как есть\n",
    "    # Все столбцы кроме 'Class' - это признаки, 'Class' - целевая переменная\n",
    "    X = df.drop('Class', axis=1)  # Матрица признаков\n",
    "    y = df['Class']               # Вектор целевой переменной\n",
    "    \n",
    "    # Разделяем на обучающую и тестовую выборки\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.3,           # 30% на тест\n",
    "        random_state=42,         # Для воспроизводимости\n",
    "        stratify=y               # Сохраняем распределение классов\n",
    "    )\n",
    "    \n",
    "    prep_time = time.time() - start_time\n",
    "    print(f\"   ✓ Данные подготовлены за {prep_time:.2f} секунд\")\n",
    "    print(f\"   ✓ Обучающая выборка: {X_train.shape[0]:,} samples\")\n",
    "    print(f\"   ✓ Тестовая выборка: {X_test.shape[0]:,} samples\")\n",
    "    \n",
    "    # === ЭТАП 4: ОБУЧЕНИЕ МОДЕЛИ ===\n",
    "    print(\"\\n4. ОБУЧЕНИЕ МОДЕЛИ (RandomForest)...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Создаем и обучаем модель\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,        # Количество деревьев\n",
    "        max_depth=10,            # Максимальная глубина\n",
    "        random_state=42,         # Для воспроизводимости\n",
    "        n_jobs=-1               # Используем все ядра процессора\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)  # Обучаем модель!\n",
    "    train_time = time.time() - start_time\n",
    "    print(f\"   ✓ Модель обучена за {train_time:.2f} секунд\")\n",
    "    \n",
    "    # === ЭТАП 5: ПРЕДСКАЗАНИЯ ===\n",
    "    print(\"\\n5. ПРЕДСКАЗАНИЯ НА ТЕСТОВЫХ ДАННЫХ...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Делаем предсказания\n",
    "    y_pred = model.predict(X_test)           # Классы (0 или 1)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Вероятности класса 1\n",
    "    \n",
    "    predict_time = time.time() - start_time\n",
    "    print(f\"   ✓ Предсказания сделаны за {predict_time:.2f} секунд\")\n",
    "    \n",
    "    # === ЭТАП 6: ОЦЕНКА МОДЕЛИ ===\n",
    "    print(\"\\n6. ОЦЕНКА КАЧЕСТВА МОДЕЛИ:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Вычисляем метрики\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Выводим метрики\n",
    "    print(f\"   ТОЧНОСТЬ (Accuracy):  {accuracy:.4f}\")\n",
    "    print(f\"   ТОЧНОСТЬ (Precision): {precision:.4f}\")\n",
    "    print(f\"   ПОЛНОТА (Recall):     {recall:.4f}\")\n",
    "    print(f\"   F1-MEASURE:          {f1:.4f}\")\n",
    "    print(f\"   AUC-ROC:             {auc:.4f}\")\n",
    "    \n",
    "    # Детальный отчет\n",
    "    print(\"\\n   ДЕТАЛЬНЫЙ ОТЧЕТ:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Legit', 'Fraud']))\n",
    "    \n",
    "    # === ИТОГИ ===\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"ИТОГИ SKLEARN ПАЙПЛАЙНА:\")\n",
    "    print(f\"   • Общее время выполнения: {load_time + prep_time + train_time + predict_time:.2f} сек\")\n",
    "    print(f\"   • Размер данных: {df.shape[0]:,} строк × {df.shape[1]} столбцов\")\n",
    "    print(f\"   • Лучшая метрика (AUC-ROC): {auc:.4f}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9970ee42-4e9b-4835-ad2b-6b548a2e7072",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection - SKLEARN - Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81bd8ace-36e9-44e0-9cbb-7fa2d08534bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, classification_report)\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb7f4026-76d2-4b39-a518-1482ff0b8df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SKLEARN ML ПАЙПЛАЙН - Credit Card Fraud Detection\n",
      "======================================================================\n",
      "\n",
      "1. ЗАГРУЗКА ДАННЫХ...\n",
      "   ✓ Данные загружены за 1.11 секунд\n",
      "   ✓ Размер данных: 284,807 строк, 31 столбцов\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SKLEARN ML ПАЙПЛАЙН - Credit Card Fraud Detection\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# === ЭТАП 1: ЗАГРУЗКА ДАННЫХ ===\n",
    "print(\"\\n1. ЗАГРУЗКА ДАННЫХ...\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Читаем CSV файл\n",
    "    df = pd.read_csv('/shared_data/creditcard.csv')\n",
    "    load_time = time.time() - start_time\n",
    "    print(f\"   ✓ Данные загружены за {load_time:.2f} секунд\")\n",
    "    print(f\"   ✓ Размер данных: {df.shape[0]:,} строк, {df.shape[1]} столбцов\")\n",
    "except FileNotFoundError:\n",
    "    print(\"   ✗ Ошибка: Файл '/shared_data/creditcard.csv' не найден!\")\n",
    "    print(\"   Скачайте датасет с Kaggle: https://www.kaggle.com/mlg-ulb/creditcardfraud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "771246d4-9aa4-43a3-9b00-8e342a21bbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. АНАЛИЗ ДАННЫХ...\n",
      "   Столбцы: ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
      "   Целевая переменная 'Class': {0: 284315, 1: 492}\n",
      "   Пропущенные значения: 0\n"
     ]
    }
   ],
   "source": [
    "# === ЭТАП 2: ПРОСМОТР ДАННЫХ ===\n",
    "print(\"\\n2. АНАЛИЗ ДАННЫХ...\")\n",
    "print(f\"   Столбцы: {list(df.columns)}\")\n",
    "print(f\"   Целевая переменная 'Class': {df['Class'].value_counts().to_dict()}\")\n",
    "print(f\"   Пропущенные значения: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94d386fe-0a2a-4e68-bf03-4628b37b36a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. ПОДГОТОВКА ДАННЫХ...\n",
      "   ✓ Данные подготовлены за 0.09 секунд\n",
      "   ✓ Обучающая выборка: 199,364 samples\n",
      "   ✓ Тестовая выборка: 85,443 samples\n"
     ]
    }
   ],
   "source": [
    "# === ЭТАП 3: ПОДГОТОВКА ДАННЫХ ===\n",
    "print(\"\\n3. ПОДГОТОВКА ДАННЫХ...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# В sklearn мы просто разделяем данные как есть\n",
    "# Все столбцы кроме 'Class' - это признаки, 'Class' - целевая переменная\n",
    "X = df.drop('Class', axis=1)  # Матрица признаков\n",
    "y = df['Class']               # Вектор целевой переменной\n",
    "\n",
    "# Разделяем на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3,           # 30% на тест\n",
    "    random_state=42,         # Для воспроизводимости\n",
    "    stratify=y               # Сохраняем распределение классов\n",
    ")\n",
    "\n",
    "prep_time = time.time() - start_time\n",
    "print(f\"   ✓ Данные подготовлены за {prep_time:.2f} секунд\")\n",
    "print(f\"   ✓ Обучающая выборка: {X_train.shape[0]:,} samples\")\n",
    "print(f\"   ✓ Тестовая выборка: {X_test.shape[0]:,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc9ce0c8-4189-46cc-920d-36c5ad663760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. ОБУЧЕНИЕ МОДЕЛИ (RandomForest)...\n",
      "   ✓ Модель обучена за 6.51 секунд\n"
     ]
    }
   ],
   "source": [
    "# === ЭТАП 4: ОБУЧЕНИЕ МОДЕЛИ ===\n",
    "print(\"\\n4. ОБУЧЕНИЕ МОДЕЛИ (RandomForest)...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Создаем и обучаем модель\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,        # Количество деревьев\n",
    "    max_depth=10,            # Максимальная глубина\n",
    "    random_state=42,         # Для воспроизводимости\n",
    "    n_jobs=-1               # Используем все ядра процессора\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)  # Обучаем модель!\n",
    "train_time = time.time() - start_time\n",
    "print(f\"   ✓ Модель обучена за {train_time:.2f} секунд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea40fc02-85bd-406b-924a-d05599487381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. ПРЕДСКАЗАНИЯ НА ТЕСТОВЫХ ДАННЫХ...\n",
      "   ✓ Предсказания сделаны за 0.12 секунд\n"
     ]
    }
   ],
   "source": [
    "# === ЭТАП 5: ПРЕДСКАЗАНИЯ ===\n",
    "print(\"\\n5. ПРЕДСКАЗАНИЯ НА ТЕСТОВЫХ ДАННЫХ...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Делаем предсказания\n",
    "y_pred = model.predict(X_test)           # Классы (0 или 1)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]  # Вероятности класса 1\n",
    "\n",
    "predict_time = time.time() - start_time\n",
    "print(f\"   ✓ Предсказания сделаны за {predict_time:.2f} секунд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea88e472-5371-4636-9658-b1c9cb3f015d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. ОЦЕНКА КАЧЕСТВА МОДЕЛИ:\n",
      "--------------------------------------------------\n",
      "   ТОЧНОСТЬ (Accuracy):  0.9995\n",
      "   ТОЧНОСТЬ (Precision): 0.9569\n",
      "   ПОЛНОТА (Recall):     0.7500\n",
      "   F1-MEASURE:          0.8409\n",
      "   AUC-ROC:             0.9682\n",
      "\n",
      "   ДЕТАЛЬНЫЙ ОТЧЕТ:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Legit       1.00      1.00      1.00     85295\n",
      "       Fraud       0.96      0.75      0.84       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.98      0.87      0.92     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ИТОГИ SKLEARN ПАЙПЛАЙНА:\n",
      "   • Общее время выполнения: 7.82 сек\n",
      "   • Размер данных: 284,807 строк × 31 столбцов\n",
      "   • Лучшая метрика (AUC-ROC): 0.9682\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# === ЭТАП 6: ОЦЕНКА МОДЕЛИ ===\n",
    "print(\"\\n6. ОЦЕНКА КАЧЕСТВА МОДЕЛИ:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Вычисляем метрики\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Выводим метрики\n",
    "print(f\"   ТОЧНОСТЬ (Accuracy):  {accuracy:.4f}\")\n",
    "print(f\"   ТОЧНОСТЬ (Precision): {precision:.4f}\")\n",
    "print(f\"   ПОЛНОТА (Recall):     {recall:.4f}\")\n",
    "print(f\"   F1-MEASURE:          {f1:.4f}\")\n",
    "print(f\"   AUC-ROC:             {auc:.4f}\")\n",
    "\n",
    "# Детальный отчет\n",
    "print(\"\\n   ДЕТАЛЬНЫЙ ОТЧЕТ:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Legit', 'Fraud']))\n",
    "\n",
    "# === ИТОГИ ===\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ИТОГИ SKLEARN ПАЙПЛАЙНА:\")\n",
    "print(f\"   • Общее время выполнения: {load_time + prep_time + train_time + predict_time:.2f} сек\")\n",
    "print(f\"   • Размер данных: {df.shape[0]:,} строк × {df.shape[1]} столбцов\")\n",
    "print(f\"   • Лучшая метрика (AUC-ROC): {auc:.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "550806b7-eec2-411d-a550-31f589cfd4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85290</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0    1\n",
       "Actual               \n",
       "0          85290    5\n",
       "1             37  111"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "display(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a78baf-bb8a-42d4-a388-707b9fec5643",
   "metadata": {},
   "source": [
    "# Housing - SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7911b39-f898-479d-9aaa-0ad91e9e8a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Sklearn пример для РЕГРЕССИИ на California Housing Dataset\n",
    "Запуск: python sklearn_regression.py\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"SKLEARN РЕГРЕССИЯ - California Housing Dataset\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # === ЭТАП 1: ЗАГРУЗКА ДАННЫХ ===\n",
    "    print(\"\\n1. ЗАГРУЗКА ДАННЫХ...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Читаем CSV файл\n",
    "        df = pd.read_csv('/work/california_housing.csv')\n",
    "        load_time = time.time() - start_time\n",
    "        print(f\"   ✓ Данные загружены за {load_time:.2f} секунд\")\n",
    "        print(f\"   ✓ Размер данных: {df.shape[0]:,} строк, {df.shape[1]} столбцов\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"   ✗ Ошибка: Файл '/work/california_housing.csv' не найден!\")\n",
    "        print(\"   Скачайте датасет: https://www.kaggle.com/datasets/camnugent/california-housing-prices\")\n",
    "        return\n",
    "    \n",
    "    # === ЭТАП 2: ПРОСМОТР И ОЧИСТКА ДАННЫХ ===\n",
    "    print(\"\\n2. АНАЛИЗ И ОЧИСТКА ДАННЫХ...\")\n",
    "    print(f\"   Исходные столбцы: {list(df.columns)}\")\n",
    "    \n",
    "    # Проверяем пропущенные значения\n",
    "    missing_before = df.isnull().sum()\n",
    "    print(f\"   Пропущенные значения до обработки:\")\n",
    "    for col, missing_count in missing_before.items():\n",
    "        if missing_count > 0:\n",
    "            print(f\"     {col}: {missing_count} пропусков ({missing_count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Удаляем текстовый признак 'ocean_proximity'\n",
    "    if 'ocean_proximity' in df.columns:\n",
    "        df = df.drop('ocean_proximity', axis=1)\n",
    "        print(\"   ✓ Текстовый признак 'ocean_proximity' удален\")\n",
    "    \n",
    "    print(f\"   Столбцы после очистки: {list(df.columns)}\")\n",
    "    \n",
    "    # Показываем статистику по целевой переменной\n",
    "    target_col = 'median_house_value'  # Целевая переменная - цена дома\n",
    "    print(f\"   Целевая переменная '{target_col}':\")\n",
    "    print(f\"     Min: ${df[target_col].min():,}, Max: ${df[target_col].max():,}\")\n",
    "    print(f\"     Mean: ${df[target_col].mean():,.0f}, Std: ${df[target_col].std():,.0f}\")\n",
    "    \n",
    "    # === ЭТАП 3: ОБРАБОТКА ПРОПУЩЕННЫХ ЗНАЧЕНИЙ ===\n",
    "    print(\"\\n3. ОБРАБОТКА ПРОПУЩЕННЫХ ЗНАЧЕНИЙ...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Разделяем данные на признаки и целевую переменную ДО обработки пропусков\n",
    "    X = df.drop(target_col, axis=1)  # Матрица признаков\n",
    "    y = df[target_col]               # Вектор целевой переменной\n",
    "    \n",
    "    # Заполняем пропуски медианой для каждого столбца\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "    # Преобразуем обратно в DataFrame\n",
    "    X_imputed = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "    \n",
    "    # Проверяем результат\n",
    "    missing_after = X_imputed.isnull().sum().sum()\n",
    "    print(f\"   ✓ Пропуски заполнены медианой\")\n",
    "    print(f\"   ✓ Пропущенных значений после обработки: {missing_after}\")\n",
    "    \n",
    "    # Показываем какие столбцы были обработаны\n",
    "    for col in X.columns:\n",
    "        if missing_before[col] > 0:\n",
    "            median_val = imputer.statistics_[list(X.columns).index(col)]\n",
    "            print(f\"     {col}: {missing_before[col]} пропусков → заполнено медианой {median_val:.2f}\")\n",
    "    \n",
    "    prep_time = time.time() - start_time\n",
    "    print(f\"   ✓ Обработка пропусков выполнена за {prep_time:.2f} секунд\")\n",
    "    \n",
    "    # === ЭТАП 4: РАЗДЕЛЕНИЕ ДАННЫХ ===\n",
    "    print(\"\\n4. РАЗДЕЛЕНИЕ ДАННЫХ НА ОБУЧАЮЩУЮ И ТЕСТОВУЮ ВЫБОРКИ...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Разделяем на обучающую и тестовую выборки\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_imputed, y, \n",
    "        test_size=0.3,           # 30% на тест\n",
    "        random_state=42,         # Для воспроизводимости\n",
    "    )\n",
    "    \n",
    "    split_time = time.time() - start_time\n",
    "    print(f\"   ✓ Данные разделены за {split_time:.2f} секунд\")\n",
    "    print(f\"   ✓ Обучающая выборка: {X_train.shape[0]:,} samples\")\n",
    "    print(f\"   ✓ Тестовая выборка: {X_test.shape[0]:,} samples\")\n",
    "    print(f\"   ✓ Числовые признаки: {list(X_imputed.columns)}\")\n",
    "    \n",
    "    # === ЭТАП 5: ОБУЧЕНИЕ МОДЕЛИ ГРАДИЕНТНЫЙ БУСТИНГ ===\n",
    "    print(\"\\n5. ОБУЧЕНИЕ МОДЕЛИ (GradientBoostingRegressor)...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Создаем и обучаем модель градиентного бустинга\n",
    "    model = GradientBoostingRegressor(\n",
    "        n_estimators=100,        # Количество деревьев в ансамбле\n",
    "        learning_rate=0.1,       # Темп обучения\n",
    "        max_depth=3,             # Максимальная глубина деревьев\n",
    "        random_state=42,         # Для воспроизводимости\n",
    "        subsample=0.8           # Доля samples для каждого дерева\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)  # Обучаем модель!\n",
    "    train_time = time.time() - start_time\n",
    "    print(f\"   ✓ Модель обучена за {train_time:.2f} секунд\")\n",
    "    print(f\"   ✓ Обучено деревьев: {model.n_estimators}\")\n",
    "    \n",
    "    # === ЭТАП 6: ПРЕДСКАЗАНИЯ ===\n",
    "    print(\"\\n6. ПРЕДСКАЗАНИЯ НА ТЕСТОВЫХ ДАННЫХ...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Делаем предсказания (непрерывные значения!)\n",
    "    y_pred = model.predict(X_test)  # Предсказанные цены домов\n",
    "    \n",
    "    predict_time = time.time() - start_time\n",
    "    print(f\"   ✓ Предсказания сделаны за {predict_time:.2f} секунд\")\n",
    "    \n",
    "    # Показываем примеры реальных и предсказанных значений\n",
    "    print(\"\\n   Примеры предсказаний (первые 10):\")\n",
    "    comparison = pd.DataFrame({\n",
    "        'Actual': y_test.values[:10],\n",
    "        'Predicted': y_pred[:10],\n",
    "        'Error': y_test.values[:10] - y_pred[:10]\n",
    "    })\n",
    "    print(comparison.round(2))\n",
    "    \n",
    "    # === ЭТАП 7: ОЦЕНКА МОДЕЛИ РЕГРЕССИИ ===\n",
    "    print(\"\\n7. ОЦЕНКА КАЧЕСТВА РЕГРЕССИИ:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Вычисляем метрики регрессии\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    # Выводим метрики\n",
    "    print(f\"   СРЕДНЯЯ АБСОЛЮТНАЯ ОШИБКА (MAE):    ${mae:,.0f}\")\n",
    "    print(f\"   СРЕДНЯЯ КВАДРАТИЧНАЯ ОШИБКА (MSE):  ${mse:,.0f}\")\n",
    "    print(f\"   КОРЕНЬ ИЗ MSE (RMSE):               ${rmse:,.0f}\")\n",
    "    print(f\"   КОЭФФИЦИЕНТ ДЕТЕРМИНАЦИИ (R²):      {r2:.4f}\")\n",
    "    \n",
    "    # Интерпретация R²\n",
    "    print(f\"\\n   R² = {r2:.1%} - модель объясняет {r2:.1%} дисперсии целевой переменной\")\n",
    "    \n",
    "    # Сравниваем с базовым предсказанием (среднее значение)\n",
    "    baseline_mae = mean_absolute_error(y_test, [y_train.mean()] * len(y_test))\n",
    "    print(f\"   Улучшение над baseline (среднее):    {((baseline_mae - mae) / baseline_mae * 100):.1f}%\")\n",
    "    \n",
    "    # === ЭТАП 8: АНАЛИЗ ВАЖНОСТИ ПРИЗНАКОВ ===\n",
    "    print(\"\\n8. ВАЖНОСТЬ ПРИЗНАКОВ:\")\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_imputed.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(feature_importance.to_string(index=False))\n",
    "    \n",
    "    # === ИТОГИ ===\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"ИТОГИ SKLEARN РЕГРЕССИИ:\")\n",
    "    print(f\"   • Общее время выполнения: {load_time + prep_time + split_time + train_time + predict_time:.2f} сек\")\n",
    "    print(f\"   • Размер данных: {df.shape[0]:,} строк × {df.shape[1]} столбцов\")\n",
    "    print(f\"   • Обработано пропусков: {missing_before.sum()} значений\")\n",
    "    print(f\"   • Все признаки числовые: {list(X_imputed.columns)}\")\n",
    "    print(f\"   • Лучшая метрика (R²): {r2:.4f}\")\n",
    "    print(f\"   • Ошибка предсказания: ±${rmse:,.0f}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607100ea-e9e0-42e8-8e24-5a4563fd5a8d",
   "metadata": {},
   "source": [
    "# Housing - SKLEARN - Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7219ab7-7e81-4cde-8a4b-16483f44c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Sklearn пример для РЕГРЕССИИ на California Housing Dataset\n",
    "Запуск: python sklearn_regression.py\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c06509a-d57a-4656-8240-3f0d2f7c195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SKLEARN РЕГРЕССИЯ - California Housing Dataset\n",
      "======================================================================\n",
      "\n",
      "1. ЗАГРУЗКА ДАННЫХ...\n",
      "   ✓ Данные загружены за 0.02 секунд\n",
      "   ✓ Размер данных: 20,640 строк, 10 столбцов\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SKLEARN РЕГРЕССИЯ - California Housing Dataset\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# === ЭТАП 1: ЗАГРУЗКА ДАННЫХ ===\n",
    "print(\"\\n1. ЗАГРУЗКА ДАННЫХ...\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Читаем CSV файл\n",
    "    df = pd.read_csv('/shared_data/housing.csv')\n",
    "    load_time = time.time() - start_time\n",
    "    print(f\"   ✓ Данные загружены за {load_time:.2f} секунд\")\n",
    "    print(f\"   ✓ Размер данных: {df.shape[0]:,} строк, {df.shape[1]} столбцов\")\n",
    "except FileNotFoundError:\n",
    "    print(\"   ✗ Ошибка: Файл '/work/california_housing.csv' не найден!\")\n",
    "    print(\"   Скачайте датасет: https://www.kaggle.com/datasets/camnugent/california-housing-prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a37b44c-f1bf-4198-8c61-96f0b3fd82f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. АНАЛИЗ И ОЧИСТКА ДАННЫХ...\n",
      "   Исходные столбцы: ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value', 'ocean_proximity']\n",
      "   Пропущенные значения до обработки:\n",
      "     total_bedrooms: 207 пропусков (1.0%)\n",
      "   ✓ Текстовый признак 'ocean_proximity' удален\n",
      "   Столбцы после очистки: ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value']\n",
      "   Целевая переменная 'median_house_value':\n",
      "     Min: $14,999.0, Max: $500,001.0\n",
      "     Mean: $206,856, Std: $115,396\n"
     ]
    }
   ],
   "source": [
    "# === ЭТАП 2: ПРОСМОТР И ОЧИСТКА ДАННЫХ ===\n",
    "print(\"\\n2. АНАЛИЗ И ОЧИСТКА ДАННЫХ...\")\n",
    "print(f\"   Исходные столбцы: {list(df.columns)}\")\n",
    "\n",
    "# Проверяем пропущенные значения\n",
    "missing_before = df.isnull().sum()\n",
    "print(f\"   Пропущенные значения до обработки:\")\n",
    "for col, missing_count in missing_before.items():\n",
    "    if missing_count > 0:\n",
    "        print(f\"     {col}: {missing_count} пропусков ({missing_count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Удаляем текстовый признак 'ocean_proximity'\n",
    "if 'ocean_proximity' in df.columns:\n",
    "    df = df.drop('ocean_proximity', axis=1)\n",
    "    print(\"   ✓ Текстовый признак 'ocean_proximity' удален\")\n",
    "\n",
    "print(f\"   Столбцы после очистки: {list(df.columns)}\")\n",
    "\n",
    "# Показываем статистику по целевой переменной\n",
    "target_col = 'median_house_value'  # Целевая переменная - цена дома\n",
    "print(f\"   Целевая переменная '{target_col}':\")\n",
    "print(f\"     Min: ${df[target_col].min():,}, Max: ${df[target_col].max():,}\")\n",
    "print(f\"     Mean: ${df[target_col].mean():,.0f}, Std: ${df[target_col].std():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5735fd6-70f2-44a3-8d6d-e77d2a39c964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. ОБРАБОТКА ПРОПУЩЕННЫХ ЗНАЧЕНИЙ...\n",
      "   ✓ Пропуски заполнены медианой\n",
      "   ✓ Пропущенных значений после обработки: 0\n",
      "     total_bedrooms: 207 пропусков → заполнено медианой 435.00\n",
      "   ✓ Обработка пропусков выполнена за 0.02 секунд\n"
     ]
    }
   ],
   "source": [
    "# === ЭТАП 3: ОБРАБОТКА ПРОПУЩЕННЫХ ЗНАЧЕНИЙ ===\n",
    "print(\"\\n3. ОБРАБОТКА ПРОПУЩЕННЫХ ЗНАЧЕНИЙ...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Разделяем данные на признаки и целевую переменную ДО обработки пропусков\n",
    "X = df.drop(target_col, axis=1)  # Матрица признаков\n",
    "y = df[target_col]               # Вектор целевой переменной\n",
    "\n",
    "# Заполняем пропуски медианой для каждого столбца\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Преобразуем обратно в DataFrame\n",
    "X_imputed = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "# Проверяем результат\n",
    "missing_after = X_imputed.isnull().sum().sum()\n",
    "print(f\"   ✓ Пропуски заполнены медианой\")\n",
    "print(f\"   ✓ Пропущенных значений после обработки: {missing_after}\")\n",
    "\n",
    "# Показываем какие столбцы были обработаны\n",
    "for col in X.columns:\n",
    "    if missing_before[col] > 0:\n",
    "        median_val = imputer.statistics_[list(X.columns).index(col)]\n",
    "        print(f\"     {col}: {missing_before[col]} пропусков → заполнено медианой {median_val:.2f}\")\n",
    "\n",
    "prep_time = time.time() - start_time\n",
    "print(f\"   ✓ Обработка пропусков выполнена за {prep_time:.2f} секунд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b5c258d-e7e8-4483-8063-5f4c5047480b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. РАЗДЕЛЕНИЕ ДАННЫХ НА ОБУЧАЮЩУЮ И ТЕСТОВУЮ ВЫБОРКИ...\n",
      "   ✓ Данные разделены за 0.00 секунд\n",
      "   ✓ Обучающая выборка: 14,448 samples\n",
      "   ✓ Тестовая выборка: 6,192 samples\n",
      "   ✓ Числовые признаки: ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n"
     ]
    }
   ],
   "source": [
    "# === ЭТАП 4: РАЗДЕЛЕНИЕ ДАННЫХ ===\n",
    "print(\"\\n4. РАЗДЕЛЕНИЕ ДАННЫХ НА ОБУЧАЮЩУЮ И ТЕСТОВУЮ ВЫБОРКИ...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Разделяем на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imputed, y, \n",
    "    test_size=0.3,           # 30% на тест\n",
    "    random_state=42,         # Для воспроизводимости\n",
    ")\n",
    "\n",
    "split_time = time.time() - start_time\n",
    "print(f\"   ✓ Данные разделены за {split_time:.2f} секунд\")\n",
    "print(f\"   ✓ Обучающая выборка: {X_train.shape[0]:,} samples\")\n",
    "print(f\"   ✓ Тестовая выборка: {X_test.shape[0]:,} samples\")\n",
    "print(f\"   ✓ Числовые признаки: {list(X_imputed.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f286ed1-39a9-4960-8a2c-0fade4e296e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. ОБУЧЕНИЕ МОДЕЛИ (GradientBoostingRegressor)...\n",
      "   ✓ Модель обучена за 1.41 секунд\n",
      "   ✓ Обучено деревьев: 100\n"
     ]
    }
   ],
   "source": [
    "# === ЭТАП 5: ОБУЧЕНИЕ МОДЕЛИ ГРАДИЕНТНЫЙ БУСТИНГ ===\n",
    "print(\"\\n5. ОБУЧЕНИЕ МОДЕЛИ (GradientBoostingRegressor)...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Создаем и обучаем модель градиентного бустинга\n",
    "model = GradientBoostingRegressor(\n",
    "    n_estimators=100,        # Количество деревьев в ансамбле\n",
    "    learning_rate=0.1,       # Темп обучения\n",
    "    max_depth=3,             # Максимальная глубина деревьев\n",
    "    random_state=42,         # Для воспроизводимости\n",
    "    subsample=0.8           # Доля samples для каждого дерева\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)  # Обучаем модель!\n",
    "train_time = time.time() - start_time\n",
    "print(f\"   ✓ Модель обучена за {train_time:.2f} секунд\")\n",
    "print(f\"   ✓ Обучено деревьев: {model.n_estimators}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c85e464-04f8-4313-9cd4-f2bc4f24cea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. ПРЕДСКАЗАНИЯ НА ТЕСТОВЫХ ДАННЫХ...\n",
      "   ✓ Предсказания сделаны за 0.01 секунд\n",
      "\n",
      "   Примеры предсказаний (первые 10):\n",
      "     Actual  Predicted      Error\n",
      "0   47700.0   42847.09    4852.91\n",
      "1   45800.0   92942.06  -47142.06\n",
      "2  500001.0  360341.87  139659.13\n",
      "3  218600.0  263196.31  -44596.31\n",
      "4  278000.0  237880.90   40119.10\n",
      "5  158700.0  160058.98   -1358.98\n",
      "6  198200.0  277725.92  -79525.92\n",
      "7  157500.0  206392.72  -48892.72\n",
      "8  340000.0  288229.14   51770.86\n",
      "9  446600.0  440704.96    5895.04\n"
     ]
    }
   ],
   "source": [
    "# === ЭТАП 6: ПРЕДСКАЗАНИЯ ===\n",
    "print(\"\\n6. ПРЕДСКАЗАНИЯ НА ТЕСТОВЫХ ДАННЫХ...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Делаем предсказания (непрерывные значения!)\n",
    "y_pred = model.predict(X_test)  # Предсказанные цены домов\n",
    "\n",
    "predict_time = time.time() - start_time\n",
    "print(f\"   ✓ Предсказания сделаны за {predict_time:.2f} секунд\")\n",
    "\n",
    "# Показываем примеры реальных и предсказанных значений\n",
    "print(\"\\n   Примеры предсказаний (первые 10):\")\n",
    "comparison = pd.DataFrame({\n",
    "    'Actual': y_test.values[:10],\n",
    "    'Predicted': y_pred[:10],\n",
    "    'Error': y_test.values[:10] - y_pred[:10]\n",
    "})\n",
    "print(comparison.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2981ae3e-588a-44f9-8f54-e87256356e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. ОЦЕНКА КАЧЕСТВА РЕГРЕССИИ:\n",
      "--------------------------------------------------\n",
      "   СРЕДНЯЯ АБСОЛЮТНАЯ ОШИБКА (MAE):    $37,592\n",
      "   СРЕДНЯЯ КВАДРАТИЧНАЯ ОШИБКА (MSE):  $2,970,917,881\n",
      "   КОРЕНЬ ИЗ MSE (RMSE):               $54,506\n",
      "   КОЭФФИЦИЕНТ ДЕТЕРМИНАЦИИ (R²):      0.7737\n",
      "\n",
      "   R² = 77.4% - модель объясняет 77.4% дисперсии целевой переменной\n",
      "   Улучшение над baseline (среднее):    58.5%\n",
      "\n",
      "8. ВАЖНОСТЬ ПРИЗНАКОВ:\n",
      "           feature  importance\n",
      "     median_income    0.603432\n",
      "          latitude    0.143552\n",
      "         longitude    0.135507\n",
      "housing_median_age    0.053353\n",
      "        population    0.029093\n",
      "    total_bedrooms    0.021366\n",
      "        households    0.010613\n",
      "       total_rooms    0.003084\n"
     ]
    }
   ],
   "source": [
    "# === ЭТАП 7: ОЦЕНКА МОДЕЛИ РЕГРЕССИИ ===\n",
    "print(\"\\n7. ОЦЕНКА КАЧЕСТВА РЕГРЕССИИ:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Вычисляем метрики регрессии\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Выводим метрики\n",
    "print(f\"   СРЕДНЯЯ АБСОЛЮТНАЯ ОШИБКА (MAE):    ${mae:,.0f}\")\n",
    "print(f\"   СРЕДНЯЯ КВАДРАТИЧНАЯ ОШИБКА (MSE):  ${mse:,.0f}\")\n",
    "print(f\"   КОРЕНЬ ИЗ MSE (RMSE):               ${rmse:,.0f}\")\n",
    "print(f\"   КОЭФФИЦИЕНТ ДЕТЕРМИНАЦИИ (R²):      {r2:.4f}\")\n",
    "\n",
    "# Интерпретация R²\n",
    "print(f\"\\n   R² = {r2:.1%} - модель объясняет {r2:.1%} дисперсии целевой переменной\")\n",
    "\n",
    "# Сравниваем с базовым предсказанием (среднее значение)\n",
    "baseline_mae = mean_absolute_error(y_test, [y_train.mean()] * len(y_test))\n",
    "print(f\"   Улучшение над baseline (среднее):    {((baseline_mae - mae) / baseline_mae * 100):.1f}%\")\n",
    "\n",
    "# === ЭТАП 8: АНАЛИЗ ВАЖНОСТИ ПРИЗНАКОВ ===\n",
    "print(\"\\n8. ВАЖНОСТЬ ПРИЗНАКОВ:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_imputed.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eca5a0be-6c04-4f03-a88c-8f165a0f34e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ИТОГИ SKLEARN РЕГРЕССИИ:\n",
      "   • Общее время выполнения: 1.46 сек\n",
      "   • Размер данных: 20,640 строк × 9 столбцов\n",
      "   • Обработано пропусков: 207 значений\n",
      "   • Все признаки числовые: ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n",
      "   • Лучшая метрика (R²): 0.7737\n",
      "   • Ошибка предсказания: ±$54,506\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# === ИТОГИ ===\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ИТОГИ SKLEARN РЕГРЕССИИ:\")\n",
    "print(f\"   • Общее время выполнения: {load_time + prep_time + split_time + train_time + predict_time:.2f} сек\")\n",
    "print(f\"   • Размер данных: {df.shape[0]:,} строк × {df.shape[1]} столбцов\")\n",
    "print(f\"   • Обработано пропусков: {missing_before.sum()} значений\")\n",
    "print(f\"   • Все признаки числовые: {list(X_imputed.columns)}\")\n",
    "print(f\"   • Лучшая метрика (R²): {r2:.4f}\")\n",
    "print(f\"   • Ошибка предсказания: ±${rmse:,.0f}\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
