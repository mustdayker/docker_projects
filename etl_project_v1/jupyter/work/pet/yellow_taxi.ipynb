{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025655f6-59c2-417a-a5f1-364e36a9ce23",
   "metadata": {},
   "source": [
    "# –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–µ—Ç–ª—å–Ω–æ—Å—Ç–∏ —Ç–∞–∫—Å–∏ –≤ –ù—å—é-–ô–æ—Ä–∫–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe30d3f1-2d44-4bfd-aaee-68372acbbe24",
   "metadata": {},
   "source": [
    "–ö–æ–Ω–µ—á–Ω–æ! –≠—Ç–æ –æ–¥–∏–Ω –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ NYC Taxi & Limousine Commission (TLC) - –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–µ–∑–¥–∫–∞—Ö –≤ –∂–µ–ª—Ç—ã—Ö —Ç–∞–∫—Å–∏ –ù—å—é-–ô–æ—Ä–∫–∞. –í–æ—Ç –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—è:\n",
    "\n",
    "## –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–µ–∑–¥–∫–µ\n",
    "\n",
    "**`vendorid`** - –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞/–≤–µ–Ω–¥–æ—Ä–∞ —Ç–∞–∫—Å–∏\n",
    "- 1 = Creative Mobile Technologies (CMT)\n",
    "- 2 = VeriFone Inc. (VTS)\n",
    "\n",
    "**`tpep_pickup_datetime`** - –î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –ø–æ–µ–∑–¥–∫–∏ (Timestamp)\n",
    "\n",
    "**`tpep_dropoff_datetime`** - –î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø–æ–µ–∑–¥–∫–∏ (Timestamp)\n",
    "\n",
    "**`passenger_count`** - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤ –≤ —Ç–∞–∫—Å–∏\n",
    "\n",
    "## –ì–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n",
    "\n",
    "**`trip_distance`** - –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ–µ–∑–¥–∫–∏ –≤ –º–∏–ª—è—Ö\n",
    "\n",
    "**`pulocationid`** - ID –∑–æ–Ω—ã —Ç–∞–∫—Å–∏ (Taxi Zone) –¥–ª—è –ø–æ—Å–∞–¥–∫–∏\n",
    "- –°—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ —Ç–∞–±–ª–∏—Ü—É taxi zones\n",
    "\n",
    "**`dolocationid`** - ID –∑–æ–Ω—ã —Ç–∞–∫—Å–∏ (Taxi Zone) –¥–ª—è –≤—ã—Å–∞–¥–∫–∏\n",
    "- –°—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ —Ç–∞–±–ª–∏—Ü—É taxi zones\n",
    "\n",
    "**`ratecodeid`** - –¢–∏–ø —Ç–∞—Ä–∏—Ñ–∞:\n",
    "- 1 = –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ç–∞—Ä–∏—Ñ\n",
    "- 2 = JFK Airport\n",
    "- 3 = Newark Airport\n",
    "- 4 = Nassau or Westchester\n",
    "- 5 = Negotiated fare\n",
    "- 6 = Group ride\n",
    "\n",
    "## –§–ª–∞–≥–∏ –∏ —Å—Ç–∞—Ç—É—Å—ã\n",
    "\n",
    "**`store_and_fwd_flag`** - –§–ª–∞–≥ —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –ø–µ—Ä–µ—Å—ã–ª–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
    "- Y = –ø–æ–µ–∑–¥–∫–∞ –±—ã–ª–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –ø–∞–º—è—Ç–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –∏ –ø–µ—Ä–µ–¥–∞–Ω–∞ –ø–æ–∑–∂–µ\n",
    "- N = –ø–æ–µ–∑–¥–∫–∞ –ø–µ—Ä–µ–¥–∞–Ω–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏\n",
    "\n",
    "**`payment_type`** - –¢–∏–ø –æ–ø–ª–∞—Ç—ã:\n",
    "- 1 = –ö—Ä–µ–¥–∏—Ç–Ω–∞—è –∫–∞—Ä—Ç–∞\n",
    "- 2 = –ù–∞–ª–∏—á–Ω—ã–µ\n",
    "- 3 = –ë–µ–∑ –æ–ø–ª–∞—Ç—ã\n",
    "- 4 = –°–ø–æ—Ä\n",
    "- 5 = –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ\n",
    "- 6 = Voided trip\n",
    "\n",
    "## –°—Ç–æ–∏–º–æ—Å—Ç—å –ø–æ–µ–∑–¥–∫–∏ (–≤ –¥–æ–ª–ª–∞—Ä–∞—Ö)\n",
    "\n",
    "**`fare_amount`** - –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø—Ä–æ–µ–∑–¥–∞\n",
    "\n",
    "**`extra`** - –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–ª–∞—Ç–µ–∂–∏:\n",
    "- –ü–∏–∫–æ–≤–æ–µ –≤—Ä–µ–º—è, –Ω–æ—á–Ω—ã–µ –Ω–∞–¥–±–∞–≤–∫–∏ –∏ —Ç.–¥.\n",
    "\n",
    "**`mta_tax`** - –ù–∞–ª–æ–≥ MTA ($0.50)\n",
    "\n",
    "**`tip_amount`** - –ß–∞–µ–≤—ã–µ\n",
    "\n",
    "**`tolls_amount`** - –ü–ª–∞—Ç–∞ –∑–∞ –ø—Ä–æ–µ–∑–¥ –ø–æ –ø–ª–∞—Ç–Ω—ã–º –¥–æ—Ä–æ–≥–∞–º/–º–æ—Å—Ç–∞–º\n",
    "\n",
    "**`improvement_surcharge`** - –ù–∞–¥–±–∞–≤–∫–∞ –∑–∞ —É–ª—É—á—à–µ–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞ ($0.30)\n",
    "\n",
    "**`total_amount`** - –û–±—â–∞—è —Å—É–º–º–∞ –∫ –æ–ø–ª–∞—Ç–µ\n",
    "\n",
    "**`congestion_surcharge`** - –ù–∞–¥–±–∞–≤–∫–∞ –∑–∞ –ø—Ä–æ–±–∫–∏\n",
    "- –ü—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –≤ –∑–æ–Ω–∞—Ö —Å –≤—ã—Å–æ–∫–æ–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç—å—é\n",
    "\n",
    "**`airport_fee`** - –ê—ç—Ä–æ–ø–æ—Ä—Ç–æ–≤—ã–π —Å–±–æ—Ä\n",
    "- –ü—Ä–∏ –ø–æ–µ–∑–¥–∫–∞—Ö –∏–∑ –∞—ç—Ä–æ–ø–æ—Ä—Ç–æ–≤\n",
    "\n",
    "## –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö:\n",
    "\n",
    "1. **–ß–∞—Å—Ç–æ—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è**: –ï–∂–µ–º–µ—Å—è—á–Ω–æ\n",
    "2. **–§–æ—Ä–º–∞—Ç**: Parquet (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏)\n",
    "3. **–û–±—ä–µ–º**: –û–±—ã—á–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–ª–ª–∏–æ–Ω–æ–≤ –∑–∞–ø–∏—Å–µ–π –≤ –º–µ—Å—è—Ü\n",
    "4. **–ö–∞—á–µ—Å—Ç–≤–æ**: –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç TLC, –Ω–æ —Ç—Ä–µ–±—É—é—Ç –æ—á–∏—Å—Ç–∫–∏\n",
    "\n",
    "## –¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –¥–∞–Ω–Ω—ã—Ö:\n",
    "- –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏\n",
    "- –ù—É–ª–µ–≤—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –ø—Ä–∏ –Ω–µ–Ω—É–ª–µ–≤–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏\n",
    "- –ê–Ω–æ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –ø–æ–µ–∑–¥–∫–∏\n",
    "- –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –ø–æ–ª—è—Ö\n",
    "\n",
    "–≠—Ç–∏ –¥–∞–Ω–Ω—ã–µ —à–∏—Ä–æ–∫–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è:\n",
    "- –ê–Ω–∞–ª–∏–∑–∞ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤\n",
    "- –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ø—Ä–æ—Å–∞ –Ω–∞ —Ç–∞–∫—Å–∏\n",
    "- –ì–µ–æ–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞\n",
    "- –ê–Ω–∞–ª–∏–∑–∞ –¥–æ—Ö–æ–¥–æ–≤ –∏ –±–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫\n",
    "\n",
    "–•–æ—á–µ—à—å, —á—Ç–æ–±—ã —è –ø–æ–º–æ–≥ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã —ç—Ç–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff75d0aa-c32d-4392-9987-2f9e53891bef",
   "metadata": {},
   "source": [
    "–û—Ç–ª–∏—á–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã! –≠—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç –æ—á–µ–Ω—å –±–æ–≥–∞—Ç –Ω–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.\n",
    "\n",
    "## üìä **–ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞**\n",
    "\n",
    "### **–í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏**\n",
    "```python\n",
    "# –ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è/–µ–∂–µ–º–µ—Å—è—á–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å\n",
    "daily_trips = df.groupBy(date_format(\"tpep_pickup_datetime\", \"yyyy-MM-dd\")).count()\n",
    "\n",
    "# –ß–∞—Å—ã –ø–∏–∫–æ–≤–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏\n",
    "peak_hours = df.groupBy(hour(\"tpep_pickup_datetime\")).count().orderBy(\"hour\")\n",
    "```\n",
    "\n",
    "### **–ì–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏**\n",
    "```python\n",
    "# –°–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∑–æ–Ω—ã –ø–æ—Å–∞–¥–∫–∏/–≤—ã—Å–∞–¥–∫–∏\n",
    "top_pickup_locations = df.groupBy(\"pulocationid\").count().orderBy(desc(\"count\"))\n",
    "top_dropoff_locations = df.groupBy(\"dolocationid\").count().orderBy(desc(\"count\"))\n",
    "```\n",
    "\n",
    "### **–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏**\n",
    "```python\n",
    "# –°—Ä–µ–¥–Ω–∏–π —á–µ–∫ –ø–æ —á–∞—Å–∞–º/–¥–Ω—è–º\n",
    "avg_fare_by_hour = df.groupBy(hour(\"tpep_pickup_datetime\")).agg(\n",
    "    avg(\"total_amount\").alias(\"avg_revenue\")\n",
    ")\n",
    "\n",
    "# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –æ–ø–ª–∞—Ç\n",
    "payment_distribution = df.groupBy(\"payment_type\").count()\n",
    "```\n",
    "\n",
    "### **–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏**\n",
    "```python\n",
    "# –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ–µ–∑–¥–æ–∫\n",
    "df.withColumn(\"trip_duration_minutes\", \n",
    "    (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\"))/60\n",
    ").select(\n",
    "    avg(\"trip_duration_minutes\").alias(\"avg_duration\"),\n",
    "    avg(\"trip_distance\").alias(\"avg_distance\")\n",
    ").show()\n",
    "```\n",
    "\n",
    "## ü§ñ **–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ —ç—Ç–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ**\n",
    "\n",
    "### **1. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–µ–∑–¥–∫–∏**\n",
    "**–í–æ–ø—Ä–æ—Å**: \"–°–∫–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–π–º–µ—Ç –ø–æ–µ–∑–¥–∫–∞ –∏–∑ —Ç–æ—á–∫–∏ A –≤ —Ç–æ—á–∫—É B?\"\n",
    "```python\n",
    "# –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è\n",
    "df = df.withColumn(\"trip_duration\", \n",
    "    unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\")\n",
    ")\n",
    "\n",
    "# –ü—Ä–∏–∑–Ω–∞–∫–∏: –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏, —á–∞—Å, –∑–æ–Ω—ã, —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ, –ø–∞—Å—Å–∞–∂–∏—Ä—ã\n",
    "```\n",
    "\n",
    "### **2. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –ø–æ–µ–∑–¥–∫–∏**\n",
    "**–í–æ–ø—Ä–æ—Å**: \"–°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç —Å—Ç–æ–∏—Ç—å –ø–æ–µ–∑–¥–∫–∞?\"\n",
    "```python\n",
    "# –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: total_amount\n",
    "# –ü—Ä–∏–∑–Ω–∞–∫–∏: —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ, –≤—Ä–µ–º—è —Å—É—Ç–æ–∫, –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏, –∑–æ–Ω—ã, –ø—Ä–æ–±–∫–∏\n",
    "```\n",
    "\n",
    "### **3. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —á–∞–µ–≤—ã—Ö**\n",
    "**–í–æ–ø—Ä–æ—Å**: \"–î–∞—Å—Ç –ª–∏ –ø–∞—Å—Å–∞–∂–∏—Ä —á–∞–µ–≤—ã–µ?\"\n",
    "```python\n",
    "# –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è\n",
    "df = df.withColumn(\"has_tip\", when(col(\"tip_amount\") > 0, 1).otherwise(0))\n",
    "```\n",
    "\n",
    "### **4. –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ø—Ä–æ—Å–∞**\n",
    "**–í–æ–ø—Ä–æ—Å**: \"–°–∫–æ–ª—å–∫–æ –ø–æ–µ–∑–¥–æ–∫ –±—É–¥–µ—Ç –≤ —Å–ª–µ–¥—É—é—â–µ–º —á–∞—Å—É/–¥–Ω–µ?\"\n",
    "```python\n",
    "# –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã - –∞–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ —á–∞—Å–∞–º\n",
    "hourly_demand = df.groupBy(\n",
    "    hour(\"tpep_pickup_datetime\").alias(\"hour\"),\n",
    "    dayofweek(\"tpep_pickup_datetime\").alias(\"day_of_week\")\n",
    ").count()\n",
    "```\n",
    "\n",
    "### **5. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ø–æ–µ–∑–¥–æ–∫**\n",
    "**–í–æ–ø—Ä–æ—Å**: \"–ö–∞–∫–∏–µ —Ç–∏–ø—ã –ø–æ–µ–∑–¥–æ–∫ —Å—É—â–µ—Å—Ç–≤—É—é—Ç?\"\n",
    "```python\n",
    "# –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ø–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é, —Å—Ç–æ–∏–º–æ—Å—Ç–∏\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"trip_distance\", \"total_amount\", \"passenger_count\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "```\n",
    "\n",
    "## üí° **–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –±–∏–∑–Ω–µ—Å-–≤–æ–ø—Ä–æ—Å—ã –¥–ª—è ML**\n",
    "\n",
    "### **–î–ª—è —Ç–∞–∫—Å–∏-–∫–æ–º–ø–∞–Ω–∏–π:**\n",
    "- \"–í –∫–∞–∫–∏–µ –∑–æ–Ω—ã –Ω–∞–ø—Ä–∞–≤–∏—Ç—å —Ç–∞–∫—Å–∏ –≤ —Å–ª–µ–¥—É—é—â–∏–π —á–∞—Å?\"\n",
    "- \"–ö–∞–∫–∏–µ –ø–æ–µ–∑–¥–∫–∏ –Ω–∞–∏–±–æ–ª–µ–µ –ø—Ä–∏–±—ã–ª—å–Ω—ã–µ?\"\n",
    "- \"–ö–∞–∫ –ø–æ–≥–æ–¥–∞ –≤–ª–∏—è–µ—Ç –Ω–∞ —Å–ø—Ä–æ—Å?\"\n",
    "\n",
    "### **–î–ª—è –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤:**\n",
    "- \"–ö–æ–≥–¥–∞ –ª—É—á—à–µ –µ—Ö–∞—Ç—å, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–æ–∫?\"\n",
    "- \"–°–∫–æ–ª—å–∫–æ –≤ —Å—Ä–µ–¥–Ω–µ–º —Å—Ç–æ–∏—Ç –ø–æ–µ–∑–¥–∫–∞ –≤ –º–æ–π —Ä–∞–π–æ–Ω?\"\n",
    "\n",
    "### **–î–ª—è –≥–æ—Ä–æ–¥—Å–∫–æ–≥–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è:**\n",
    "- \"–ì–¥–µ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –Ω–æ–≤—ã–µ —Ç–∞–∫—Å–∏-—Å—Ç–æ—è–Ω–∫–∏?\"\n",
    "- \"–ö–∞–∫–∏–µ —Ä–∞–π–æ–Ω—ã –Ω—É–∂–¥–∞—é—Ç—Å—è –≤ —É–ª—É—á—à–µ–Ω–∏–∏ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞?\"\n",
    "\n",
    "## üõ† **–ü—Ä–∏–º–µ—Ä –ø–∞–π–ø–ª–∞–π–Ω–∞ ML:**\n",
    "```python\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "df_ml = df.withColumn(\"trip_duration\", \n",
    "    (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\"))/60\n",
    ").filter(\n",
    "    (col(\"trip_duration\") > 0) & (col(\"trip_duration\") < 180)  # —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π\n",
    ")\n",
    "\n",
    "# –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "zone_indexer = StringIndexer(inputCol=\"pulocationid\", outputCol=\"pu_zone_index\")\n",
    "hour_indexer = StringIndexer(inputCol=hour(\"tpep_pickup_datetime\"), outputCol=\"hour_index\")\n",
    "\n",
    "# –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"pu_zone_index\", \"hour_index\", \"trip_distance\", \"passenger_count\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# –ú–æ–¥–µ–ª—å\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"trip_duration\")\n",
    "```\n",
    "\n",
    "–≠—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç - –∑–æ–ª–æ—Ç–∞—è –∂–∏–ª–∞ –¥–ª—è Data Scientist! –ß—Ç–æ –∏–º–µ–Ω–Ω–æ —Ç–µ–±—è –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç –±–æ–ª—å—à–µ - –∞–Ω–∞–ª–∏–∑ –∏–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c880db8d-2deb-4345-9235-6500ed6d8e77",
   "metadata": {},
   "source": [
    "–û—Ç–ª–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å! –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ø–æ–µ–∑–¥–æ–∫ –º–æ–∂–µ—Ç —Ä–∞—Å–∫—Ä—ã—Ç—å —Å–∫—Ä—ã—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –¥–∞–Ω–Ω—ã—Ö. –î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º –ø–æ–¥—Ä–æ–±–Ω–æ.\n",
    "\n",
    "## üéØ **–¶–µ–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –ø–æ–µ–∑–¥–æ–∫**\n",
    "\n",
    "### **–ß—Ç–æ –º—ã –º–æ–∂–µ–º —É–∑–Ω–∞—Ç—å:**\n",
    "- –¢–∏–ø–∏—á–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –ø–æ–µ–∑–¥–æ–∫\n",
    "- –ê–Ω–æ–º–∞–ª—å–Ω—ã–µ/–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–µ–∑–¥–∫–∏\n",
    "- –°–µ–≥–º–µ–Ω—Ç—ã –∫–ª–∏–µ–Ω—Ç–æ–≤\n",
    "- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–æ–≤\n",
    "\n",
    "## üîß **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è**\n",
    "\n",
    "```python\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "df_cluster = df.withColumn(\"trip_duration_minutes\", \n",
    "    (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\")) / 60\n",
    ").filter(\n",
    "    (col(\"trip_duration_minutes\") > 0) & \n",
    "    (col(\"trip_duration_minutes\") < 180) &\n",
    "    (col(\"trip_distance\") > 0) &\n",
    "    (col(\"trip_distance\") < 50) &\n",
    "    (col(\"total_amount\") > 0) &\n",
    "    (col(\"total_amount\") < 200)\n",
    ")\n",
    "\n",
    "# –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"trip_distance\", \"trip_duration_minutes\", \"total_amount\", \"passenger_count\"],\n",
    "    outputCol=\"raw_features\"\n",
    ")\n",
    "\n",
    "# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–≤–∞–∂–Ω–æ –¥–ª—è K-means!)\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"raw_features\",\n",
    "    outputCol=\"features\",\n",
    "    withStd=True,\n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "# –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è\n",
    "kmeans = KMeans(\n",
    "    featuresCol=\"features\",\n",
    "    predictionCol=\"cluster\",\n",
    "    k=5,  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# –ü–∞–π–ø–ª–∞–π–Ω\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, scaler, kmeans])\n",
    "model = pipeline.fit(df_cluster)\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "result = model.transform(df_cluster)\n",
    "```\n",
    "\n",
    "## üìä **–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏**\n",
    "\n",
    "### **1. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º**\n",
    "```python\n",
    "# –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º\n",
    "cluster_stats = result.groupBy(\"cluster\").agg(\n",
    "    count(\"*\").alias(\"count\"),\n",
    "    avg(\"trip_distance\").alias(\"avg_distance\"),\n",
    "    avg(\"trip_duration_minutes\").alias(\"avg_duration\"),\n",
    "    avg(\"total_amount\").alias(\"avg_amount\"),\n",
    "    avg(\"passenger_count\").alias(\"avg_passengers\"),\n",
    "    percentile_approx(\"total_amount\", 0.5).alias(\"median_amount\")\n",
    ").orderBy(\"cluster\")\n",
    "\n",
    "cluster_stats.show()\n",
    "```\n",
    "\n",
    "### **2. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ü–µ–Ω—Ç—Ä–æ–∏–¥–æ–≤**\n",
    "```python\n",
    "# –ü–æ–ª—É—á–∞–µ–º —Ü–µ–Ω—Ç—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "centers = model.stages[-1].clusterCenters()\n",
    "\n",
    "print(\"–¶–µ–Ω—Ç—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:\")\n",
    "for i, center in enumerate(centers):\n",
    "    print(f\"–ö–ª–∞—Å—Ç–µ—Ä {i}: {center}\")\n",
    "```\n",
    "\n",
    "## üîç **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤**\n",
    "\n",
    "### **–¢–∏–ø–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –æ–±–Ω–∞—Ä—É–∂–∏—Ç—å:**\n",
    "\n",
    "#### **–ö–ª–∞—Å—Ç–µ—Ä 0: \"–ö–æ—Ä–æ—Ç–∫–∏–µ –≥–æ—Ä–æ–¥—Å–∫–∏–µ –ø–æ–µ–∑–¥–∫–∏\"**\n",
    "```\n",
    "- –°—Ä–µ–¥–Ω–µ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: 1-3 –º–∏–ª–∏\n",
    "- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 5-15 –º–∏–Ω—É—Ç\n",
    "- –°—Ç–æ–∏–º–æ—Å—Ç—å: $8-15\n",
    "- –ü–∞—Å—Å–∞–∂–∏—Ä—ã: 1-2\n",
    "```\n",
    "**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è**: –ë—ã—Å—Ç—Ä—ã–µ –ø–æ–µ–∑–¥–∫–∏ –ø–æ —Ü–µ–Ω—Ç—Ä—É –≥–æ—Ä–æ–¥–∞, –≤–æ–∑–º–æ–∂–Ω–æ, –¥–µ–ª–æ–≤—ã–µ –≤—Å—Ç—Ä–µ—á–∏\n",
    "\n",
    "#### **–ö–ª–∞—Å—Ç–µ—Ä 1: \"–ê—ç—Ä–æ–ø–æ—Ä—Ç–æ–≤—ã–µ –ø–æ–µ–∑–¥–∫–∏\"**\n",
    "```\n",
    "- –°—Ä–µ–¥–Ω–µ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: 15-25 –º–∏–ª—å  \n",
    "- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 30-60 –º–∏–Ω—É—Ç\n",
    "- –°—Ç–æ–∏–º–æ—Å—Ç—å: $50-80\n",
    "- –ü–∞—Å—Å–∞–∂–∏—Ä—ã: 1-2 —Å –±–∞–≥–∞–∂–æ–º\n",
    "```\n",
    "**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è**: –ü–æ–µ–∑–¥–∫–∏ –≤ JFK/LaGuardia\n",
    "\n",
    "#### **–ö–ª–∞—Å—Ç–µ—Ä 2: \"–î–∞–ª—å–Ω–∏–µ –ø–æ–µ–∑–¥–∫–∏\"**\n",
    "```\n",
    "- –°—Ä–µ–¥–Ω–µ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: 8-12 –º–∏–ª—å\n",
    "- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 25-40 –º–∏–Ω—É—Ç\n",
    "- –°—Ç–æ–∏–º–æ—Å—Ç—å: $30-50\n",
    "- –ü–∞—Å—Å–∞–∂–∏—Ä—ã: 1-3\n",
    "```\n",
    "**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è**: –ü–æ–µ–∑–¥–∫–∏ –º–µ–∂–¥—É —Ä–∞–π–æ–Ω–∞–º–∏, –≤–æ–∑–º–æ–∂–Ω–æ, –≤ –ø—Ä–∏–≥–æ—Ä–æ–¥\n",
    "\n",
    "#### **–ö–ª–∞—Å—Ç–µ—Ä 3: \"–ì—Ä—É–ø–ø–æ–≤—ã–µ –ø–æ–µ–∑–¥–∫–∏\"**\n",
    "```\n",
    "- –°—Ä–µ–¥–Ω–µ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: 2-5 –º–∏–ª—å\n",
    "- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 10-20 –º–∏–Ω—É—Ç\n",
    "- –°—Ç–æ–∏–º–æ—Å—Ç—å: $12-25\n",
    "- –ü–∞—Å—Å–∞–∂–∏—Ä—ã: 4-6\n",
    "```\n",
    "**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è**: –ì—Ä—É–ø–ø–æ–≤—ã–µ –ø–æ–µ–∑–¥–∫–∏, –≤–æ–∑–º–æ–∂–Ω–æ, —Ç—É—Ä–∏—Å—Ç—ã\n",
    "\n",
    "#### **–ö–ª–∞—Å—Ç–µ—Ä 4: \"–ù–æ—á–Ω—ã–µ –ø–æ–µ–∑–¥–∫–∏\"**\n",
    "```\n",
    "- –°—Ä–µ–¥–Ω–µ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: 3-7 –º–∏–ª—å\n",
    "- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 15-30 –º–∏–Ω—É—Ç  \n",
    "- –°—Ç–æ–∏–º–æ—Å—Ç—å: $20-40 (—Å –Ω–æ—á–Ω—ã–º–∏ –Ω–∞–¥–±–∞–≤–∫–∞–º–∏)\n",
    "- –ü–∞—Å—Å–∞–∂–∏—Ä—ã: 2-3\n",
    "```\n",
    "**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è**: –ü–æ–µ–∑–¥–∫–∏ –≤–µ—á–µ—Ä–æ–º/–Ω–æ—á—å—é\n",
    "\n",
    "## üí° **–ë–∏–∑–Ω–µ—Å-–∏–Ω—Å–∞–π—Ç—ã –∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏**\n",
    "\n",
    "### **–î–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –±–∏–∑–Ω–µ—Å–∞:**\n",
    "```python\n",
    "# –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "profitability = result.groupBy(\"cluster\").agg(\n",
    "    avg(\"total_amount\").alias(\"avg_revenue\"),\n",
    "    avg(\"trip_duration_minutes\").alias(\"avg_duration\"),\n",
    "    (avg(\"total_amount\") / avg(\"trip_duration_minutes\")).alias(\"revenue_per_minute\")\n",
    ").orderBy(desc(\"revenue_per_minute\"))\n",
    "\n",
    "profitability.show()\n",
    "```\n",
    "\n",
    "### **–ß—Ç–æ –º–æ–∂–Ω–æ —É–∑–Ω–∞—Ç—å:**\n",
    "\n",
    "1. **–°–∞–º—ã–µ –ø—Ä–∏–±—ã–ª—å–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã** - –∫–∞–∫–∏–µ —Ç–∏–ø—ã –ø–æ–µ–∑–¥–æ–∫ –ø—Ä–∏–Ω–æ—Å—è—Ç –±–æ–ª—å—à–µ –¥–µ–Ω–µ–≥ –≤ –º–∏–Ω—É—Ç—É\n",
    "2. **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ñ–ª–æ—Ç–∞** - –∫—É–¥–∞ –Ω–∞–ø—Ä–∞–≤–ª—è—Ç—å —Ç–∞–∫—Å–∏ –≤ —Ä–∞–∑–Ω–æ–µ –≤—Ä–µ–º—è —Å—É—Ç–æ–∫\n",
    "3. **–¶–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ** - –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ü–µ–Ω–æ–≤—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤\n",
    "4. **–ê–Ω–æ–º–∞–ª–∏–∏** - –≤—ã—è–≤–ª–µ–Ω–∏–µ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏—Ö –∏–ª–∏ –æ—à–∏–±–æ—á–Ω—ã—Ö –ø–æ–µ–∑–¥–æ–∫\n",
    "5. **–°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å** - –∫–∞–∫ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –º–µ–Ω—è—é—Ç—Å—è –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏/–≤—Ä–µ–º–µ–Ω–∏ –≥–æ–¥–∞\n",
    "\n",
    "## üö® **–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π**\n",
    "\n",
    "```python\n",
    "# –ü–æ–µ–∑–¥–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –≤–ø–∏—Å—ã–≤–∞—é—Ç—Å—è –≤ –∫–ª–∞—Å—Ç–µ—Ä—ã\n",
    "anomalies = result.filter(\n",
    "    (col(\"trip_distance\") > 50) | \n",
    "    (col(\"total_amount\") > 200) |\n",
    "    (col(\"trip_duration_minutes\") > 180)\n",
    ")\n",
    "\n",
    "print(f\"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –ø–æ–µ–∑–¥–æ–∫: {anomalies.count()}\")\n",
    "```\n",
    "\n",
    "## üìà **–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤**\n",
    "\n",
    "```python\n",
    "# –î–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ pandas\n",
    "cluster_sample = result.select(\n",
    "    \"trip_distance\", \"trip_duration_minutes\", \"total_amount\", \"cluster\"\n",
    ").sample(0.1).toPandas()\n",
    "\n",
    "# Scatter plot –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=cluster_sample, x=\"trip_distance\", y=\"total_amount\", hue=\"cluster\", palette=\"viridis\")\n",
    "plt.title(\"–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ø–æ–µ–∑–¥–æ–∫ —Ç–∞–∫—Å–∏\")\n",
    "plt.xlabel(\"–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–º–∏–ª–∏)\")\n",
    "plt.ylabel(\"–°—Ç–æ–∏–º–æ—Å—Ç—å ($)\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "## üéØ **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤**\n",
    "\n",
    "**–î–ª—è —Ç–∞–∫—Å–∏-–∫–æ–º–ø–∞–Ω–∏–∏:**\n",
    "- \"–ö–ª–∞—Å—Ç–µ—Ä 1 (–∞—ç—Ä–æ–ø–æ—Ä—Ç—ã) - —Å–∞–º—ã–π –ø—Ä–∏–±—ã–ª—å–Ω—ã–π, —É–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∞—à–∏–Ω —É –∞—ç—Ä–æ–ø–æ—Ä—Ç–æ–≤\"\n",
    "- \"–ö–ª–∞—Å—Ç–µ—Ä 3 (–≥—Ä—É–ø–ø–æ–≤—ã–µ) - –Ω–∏–∑–∫–∞—è –º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å, –≤–æ–∑–º–æ–∂–Ω–æ –≤–≤–µ—Å—Ç–∏ —Å–ø–µ—Ü—Ç–∞—Ä–∏—Ñ—ã\"\n",
    "- \"–ö–ª–∞—Å—Ç–µ—Ä 4 (–Ω–æ—á–Ω—ã–µ) - –≤—ã—Å–æ–∫–∏–µ –Ω–∞–¥–±–∞–≤–∫–∏, —Å—Ç–∏–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–¥–∏—Ç–µ–ª–µ–π —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–æ—á—å—é\"\n",
    "\n",
    "**–î–ª—è –≥–æ—Ä–æ–¥—Å–∫–æ–≥–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è:**\n",
    "- \"–ö–ª–∞—Å—Ç–µ—Ä 0 –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—ã—Å–æ–∫–∏–π —Å–ø—Ä–æ—Å –≤ —Ü–µ–Ω—Ç—Ä–µ - –Ω—É–∂–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ—è–Ω–∫–∏\"\n",
    "- \"–ö–ª–∞—Å—Ç–µ—Ä 2 –≤—ã—è–≤–ª—è–µ—Ç –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –≤ —É–ª—É—á—à–µ–Ω–∏–∏ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞ –º–µ–∂–¥—É —Ä–∞–π–æ–Ω–∞–º–∏\"\n",
    "\n",
    "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –±–∏–∑–Ω–µ—Å-–∏–Ω—Å–∞–π—Ç—ã!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d94212-95c8-4c1e-abb2-e34492281e63",
   "metadata": {},
   "source": [
    "## 1. –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Å–ª–æ–π bronze\n",
    "–í –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤–æ–∑—å–º–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–µ–∑–¥–æ–∫ –∂–µ–ª—Ç–æ–≥–æ —Ç–∞–∫—Å–∏. –î–ª—è —ç—Ç–æ–≥–æ –∑–∞—Ñ–∞—Ä–º–∏–º —Ñ–∞–π–ª—ã –æ—Ç—Å—é–¥–∞: https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "\n",
    "–°–æ–∑–¥–∞–¥–∏–º –±–∞–∫–µ—Ç `bronze` –≤ `MinIO` –∏ –Ω–∞–ø–∏—à–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–≤–æ–ª—è—Ç –¥–æ–∫–∞—á–∏–≤–∞—Ç—å —Ñ–∞–π–ª—ã —Å —É—á–µ—Ç–æ–º —É–∂–µ –∏–º–µ—é—â–∏—Ö—Å—è\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf49a8-b7b0-40cc-880a-25a038e9a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b8a21-aac4-4746-b78f-b6f68db7417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "\n",
    "# -------------------- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞–∫–∏–µ —Ñ–∞–π–ª—ã —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –Ω–∞ —Å–∞–π—Ç–µ --------------------\n",
    "\n",
    "def get_available_remote_files(base_url=\"https://d37ci6vzurychx.cloudfront.net/trip-data\",\n",
    "                               filename_template=\"yellow_tripdata_{year}-{month:02d}.parquet\",\n",
    "                               year=2024):\n",
    "    \"\"\"–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞–∫–∏–µ —Ñ–∞–π–ª—ã —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –Ω–∞ —Å–∞–π—Ç–µ\"\"\"\n",
    "    available_files = []\n",
    "    \n",
    "    print(\"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –Ω–∞ —Å–∞–π—Ç–µ...\")\n",
    "    \n",
    "    for month in tqdm(range(1, 13), desc=\"–ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Å—è—Ü–∞\"):\n",
    "        filename = filename_template.format(year=year, month=month)\n",
    "        url = f\"{base_url}/{filename}\"\n",
    "        \n",
    "        try:\n",
    "            # –î–µ–ª–∞–µ–º HEAD –∑–∞–ø—Ä–æ—Å —á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞\n",
    "            response = requests.head(url, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                available_files.append(filename)\n",
    "                print(f\"  ‚úì {filename} - –¥–æ—Å—Ç—É–ø–µ–Ω\")\n",
    "            else:\n",
    "                print(f\"  ‚úó {filename} - –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–∫–æ–¥: {response.status_code})\")\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"  ‚úó {filename} - –æ—à–∏–±–∫–∞: {e}\")\n",
    "    \n",
    "    return available_files\n",
    "\n",
    "# -------------------- –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ MinIO --------------------\n",
    "\n",
    "def get_local_minio_files(minio_client, \n",
    "                          bucket_name=\"bronze\", \n",
    "                          prefix=\"nyc-taxi-data\"):\n",
    "    \"\"\"–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ MinIO\"\"\"\n",
    "    local_files = []\n",
    "    try:\n",
    "        objects = minio_client.list_objects(bucket_name, prefix=prefix, recursive=True)\n",
    "        for obj in objects:\n",
    "            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ –ø–æ–ª–Ω–æ–≥–æ –ø—É—Ç–∏\n",
    "            filename = obj.object_name.replace(f\"{prefix}/\", \"\")\n",
    "            local_files.append(filename)\n",
    "    except S3Error as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –±–∞–∫–µ—Ç–∞: {e}\")\n",
    "    \n",
    "    return local_files\n",
    "\n",
    "# -------------------- –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–ª—å–∫–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –≤ MinIO --------------------  \n",
    "\n",
    "def download_missing_files(bucket_name=\"bronze\", \n",
    "                           prefix=\"nyc-taxi-data\",\n",
    "                           base_url=\"https://d37ci6vzurychx.cloudfront.net/trip-data\",\n",
    "                           filename_template=\"yellow_tripdata_{year}-{month:02d}.parquet\",\n",
    "                           year=2024):\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–ª—å–∫–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –≤ MinIO\"\"\"\n",
    "    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞ MinIO\n",
    "    minio_client = Minio(\n",
    "        \"minio:9000\",\n",
    "        access_key=\"minioadmin\",\n",
    "        secret_key=\"minioadmin\",\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –±–∞–∫–µ—Ç –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n",
    "    try:\n",
    "        if not minio_client.bucket_exists(bucket_name):\n",
    "            minio_client.make_bucket(bucket_name)\n",
    "            print(f\"‚úì –ë–∞–∫–µ—Ç {bucket_name} —Å–æ–∑–¥–∞–Ω\")\n",
    "    except S3Error as e:\n",
    "        return [f\"‚úó –û—à–∏–±–∫–∞ –±–∞–∫–µ—Ç–∞: {e}\"]\n",
    "    \n",
    "    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–∫–∏ —Ñ–∞–π–ª–æ–≤\n",
    "    remote_files = get_available_remote_files(base_url, filename_template, year)\n",
    "    local_files = get_local_minio_files(minio_client, bucket_name, prefix)\n",
    "    \n",
    "    # –ù–∞—Ö–æ–¥–∏–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã\n",
    "    missing_files = list(set(remote_files) - set(local_files))\n",
    "\n",
    "    # –ë–ª–æ–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "    print(f\"\\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:\")\n",
    "\n",
    "    print(f\"‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤ MinIO: {len(local_files)} —Ñ–∞–π–ª(–æ–≤)\")    \n",
    "\n",
    "    print()    \n",
    "    print(f\"‚Ä¢ –î–æ—Å—Ç—É–ø–Ω–æ –Ω–∞ —Å–∞–π—Ç–µ: {len(remote_files)} —Ñ–∞–π–ª(–æ–≤)\")\n",
    "    for file in sorted(remote_files):\n",
    "        print(f\"     - {file}\")\n",
    "\n",
    "    print()\n",
    "    if missing_files:\n",
    "        print(f\"‚Ä¢ –ò–∑ –Ω–∏—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ MinIO: {len(missing_files)} —Ñ–∞–π–ª(–æ–≤)\")\n",
    "        for file in sorted(missing_files):\n",
    "            print(f\"     - {file}\")\n",
    "    \n",
    "    if not missing_files:\n",
    "        return [\"‚úÖ –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∞–π–ª—ã —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\"]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # –°–∫–∞—á–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã\n",
    "    for filename in tqdm(missing_files, desc=\"–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö\"):\n",
    "        url = f\"{base_url}/{filename}\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, stream=True)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix='.parquet') as temp_file:\n",
    "                temp_path = temp_file.name\n",
    "                \n",
    "                # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª –Ω–∞ –¥–∏—Å–∫\n",
    "                total_size = int(response.headers.get('content-length', 0))\n",
    "                for chunk in response.iter_content(chunk_size=8192 * 8):\n",
    "                    if chunk:\n",
    "                        temp_file.write(chunk)\n",
    "            \n",
    "            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞\n",
    "            file_size = os.path.getsize(temp_path)\n",
    "            \n",
    "            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ MinIO\n",
    "            minio_client.fput_object(\n",
    "                bucket_name=bucket_name,\n",
    "                object_name=f\"{prefix}/{filename}\",\n",
    "                file_path=temp_path\n",
    "            )\n",
    "            \n",
    "            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª\n",
    "            os.unlink(temp_path)\n",
    "            \n",
    "            results.append(f\"‚úì {filename} ({file_size / (1024 * 1024):.1f} MB)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏\n",
    "            if 'temp_path' in locals():\n",
    "                try:\n",
    "                    os.unlink(temp_path)\n",
    "                except:\n",
    "                    pass\n",
    "            results.append(f\"‚úó {filename}: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# --------- –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ –≤ MinIO –∏ –Ω–∞ —Å–∞–π—Ç–µ –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –≥–æ–¥ ---------\n",
    "\n",
    "def show_current_state(bucket_name=\"bronze\", \n",
    "                       prefix=\"nyc-taxi-data\",\n",
    "                       base_url=\"https://d37ci6vzurychx.cloudfront.net/trip-data\",\n",
    "                       filename_template=\"yellow_tripdata_{year}-{month:02d}.parquet\",\n",
    "                       year=2024):\n",
    "    \"\"\"–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ñ–∞–π–ª–æ–≤\"\"\"\n",
    "    minio_client = Minio(\n",
    "        \"minio:9000\",\n",
    "        access_key=\"minioadmin\", \n",
    "        secret_key=\"minioadmin\",\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    remote_files = get_available_remote_files(base_url, filename_template, year)\n",
    "    local_files = get_local_minio_files(minio_client, bucket_name, prefix)\n",
    "    missing_files = list(set(remote_files) - set(local_files))\n",
    "    \n",
    "    print(\"\\nüìä –¢–ï–ö–£–©–ï–ï –°–û–°–¢–û–Ø–ù–ò–ï:\")\n",
    "    print(f\"‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤ MinIO: {len(local_files)} —Ñ–∞–π–ª(–æ–≤)\")\n",
    "\n",
    "    print()\n",
    "    print(f\"‚Ä¢ –î–æ—Å—Ç—É–ø–Ω–æ –Ω–∞ —Å–∞–π—Ç–µ: {len(remote_files)} —Ñ–∞–π–ª(–æ–≤)\")\n",
    "    for file in sorted(remote_files):\n",
    "        print(f\"     - {file}\")    \n",
    "\n",
    "    print()\n",
    "    print(f\"‚Ä¢ –ò–∑ –Ω–∏—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ MinIO: {len(missing_files)} —Ñ–∞–π–ª(–æ–≤)\")\n",
    "    if missing_files:\n",
    "        for file in sorted(missing_files):\n",
    "            print(f\"     - {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058d9266-3195-432c-a20e-f73b20f6e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–µ—Ä–µ–¥–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –∏ –ø–æ–ª—É—á–∞—Ç–µ–ª—è\n",
    "results = download_missing_files(\n",
    "    bucket_name=\"bronze\", \n",
    "    prefix=\"nyc-taxi-data\",\n",
    "    base_url=\"https://d37ci6vzurychx.cloudfront.net/trip-data\",\n",
    "    filename_template=\"yellow_tripdata_{year}-{month:02d}.parquet\",\n",
    "    year=2025\n",
    ")\n",
    "\n",
    "print(\"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ–∑–∞–≥—Ä—É–∑–∫–∏:\")\n",
    "for result in sorted(results):\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3334496f-dda1-4629-b987-fdae9a7e8371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ –≤ MinIO –∏ –Ω–∞ —Å–∞–π—Ç–µ –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –≥–æ–¥ \n",
    "show_current_state(bucket_name=\"bronze\", \n",
    "                   prefix=\"nyc-taxi-data\",\n",
    "                   base_url=\"https://d37ci6vzurychx.cloudfront.net/trip-data\",\n",
    "                   filename_template=\"yellow_tripdata_{year}-{month:02d}.parquet\",\n",
    "                   year=2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fefba8c-f239-4dbd-ab49-66f1409be5a3",
   "metadata": {},
   "source": [
    "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "–î–∞–Ω–Ω—ã–µ –∑–∞ —Ä–∞–∑–Ω—ã–µ –≥–æ–¥–∞ –ø—Ä–∏—Ö–æ–¥—è—Ç —Å —Ä–∞–∑–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d75dc3c4-1423-4e5c-abd1-6eb559f65232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/04 15:43:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/04 15:43:40 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "drivers = [\n",
    "    \"/home/jovyan/work/spark-jars/hadoop-aws-3.3.4.jar\",             # S3\n",
    "    \"/home/jovyan/work/spark-jars/aws-java-sdk-bundle-1.12.262.jar\", # S3\n",
    "    \"/home/jovyan/work/spark-jars/wildfly-openssl-1.0.7.Final.jar\",  # S3\n",
    "    \"/home/jovyan/work/spark-jars/postgresql-42.6.0.jar\",            # PostgreSQL\n",
    "]\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"mustdayker-Spark\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars\", \",\".join(drivers))\n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0636b4-7b27-4fb9-9b32-1d5534effaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022 = spark.read.format(\"parquet\").load(\"s3a://bronze/nyc-taxi-data/yellow_tripdata_2022-01.parquet\")\n",
    "df_2024 = spark.read.format(\"parquet\").load(\"s3a://bronze/nyc-taxi-data/yellow_tripdata_2024-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf36a436-2faa-4553-9067-20320664c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022.select(\"VendorID\", \"passenger_count\", \"trip_distance\", \"RatecodeID\", \"PULocationID\").printSchema()\n",
    "df_2024.select(\"VendorID\", \"passenger_count\", \"trip_distance\", \"RatecodeID\", \"PULocationID\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848052d7-4ec6-4f10-9916-fba20fee4799",
   "metadata": {},
   "source": [
    "# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–∏–ø–æ–≤, –∑–∞–≥—Ä—É–∑–∫–∞ –≤ `silver`\n",
    "\n",
    "–î–ª—è —Ç–æ–≥–æ —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –∑–∞–≥—Ä—É–∂–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –µ–¥–∏–Ω—ã–π –º–∞—Å—Å–∏–≤ –Ω–∞–ø–∏—à–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏.\n",
    "\n",
    "–§—É–Ω–∫—Ü–∏–∏ –ø—Ä–æ–≤–µ—Ä—è—é—Ç —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å—Ä–µ–∑—ã, —Å—Ä–∞–≤–Ω–∏–≤–∞—é—Ç —Å –Ω–æ–≤—ã–º–∏ –∫–æ—Ç–æ—Ä—ã–µ –ø–æ—è–≤–∏–ª–∏—Å—å –≤ Bronze –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Å—Ä–µ—Ö—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412506e-a7ac-425b-a415-c5c4f6343b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "import re\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "import time\n",
    "\n",
    "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è MinIO\n",
    "MINIO_ENDPOINT = 'minio:9000'  # –∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à endpoint\n",
    "MINIO_ACCESS_KEY = 'minioadmin'\n",
    "MINIO_SECRET_KEY = 'minioadmin'\n",
    "MINIO_BUCKET_BRONZE = 'bronze'\n",
    "MINIO_BUCKET_SILVER = 'silver'\n",
    "\n",
    "def get_minio_client():\n",
    "    \"\"\"–°–æ–∑–¥–∞–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–ª–∏–µ–Ω—Ç MinIO\"\"\"\n",
    "    return Minio(\n",
    "        MINIO_ENDPOINT,\n",
    "        access_key=MINIO_ACCESS_KEY,\n",
    "        secret_key=MINIO_SECRET_KEY,\n",
    "        secure=False  # –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ True –¥–ª—è HTTPS\n",
    "    )\n",
    "\n",
    "def extract_month_from_filename(file_path):\n",
    "    \"\"\"–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Å—è—Ü –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM\"\"\"\n",
    "    match = re.search(r'(\\d{4}-\\d{2})', file_path)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def get_processed_slices():\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—Ä–µ–∑–æ–≤ –∏–∑ Silver –∏—Å–ø–æ–ª—å–∑—É—è MinIO\"\"\"\n",
    "    try:\n",
    "        client = get_minio_client()\n",
    "        processed_slices = set()\n",
    "        \n",
    "        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –ø—Ä–µ—Ñ–∏–∫—Å–µ nyc-taxi-data/\n",
    "        objects = client.list_objects(MINIO_BUCKET_SILVER, prefix=\"nyc-taxi-data/\", recursive=True)\n",
    "        \n",
    "        for obj in objects:\n",
    "            # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Å—è—Ü –∏–∑ –ø—É—Ç–∏\n",
    "            month = extract_month_from_filename(obj.object_name)\n",
    "            if month:\n",
    "                processed_slices.add(month)\n",
    "        \n",
    "        print(f\"üìÅ –ù–∞–π–¥–µ–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—Ä–µ–∑–æ–≤ –≤ Silver: {len(processed_slices)}\")\n",
    "        return processed_slices\n",
    "        \n",
    "    except S3Error as e:\n",
    "        if e.code == 'NoSuchBucket':\n",
    "            print(\"‚ö†Ô∏è –ë–∞–∫–µ—Ç Silver –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—É—Å—Ç–æ–π\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ Silver —Å–ª–æ—è: {e}\")\n",
    "        return set()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å Silver —Å–ª–æ–π: {e}\")\n",
    "        return set()\n",
    "\n",
    "def get_bronze_files_with_months():\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –∏–∑ Bronze —Å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–º–∏ –º–µ—Å—è—Ü–∞–º–∏ –∏—Å–ø–æ–ª—å–∑—É—è MinIO\"\"\"\n",
    "    try:\n",
    "        client = get_minio_client()\n",
    "        bronze_files = []\n",
    "        \n",
    "        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –ø—Ä–µ—Ñ–∏–∫—Å–µ nyc-taxi-data/\n",
    "        objects = client.list_objects(MINIO_BUCKET_BRONZE, prefix=\"nyc-taxi-data/\", recursive=True)\n",
    "        \n",
    "        for obj in objects:\n",
    "            if obj.object_name.endswith('.parquet'):\n",
    "                month = extract_month_from_filename(obj.object_name)\n",
    "                if month:\n",
    "                    # –§–æ—Ä–º–∏—Ä—É–µ–º S3 –ø—É—Ç—å –¥–ª—è Spark\n",
    "                    s3_path = f\"s3a://{MINIO_BUCKET_BRONZE}/{obj.object_name}\"\n",
    "                    bronze_files.append({\n",
    "                        'path': s3_path,\n",
    "                        'month': month,\n",
    "                        'file_name': obj.object_name.split('/')[-1]\n",
    "                    })\n",
    "        \n",
    "        print(f\"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –≤ Bronze: {len(bronze_files)}\")\n",
    "        return bronze_files\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ Bronze —Å–ª–æ—è: {e}\")\n",
    "        return []\n",
    "\n",
    "def standardize_nyc_taxi_data(input_path, output_path):\n",
    "    \"\"\"\n",
    "    –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ NYC Taxi (–≤–∞—à–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)\n",
    "    \"\"\"\n",
    "    output_path = output_path.replace('.parquet', '')\n",
    "    \n",
    "    # –ß–∏—Ç–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "    df = spark.read.parquet(input_path)\n",
    "    \n",
    "    # 1. –ü—Ä–∏–≤–æ–¥–∏–º –≤—Å–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É\n",
    "    for col_name in df.columns:\n",
    "        df = df.withColumnRenamed(col_name, col_name.lower())\n",
    "    \n",
    "    # 2. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–ø–ø–∏–Ω–≥ —Ç–∏–ø–æ–≤ –¥–ª—è —É–Ω–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "    type_mapping = {\n",
    "        \"vendorid\": IntegerType(),\n",
    "        \"pulocationid\": IntegerType(), \n",
    "        \"dolocationid\": IntegerType(),\n",
    "        \"payment_type\": IntegerType(),\n",
    "        \"ratecodeid\": IntegerType(),\n",
    "        \"passenger_count\": IntegerType(),\n",
    "        \"fare_amount\": DoubleType(),\n",
    "        \"extra\": DoubleType(),\n",
    "        \"mta_tax\": DoubleType(),\n",
    "        \"tip_amount\": DoubleType(),\n",
    "        \"tolls_amount\": DoubleType(),\n",
    "        \"improvement_surcharge\": DoubleType(),\n",
    "        \"total_amount\": DoubleType(),\n",
    "        \"congestion_surcharge\": DoubleType(),\n",
    "        \"airport_fee\": DoubleType(),\n",
    "        \"cbd_congestion_fee\": DoubleType(),\n",
    "        \"trip_distance\": DoubleType()\n",
    "    }\n",
    "    \n",
    "    # 3. –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫\n",
    "    for col_name, target_type in type_mapping.items():\n",
    "        if col_name in df.columns:\n",
    "            df = df.withColumn(\n",
    "                col_name, \n",
    "                F.coalesce(\n",
    "                    F.col(col_name).cast(target_type), \n",
    "                    F.lit(0 if target_type == IntegerType() else 0.0)\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    # 4. –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è consistency\n",
    "    expected_columns = [\n",
    "        \"vendorid\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\",\n",
    "        \"passenger_count\", \"trip_distance\", \"ratecodeid\", \"store_and_fwd_flag\",\n",
    "        \"pulocationid\", \"dolocationid\", \"payment_type\", \"fare_amount\", \"extra\",\n",
    "        \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"improvement_surcharge\",\n",
    "        \"total_amount\", \"congestion_surcharge\", \"airport_fee\", \"cbd_congestion_fee\"\n",
    "    ]\n",
    "    \n",
    "    # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ\n",
    "    final_columns = [col for col in expected_columns if col in df.columns]\n",
    "    df_standardized = df.select(final_columns)\n",
    "    \n",
    "    # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏\n",
    "    (df_standardized\n",
    "     .coalesce(1)\n",
    "     .write\n",
    "     .mode(\"overwrite\")\n",
    "     .option(\"compression\", \"snappy\")\n",
    "     .parquet(output_path)\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {input_path} -> {output_path}\")\n",
    "    return df_standardized\n",
    "\n",
    "def process_incremental_nyc_taxi_files():\n",
    "    \"\"\"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã NYC Taxi –∏–∑ Bronze –≤ Silver\"\"\"\n",
    "    \n",
    "    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ MinIO\n",
    "    processed_slices = get_processed_slices()\n",
    "    bronze_files = get_bronze_files_with_months()\n",
    "    \n",
    "    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã\n",
    "    new_files = [f for f in bronze_files if f['month'] not in processed_slices]\n",
    "    \n",
    "    print(f\"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
    "    print(f\"   - –í—Å–µ–≥–æ –≤ Bronze: {len(bronze_files)}\")\n",
    "    print(f\"   - –£–∂–µ –≤ Silver: {len(processed_slices)}\") \n",
    "    print(f\"   - –ù–æ–≤—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(new_files)}\")\n",
    "    \n",
    "    if not new_files:\n",
    "        print(\"üéâ –í—Å–µ —Å—Ä–µ–∑—ã —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã! –ù–∏—á–µ–≥–æ –¥–µ–ª–∞—Ç—å –Ω–µ –Ω—É–∂–Ω–æ.\")\n",
    "        return\n",
    "    \n",
    "    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã\n",
    "    for i, file_info in enumerate(new_files, 1):\n",
    "        input_path = file_info['path']\n",
    "        file_name = file_info['file_name']\n",
    "        output_path = f\"s3a://{MINIO_BUCKET_SILVER}/nyc-taxi-data/{file_name.replace('.parquet', '')}\"\n",
    "        \n",
    "        print(f\"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –Ω–æ–≤—ã–π —Å—Ä–µ–∑ ({i}/{len(new_files)}): {file_info['month']}\")\n",
    "        \n",
    "        try:\n",
    "            standardize_nyc_taxi_data(input_path, output_path)\n",
    "            print(f\"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {file_info['month']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_info['month']}: {e}\")\n",
    "    \n",
    "    print(f\"üéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(new_files)} –Ω–æ–≤—ã—Ö —Å—Ä–µ–∑–æ–≤.\")\n",
    "\n",
    "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ - –ø—Ä–æ—Å–º–æ—Ç—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –±–∞–∫–µ—Ç–æ–≤\n",
    "def inspect_buckets():\n",
    "    \"\"\"–§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ - –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –±–∞–∫–µ—Ç–æ–≤\"\"\"\n",
    "    try:\n",
    "        client = get_minio_client()\n",
    "        \n",
    "        print(\"üîç –ò–Ω—Å–ø–µ–∫—Ü–∏—è Bronze –±–∞–∫–µ—Ç–∞:\")\n",
    "        bronze_objects = client.list_objects(MINIO_BUCKET_BRONZE, prefix=\"nyc-taxi-data/\", recursive=True)\n",
    "        for obj in bronze_objects:\n",
    "            print(f\"   Bronze: {obj.object_name}\")\n",
    "        \n",
    "        print(\"üîç –ò–Ω—Å–ø–µ–∫—Ü–∏—è Silver –±–∞–∫–µ—Ç–∞:\")\n",
    "        silver_objects = client.list_objects(MINIO_BUCKET_SILVER, prefix=\"nyc-taxi-data/\", recursive=True)\n",
    "        for obj in silver_objects:\n",
    "            print(f\"   Silver: {obj.object_name}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω—Å–ø–µ–∫—Ü–∏–∏ –±–∞–∫–µ—Ç–æ–≤: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067e63cb-63d8-426e-8145-6a9bcbd5476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–ª—è –æ—Ç–ª–∞–¥–∫–∏ —Å–Ω–∞—á–∞–ª–∞ –ø–æ—Å–º–æ—Ç—Ä–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –±–∞–∫–µ—Ç–æ–≤\n",
    "# inspect_buckets()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É\n",
    "process_incremental_nyc_taxi_files()\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {execution_time:.4f} —Å–µ–∫—É–Ω–¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe03ce78-27dc-4043-b15e-80e2f4f1bd2f",
   "metadata": {},
   "source": [
    "# –†–∞–±–æ—Ç–∞ —Å–æ —Å–ª–æ–µ–º Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccdd46a1-71dd-41db-b4af-0c2546be7a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "      .format(\"parquet\")\n",
    "      .load(\"s3a://silver/nyc-taxi-data/yellow_tripdata_2022-*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f49f87d-75a9-4e90-bbe2-08537bc2507c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39656098"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52685ec2-ef44-470d-803f-bddb9b3d2c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, date_format, count, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77ee986a-ddf7-49db-874e-ebbb8a633113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ï—Å–ª–∏ –ø–æ–ª–µ —É–∂–µ –∏–º–µ–µ—Ç —Ç–∏–ø timestamp/date\n",
    "result = (df\n",
    "         .filter(year(\"tpep_pickup_datetime\") == 2025)          \n",
    "         .withColumn(\"year\", year(\"tpep_pickup_datetime\"))\n",
    "         .withColumn(\"month\", date_format(\"tpep_pickup_datetime\", \"MM\"))  # \"MM\" –≤–µ—Ä–Ω–µ—Ç 01, 02, 03...\n",
    "         .groupBy(\"year\", \"month\")\n",
    "         .agg(count(\"*\").alias(\"record_count\"))\n",
    "         .orderBy(\"year\", \"month\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c128ae9-3a45-47a7-ae84-d591990ba8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:=====>                                                   (1 + 9) / 10]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------+\n",
      "|year|month|record_count|\n",
      "+----+-----+------------+\n",
      "|2025|   01|     3475234|\n",
      "|2025|   02|     3577542|\n",
      "|2025|   03|     4145229|\n",
      "|2025|   04|     3970568|\n",
      "|2025|   05|     4591844|\n",
      "|2025|   06|     4322949|\n",
      "|2025|   07|     3898971|\n",
      "|2025|   08|     3574080|\n",
      "|2025|   09|     4251009|\n",
      "|2025|   10|           1|\n",
      "+----+-----+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "result.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e250179-8a64-4993-b069-7de85193f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcb766b6-4eeb-4e57-94f3-f12f0c4b41ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 49:==============================================>         (10 + 2) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       null_count  total_count  null_pct\n",
      "vendorid                        0     39656098      0.00\n",
      "tpep_pickup_datetime            0     39656098      0.00\n",
      "tpep_dropoff_datetime           0     39656098      0.00\n",
      "passenger_count                 0     39656098      0.00\n",
      "trip_distance                   0     39656098      0.00\n",
      "ratecodeid                      0     39656098      0.00\n",
      "store_and_fwd_flag        1368303     39656098      3.45\n",
      "pulocationid                    0     39656098      0.00\n",
      "dolocationid                    0     39656098      0.00\n",
      "payment_type                    0     39656098      0.00\n",
      "fare_amount                     0     39656098      0.00\n",
      "extra                           0     39656098      0.00\n",
      "mta_tax                         0     39656098      0.00\n",
      "tip_amount                      0     39656098      0.00\n",
      "tolls_amount                    0     39656098      0.00\n",
      "improvement_surcharge           0     39656098      0.00\n",
      "total_amount                    0     39656098      0.00\n",
      "congestion_surcharge            0     39656098      0.00\n",
      "airport_fee                     0     39656098      0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "# –°—á–∏—Ç–∞–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "null_counts = df.agg(*[\n",
    "    sum(col(c).isNull().cast(\"int\")).alias(c) \n",
    "    for c in df.columns\n",
    "])\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ pandas –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "null_counts_pd = null_counts.toPandas().T\n",
    "null_counts_pd.columns = ['null_count']\n",
    "null_counts_pd['total_count'] = df.count()\n",
    "null_counts_pd['null_pct'] = (null_counts_pd['null_count'] / null_counts_pd['total_count'] * 100).round(2)\n",
    "\n",
    "print(null_counts_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb0934-8067-43cd-af90-1b3718ae7345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
