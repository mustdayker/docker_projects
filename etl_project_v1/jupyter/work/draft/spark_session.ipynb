{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "797f1f2e-7776-487b-9831-7f83df98b9d1",
   "metadata": {},
   "source": [
    "# Стандартная сессия\n",
    "- с поддержкой MinIO и Postgres и с конфигом из `spark-defaults`\n",
    "- Все параметры прописаны в `\"\\etl_project_v1\\spark\\conf\\spark-defaults.conf\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bfe093-caf6-4f29-b23e-feae4740985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "drivers = [\n",
    "    \"/home/jovyan/work/spark-jars/hadoop-aws-3.3.4.jar\",             # S3\n",
    "    \"/home/jovyan/work/spark-jars/aws-java-sdk-bundle-1.12.262.jar\", # S3\n",
    "    \"/home/jovyan/work/spark-jars/wildfly-openssl-1.0.7.Final.jar\",  # S3\n",
    "    \"/home/jovyan/work/spark-jars/postgresql-42.6.0.jar\",            # PostgreSQL\n",
    "]\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"mustdayker-Spark\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars\", \",\".join(drivers))\n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb084ba-caee-4aa1-ad1f-362b53c51891",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7e3728-c89b-4b95-9e4a-e7bb68a203a0",
   "metadata": {},
   "source": [
    "### Дополнительные параметры конфигурации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438c9e27-63ad-40d2-a058-188f217f219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополнительные оптимизации для \"Full Power\"\n",
    "spark = (SparkSession.builder    \n",
    "         .appName(\"Optimized for i5-14600K\").master(\"spark://spark-master:7077\")\n",
    "         .config(\"spark.sql.adaptive.enabled\", \"true\")          # Адаптивное выполнение запросов\n",
    "         .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") # Объединение партиций\n",
    "         .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") # Быстрая сериализация\n",
    "         .config(\"spark.sql.shuffle.partitions\", \"200\")         # Партиции для шаффлинга\n",
    "         .config(\"spark.default.parallelism\", \"40\")             # Параллелизм по умолчанию\n",
    "\n",
    "# Конфигурация Spark для вашего железа:\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"Optimized for i5-14600K\").master(\"spark://spark-master:7077\")\n",
    "         .config(\"spark.executor.instances\", \"2\")  \n",
    "         .config(\"spark.executor.cores\", \"8\")      # Оставляем 2 ядра на систему\n",
    "         .config(\"spark.executor.memory\", \"14g\")   # Оставляем 4GB на систему\n",
    "         .config(\"spark.driver.memory\", \"8g\")      # Увеличиваем для больших collect()\n",
    "         .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "         .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "         .config(\"spark.sql.adaptive.advisoryPartitionSizeInBytes\", \"128MB\")\n",
    "         .config(\"spark.sql.shuffle.partitions\", \"100\")  # 8 cores × 2 workers × 6 = 96\n",
    "         .config(\"spark.default.parallelism\", \"96\")\n",
    "         .config(\"spark.memory.fraction\", \"0.8\")\n",
    "         .config(\"spark.memory.storageFraction\", \"0.3\")\n",
    "         .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189019ec-6378-411b-ac75-2029fa393018",
   "metadata": {},
   "source": [
    "### Вывести текущую конфигурацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5498b960-66f0-40a5-a0b1-9863720d1299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "conf      = spark.sparkContext.getConf()\n",
    "config_df = pd.DataFrame(conf.getAll(), columns=['Key', 'Value'])\n",
    "config_df = config_df.sort_values('Key').reset_index(drop=True)\n",
    "config_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0180520-4c13-4ca0-b3a7-544df52b691c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b48f26e-3453-4755-a9f1-6d179b2fff54",
   "metadata": {},
   "source": [
    "# Spark сессия с максимальной производительностью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf2c84-cc02-44c4-8be7-d3c41904a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"Full Power\")\n",
    "         .master(\"spark://spark-master:7077\")\n",
    "         .config(\"spark.executor.instances\", \"2\")\n",
    "         .config(\"spark.executor.cores\", \"10\")\n",
    "         .config(\"spark.executor.memory\", \"16g\")\n",
    "         .config(\"spark.driver.memory\", \"4g\")\n",
    "         .config(\"spark.cores.max \", \"20\")\n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e92dad-a234-4a4a-b2b7-b0e38057a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe995d1-f7f0-49b8-9a9c-55edb81f00b9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0727377-116f-4aad-912e-bb97193bcfb4",
   "metadata": {},
   "source": [
    "# Коннектор к `MinIO`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d3da70-4079-403f-92f1-e24ea018886c",
   "metadata": {},
   "source": [
    "### Использовать конфиг `MinIO` из `\"\\etl_project_v1\\spark\\conf\\spark-defaults.conf\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f13db5-47f5-441d-b635-71ae5f9781e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "drivers = [\n",
    "    \"/home/jovyan/work/spark-jars/hadoop-aws-3.3.4.jar\",             # S3\n",
    "    \"/home/jovyan/work/spark-jars/aws-java-sdk-bundle-1.12.262.jar\", # S3\n",
    "    \"/home/jovyan/work/spark-jars/wildfly-openssl-1.0.7.Final.jar\",  # S3\n",
    "]\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"MinIO Test\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars\", \",\".join(drivers))\n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50bb7f0-f3ce-4037-b894-188ae905cfdc",
   "metadata": {},
   "source": [
    "### Скачать дравера из интернета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2585304-472f-48a7-9831-e3084336194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName(\"MinIO Test\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars.packages\", \n",
    "                 \"org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262\")     \n",
    "         .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\")\n",
    "         .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
    "         .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "         .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \n",
    "         .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \n",
    "         .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295f0738-f099-4383-a4a6-ad0e26707fef",
   "metadata": {},
   "source": [
    "### Использовать скачанное из `\"/home/jovyan/work/spark-jars\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a360ee9-e85d-485e-a008-078161fa0e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "drivers = [\n",
    "    \"/home/jovyan/work/spark-jars/hadoop-aws-3.3.4.jar\",             # S3\n",
    "    \"/home/jovyan/work/spark-jars/aws-java-sdk-bundle-1.12.262.jar\", # S3\n",
    "    \"/home/jovyan/work/spark-jars/wildfly-openssl-1.0.7.Final.jar\",  # S3\n",
    "]\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"MinIO Test\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars\", \",\".join(drivers))\n",
    "         .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\")\n",
    "         .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
    "         .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "         .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \n",
    "         .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \n",
    "         .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e9a8b7-2651-497e-98bf-c33ec912bba3",
   "metadata": {},
   "source": [
    "### Проверить запись"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6870b62-e099-4f26-805f-95b44631f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(10)\n",
    "df.write.mode(\"overwrite\").csv(\"s3a://learn-bucket/test_22\")\n",
    "print(\"✅ Успешно!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b9336-099f-4a64-95a1-cf77e4f31b89",
   "metadata": {},
   "source": [
    "## Файловая сессия с MinIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93e0beb4-368b-4383-a4fe-80b98a6abdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доступные бакеты: ['bronze', 'gold', 'silver', 'test']\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3_client = boto3.client('s3',\n",
    "    endpoint_url='http://minio:9000',\n",
    "    aws_access_key_id='minioadmin',\n",
    "    aws_secret_access_key='minioadmin',\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "response = s3_client.list_buckets()\n",
    "print(f\"Доступные бакеты: {[bucket['Name'] for bucket in response['Buckets']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c6ed8-c68b-45a3-9070-95298a5acb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55996fb-48a7-44c8-874e-f093fde9cbe4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5af523-75e9-4bd8-ac9d-ca5f006307e2",
   "metadata": {},
   "source": [
    "# Коннектор к `PostgreSQL`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f150bbc-7553-43d0-9520-fd289694019e",
   "metadata": {},
   "source": [
    "### Скачать из интернета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a562722b-96b7-427a-a2bb-f2f776cfceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение из PostgreSQL\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"PostgreSQL\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.5.0\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03c1f06-1b8c-4c90-9afe-ed7d046b2658",
   "metadata": {},
   "source": [
    "### Взять с локального диска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311841e3-9be9-4d41-aa04-28d5effd5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение из PostgreSQL\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"PostgreSQL\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars\", \"/home/jovyan/work/spark-jars/postgresql-42.6.0.jar\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509449e1-d3d2-4eec-b134-926a75811772",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f50c2f6-ecc4-4818-9f2c-c0336d510200",
   "metadata": {},
   "source": [
    "# Качаем драйвера один раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5afdb96-beff-46c9-b17e-7a87990fa559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def download_spark_jars():\n",
    "    \"\"\"Скачивает необходимые JAR файлы в папку spark-jars\"\"\"\n",
    "    \n",
    "    jars_dir = \"/home/jovyan/work/spark-jars\"\n",
    "    os.makedirs(jars_dir, exist_ok=True)\n",
    "    \n",
    "    jars = {\n",
    "        \"hadoop-aws-3.3.4.jar\": \"https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar\",\n",
    "        \"aws-java-sdk-bundle-1.12.262.jar\": \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar\",\n",
    "        \"wildfly-openssl-1.0.7.Final.jar\": \"https://repo1.maven.org/maven2/org/wildfly/openssl/wildfly-openssl/1.0.7.Final/wildfly-openssl-1.0.7.Final.jar\",\n",
    "        \"postgresql-42.6.0.jar\": \"https://jdbc.postgresql.org/download/postgresql-42.6.0.jar\"\n",
    "    }\n",
    "    \n",
    "    for filename, url in jars.items():\n",
    "        filepath = os.path.join(jars_dir, filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"📥 Скачиваем {filename}...\")\n",
    "            response = requests.get(url)\n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"✅ {filename} загружен\")\n",
    "        else:\n",
    "            print(f\"✅ {filename} уже существует\")\n",
    "\n",
    "# Запустите эту функцию один раз\n",
    "download_spark_jars()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
