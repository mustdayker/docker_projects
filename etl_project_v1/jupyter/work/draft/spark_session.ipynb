{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cadd09e-ce00-42fe-a66e-c978fce28e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b48f26e-3453-4755-a9f1-6d179b2fff54",
   "metadata": {},
   "source": [
    "# Spark сессия с максимальной производительностью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf2c84-cc02-44c4-8be7-d3c41904a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName(\"Full Power\")\n",
    "         .master(\"spark://spark-master:7077\")\n",
    "         .config(\"spark.executor.instances\", \"2\")  \n",
    "         .config(\"spark.executor.cores\", \"10\")     \n",
    "         .config(\"spark.executor.memory\", \"16g\")   \n",
    "         .config(\"spark.driver.memory\", \"4g\")      \n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856fcd9c-993e-45d5-9369-d275cef9e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(10)\n",
    "df.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7f2160-bba6-44a6-9f2e-b8a94d81a4c5",
   "metadata": {},
   "source": [
    "```python\n",
    "# Создание SparkSession с настройками для максимальной производительности\n",
    "spark = (SparkSession.builder\n",
    "         # Имя приложения для идентификации в Spark UI и логах\n",
    "         .appName(\"Full Power\")\n",
    "         \n",
    "         # Подключение к Spark кластеру\n",
    "         # spark-master:7077 - главный узел кластера, который управляет распределенными вычислениями\n",
    "         .master(\"spark://spark-master:7077\")\n",
    "         \n",
    "         # КОНФИГУРАЦИЯ ИСПОЛНИТЕЛЕЙ (EXECUTORS)\n",
    "         # Executor - процесс, выполняющий задачи на рабочих узлах кластера\n",
    "         \n",
    "         # Количество исполнителей на рабочем узле\n",
    "         # 2 исполнителя будут запущены на каждом worker node\n",
    "         # Это позволяет лучше изолировать задачи и управлять памятью\n",
    "         .config(\"spark.executor.instances\", \"2\")  \n",
    "         \n",
    "         # Количество CPU ядер на каждый исполнитель\n",
    "         # 10 ядер позволяют выполнять до 10 параллельных задач в каждом executor\n",
    "         # Оптимально для узлов с большим количеством процессорных ядер\n",
    "         .config(\"spark.executor.cores\", \"10\")     \n",
    "         \n",
    "         # Объем оперативной памяти на каждый исполнитель\n",
    "         # 16GB RAM для каждого executor процесса\n",
    "         # Включает память для выполнения задач и хранения данных в памяти\n",
    "         # Структура памяти executor:\n",
    "         # - Execution Memory (шаффлинг, joins, агрегации)\n",
    "         # - Storage Memory (кэшированные DataFrame/RDD)\n",
    "         # - User Memory (пользовательские структуры данных)\n",
    "         # - Reserved Memory (системные нужды Spark ~300MB)\n",
    "         .config(\"spark.executor.memory\", \"16g\")   \n",
    "         \n",
    "         # КОНФИГУРАЦИЯ ДРАЙВЕРА\n",
    "         # Driver - главный процесс, координирующий выполнение приложения\n",
    "         \n",
    "         # Память драйвера - 4GB для:\n",
    "         # - Хранения метаданных приложения\n",
    "         # - Сбора результатов (collect())\n",
    "         # - Broadcast переменных\n",
    "         # - Управления задачами и планирования\n",
    "         .config(\"spark.driver.memory\", \"4g\")      \n",
    "         \n",
    "         # Создание или получение существующей сессии\n",
    "         .getOrCreate()\n",
    "        )\n",
    "```\n",
    "\n",
    "## Детальное объяснение архитектуры:\n",
    "\n",
    "### **Распределение ресурсов:**\n",
    "```\n",
    "Worker Node (физическая/виртуальная машина)\n",
    "├── Executor 1 (16GB RAM, 10 cores)\n",
    "│   ├── Task Slot 1\n",
    "│   ├── Task Slot 2\n",
    "│   └── ... Task Slot 10\n",
    "└── Executor 2 (16GB RAM, 10 cores)\n",
    "    ├── Task Slot 1\n",
    "    ├── Task Slot 2\n",
    "    └── ... Task Slot 10\n",
    "```\n",
    "\n",
    "### **Производительность и масштабирование:**\n",
    "\n",
    "1. **Параллелизм задач:**\n",
    "   - Всего слотов для задач: `2 executors × 10 cores = 20 параллельных задач`\n",
    "   - Это позволяет обрабатывать до 20 партиций данных одновременно\n",
    "\n",
    "2. **Распределение памяти:**\n",
    "   ```python\n",
    "   # Примерная структура памяти executor (16GB):\n",
    "   - Spark Memory: ~60% (9.6GB)\n",
    "     * Storage Memory: кэшированные данные\n",
    "     * Execution Memory: операции шаффлинга\n",
    "   - User Memory: ~25% (4GB) - пользовательские структуры\n",
    "   - Reserved: ~5% (0.8GB) - системные нужды\n",
    "   ```\n",
    "\n",
    "3. **Рекомендации для продакшена:**\n",
    "   ```python\n",
    "   # Дополнительные оптимизации для \"Full Power\":\n",
    "   .config(\"spark.sql.adaptive.enabled\", \"true\")          # Адаптивное выполнение запросов\n",
    "   .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") # Объединение партиций\n",
    "   .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") # Быстрая сериализация\n",
    "   .config(\"spark.sql.shuffle.partitions\", \"200\")         # Партиции для шаффлинга\n",
    "   .config(\"spark.default.parallelism\", \"40\")             # Параллелизм по умолчанию\n",
    "   ```\n",
    "\n",
    "### **Типичные сценарии использования:**\n",
    "- **Обработка больших данных** (сотни GB - TB)\n",
    "- **Сложные ETL-пайплайны** с множеством преобразований\n",
    "- **Машинное обучение на больших датасетах**\n",
    "- **Аналитика в реальном времени** с высокими требованиями к производительности\n",
    "\n",
    "Такая конфигурация подходит для мощных продакшен-кластеров с значительными вычислительными ресурсами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55082922-4377-45ba-9ea9-3d2cbfe49355",
   "metadata": {},
   "source": [
    "Отличная конфигурация! С вашим железом и текущим setup вы можете обрабатывать значительные объемы данных. Давайте разберем детально:\n",
    "\n",
    "## **Текущие ресурсы кластера:**\n",
    "\n",
    "### Вычислительная мощность:\n",
    "```\n",
    "Всего в кластере:\n",
    "- 2 worker × 10 cores = 20 CPU ядер\n",
    "- 2 worker × 18GB RAM = 36GB оперативной памяти\n",
    "```\n",
    "\n",
    "### Память для обработки данных:\n",
    "```python\n",
    "# Доступная память для данных (приблизительно):\n",
    "Общая RAM: 36GB\n",
    "- Системные нужды Spark: ~2GB\n",
    "- Резерв: ~4GB\n",
    "= Доступно для данных: ~30GB\n",
    "```\n",
    "\n",
    "## **Объемы данных для обработки:**\n",
    "\n",
    "### **1. Оптимальные объемы (комфортная работа):**\n",
    "- **В памяти:** 15-25 GB данных\n",
    "- **На диске (с шаффлингом):** 50-100 GB данных\n",
    "- **Ежедневная обработка:** 200-500 GB (с разбивкой на батчи)\n",
    "\n",
    "### **2. Максимальные объемы (с оптимизацией):**\n",
    "- **Единоразово в памяти:** до 30 GB\n",
    "- **С промежуточной записью на диск:** 200-300 GB\n",
    "- **Ежедневно:** 1-2 TB (с правильным партиционированием)\n",
    "\n",
    "## **Рекомендации по оптимизации:**\n",
    "\n",
    "### Конфигурация Spark для вашего железа:\n",
    "```python\n",
    "spark = (SparkSession.builder\n",
    "    .appName(\"Optimized for i5-14600K\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .config(\"spark.executor.instances\", \"2\")  \n",
    "    .config(\"spark.executor.cores\", \"8\")      # Оставляем 2 ядра на систему\n",
    "    .config(\"spark.executor.memory\", \"14g\")   # Оставляем 4GB на систему\n",
    "    .config(\"spark.driver.memory\", \"8g\")      # Увеличиваем для больших collect()\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "    .config(\"spark.sql.adaptive.advisoryPartitionSizeInBytes\", \"128MB\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"100\")  # 8 cores × 2 workers × 6 = 96\n",
    "    .config(\"spark.default.parallelism\", \"96\")\n",
    "    .config(\"spark.memory.fraction\", \"0.8\")\n",
    "    .config(\"spark.memory.storageFraction\", \"0.3\")\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "```\n",
    "\n",
    "## **Типичные сценарии обработки:**\n",
    "\n",
    "### **1. Аналитические запросы:**\n",
    "```python\n",
    "# Мгновенная обработка: 5-10 GB\n",
    "# Запросы до 1 минуты: 10-20 GB  \n",
    "# Длительные ETL: 50-100 GB за запуск\n",
    "```\n",
    "\n",
    "### **2. Машинное обучение:**\n",
    "```python\n",
    "# Обучение моделей:\n",
    "# - До 10M строк × 100 фич: комфортно\n",
    "# - До 50M строк × 50 фич: с оптимизацией\n",
    "# - Feature engineering: 20-30 GB наборов данных\n",
    "```\n",
    "\n",
    "### **3. Стриминг данных:**\n",
    "```python\n",
    "# Потоковая обработка:\n",
    "# - До 50,000 событий/секунду\n",
    "# - Микробатчи по 10-30 секунд\n",
    "# - Окна агрегации: 1-60 минут\n",
    "```\n",
    "\n",
    "## **Мониторинг и ограничения:**\n",
    "\n",
    "### Признаки нехватки ресурсов:\n",
    "```python\n",
    "# Тревожные сигналы:\n",
    "- Frequent GC pauses (> 10% времени)\n",
    "- Spill на диск (Disk spill bytes > 0)\n",
    "- OOM errors\n",
    "- Tasks taking > 5-10 minutes\n",
    "```\n",
    "\n",
    "### Практические примеры объемов:\n",
    "```\n",
    "✅ Легко:     Анализ 10GB CSV (~100M строк)\n",
    "✅ Комфортно: ETL 50GB данных ежедневно  \n",
    "⚠️ Возможно:  Обработка 150GB с оптимизацией\n",
    "❌ Сложно:    Единовременная обработка >200GB\n",
    "```\n",
    "\n",
    "## **Рекомендации для вашего setup:**\n",
    "\n",
    "1. **Используйте партиционирование** для больших datasets\n",
    "2. **Кэшируйте часто используемые DataFrames**\n",
    "3. **Настройте правильные типы данных** (меньше памяти)\n",
    "4. **Используйте формат Parquet/ORC** вместо CSV/JSON\n",
    "5. **Мониторьте Spark UI** на портах 8085-8087\n",
    "\n",
    "Ваша система отлично подходит для серьезных data engineering задач и может обрабатывать гигабайты данных ежедневно!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0727377-116f-4aad-912e-bb97193bcfb4",
   "metadata": {},
   "source": [
    "# Коннектор к `MinIO`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2585304-472f-48a7-9831-e3084336194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName(\"MinIO Test\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars.packages\", \n",
    "                 \"org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262\")     \n",
    "         .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\")\n",
    "         .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
    "         .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "         .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \n",
    "         .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \n",
    "         .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6870b62-e099-4f26-805f-95b44631f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(10)\n",
    "df.write.mode(\"overwrite\").csv(\"s3a://learn-bucket/test-csv-33\")\n",
    "print(\"✅ Успешно!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c6ed8-c68b-45a3-9070-95298a5acb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c79079f-a42e-4f56-8efa-c55946d3e797",
   "metadata": {},
   "source": [
    "```python\n",
    "# Создание SparkSession - основной точки входа для работы с Spark\n",
    "spark = (SparkSession.builder\n",
    "         # Указываем имя приложения - будет отображаться в Spark UI\n",
    "         .appName(\"MinIO Test\")\n",
    "         \n",
    "         # Задаем URL мастер-ноды Spark кластера\n",
    "         # spark://spark-master:7077 - означает, что Spark работает в кластерном режиме\n",
    "         # spark-master - имя хоста мастер-ноды (обычно задается в Docker Compose или Kubernetes)\n",
    "         # 7077 - стандартный порт для подключения драйверов к кластеру\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         \n",
    "         # Указываем необходимые JAR-пакеты для работы с S3-совместимыми хранилищами\n",
    "         # hadoop-aws:3.3.4 - библиотека Hadoop для работы с AWS S3\n",
    "         # aws-java-sdk-bundle:1.12.262 - AWS Java SDK для клиентских операций\n",
    "         # Spark автоматически скачает эти зависимости при запуске\n",
    "         .config(\"spark.jars.packages\", \n",
    "                 \"org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262\")     \n",
    "         \n",
    "         # Настройка доступа к MinIO - логин (access key)\n",
    "         # MinIO по умолчанию использует minioadmin/minioadmin\n",
    "         .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\")\n",
    "         \n",
    "         # Настройка доступа к MinIO - пароль (secret key)\n",
    "         .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
    "         \n",
    "         # Указываем endpoint MinIO сервера\n",
    "         # http://minio:9000 - MinIO работает по HTTP на порту 9000\n",
    "         # 'minio' - имя сервиса в Docker-сети\n",
    "         .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "         \n",
    "         # Включаем path-style доступ к бакетам (требуется для MinIO)\n",
    "         # В отличие от virtual-hosted style, где бакет в домене: bucket.host.com\n",
    "         # Path-style: host.com/bucket/path/to/file\n",
    "         .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \n",
    "         \n",
    "         # Указываем реализацию файловой системы для S3\n",
    "         # S3AFileSystem - Hadoop файловая система для работы с S3-совместимыми хранилищами\n",
    "         .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \n",
    "         \n",
    "         # Отключаем SSL/TLS шифрование соединения\n",
    "         # Так как мы используем HTTP (не HTTPS) для подключения к MinIO\n",
    "         .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \n",
    "         \n",
    "         # Создаем или получаем существующий SparkSession\n",
    "         # getOrCreate() предотвращает создание дублирующихся сессий\n",
    "         .getOrCreate()\n",
    "        )\n",
    "```\n",
    "\n",
    "## Ключевые моменты конфигурации:\n",
    "\n",
    "### 1. **Архитектура подключения**\n",
    "- Spark драйвер подключается к кластеру через мастер-ноду\n",
    "- Executor'ы в кластере получат те же конфигурации S3/MinIO\n",
    "\n",
    "### 2. **Работа с MinIO**\n",
    "- MinIO эмулирует S3 API, поэтому используем S3A connector\n",
    "- Path-style access обязателен для MinIO\n",
    "- Отключен SSL т.к. используется HTTP\n",
    "\n",
    "### 3. **Зависимости**\n",
    "- `hadoop-aws` предоставляет S3A файловую систему  \n",
    "- `aws-java-sdk` обеспечивает низкоуровневые S3 операции\n",
    "\n",
    "### 4. **Безопасность в продакшене**\n",
    "```python\n",
    "# В реальных сценариях лучше использовать:\n",
    ".config(\"spark.hadoop.fs.s3a.access.key\", os.environ.get(\"AWS_ACCESS_KEY\"))\n",
    ".config(\"spark.hadoop.fs.s3a.secret.key\", os.environ.get(\"AWS_SECRET_KEY\"))\n",
    "```\n",
    "\n",
    "После создания сессии можно работать с MinIO как с обычной S3 файловой системой:\n",
    "```python\n",
    "df = spark.read.parquet(\"s3a://my-bucket/data/\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c9ee36-b123-4d67-be37-f03f6c65f3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2182356-9c43-404b-9b0c-5d9baa2c1d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
