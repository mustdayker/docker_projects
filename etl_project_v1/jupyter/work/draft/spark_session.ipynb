{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "797f1f2e-7776-487b-9831-7f83df98b9d1",
   "metadata": {},
   "source": [
    "### Сессия с поддержкой MinIO и Postgres и с конфигом из `spark-defaults`\n",
    "\n",
    "Все параметры прописаны в `\"\\etl_project_v1\\spark\\conf\\spark-defaults.conf\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bfe093-caf6-4f29-b23e-feae4740985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "drivers = [\n",
    "    \"/home/jovyan/work/spark-jars/hadoop-aws-3.3.4.jar\",             # S3\n",
    "    \"/home/jovyan/work/spark-jars/aws-java-sdk-bundle-1.12.262.jar\", # S3\n",
    "    \"/home/jovyan/work/spark-jars/wildfly-openssl-1.0.7.Final.jar\",  # S3\n",
    "    \"/home/jovyan/work/spark-jars/postgresql-42.6.0.jar\",            # PostgreSQL\n",
    "]\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"mustdayker-Spark\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars\", \",\".join(drivers))\n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad5c0a5-6c00-4ea9-87ea-be77d1ab9be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка записи в MinIO\n",
    "df = spark.range(10)\n",
    "df.write.mode(\"overwrite\").csv(\"s3a://learn-bucket/test_22\")\n",
    "print(\"✅ Успешно!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7e3728-c89b-4b95-9e4a-e7bb68a203a0",
   "metadata": {},
   "source": [
    "## Дополнительные параметры конфигурации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438c9e27-63ad-40d2-a058-188f217f219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополнительные оптимизации для \"Full Power\"\n",
    "spark = (SparkSession.builder    \n",
    "         .appName(\"Optimized for i5-14600K\").master(\"spark://spark-master:7077\")\n",
    "         .config(\"spark.sql.adaptive.enabled\", \"true\")          # Адаптивное выполнение запросов\n",
    "         .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") # Объединение партиций\n",
    "         .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") # Быстрая сериализация\n",
    "         .config(\"spark.sql.shuffle.partitions\", \"200\")         # Партиции для шаффлинга\n",
    "         .config(\"spark.default.parallelism\", \"40\")             # Параллелизм по умолчанию\n",
    "\n",
    "# Конфигурация Spark для вашего железа:\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"Optimized for i5-14600K\").master(\"spark://spark-master:7077\")\n",
    "         .config(\"spark.executor.instances\", \"2\")  \n",
    "         .config(\"spark.executor.cores\", \"8\")      # Оставляем 2 ядра на систему\n",
    "         .config(\"spark.executor.memory\", \"14g\")   # Оставляем 4GB на систему\n",
    "         .config(\"spark.driver.memory\", \"8g\")      # Увеличиваем для больших collect()\n",
    "         .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "         .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "         .config(\"spark.sql.adaptive.advisoryPartitionSizeInBytes\", \"128MB\")\n",
    "         .config(\"spark.sql.shuffle.partitions\", \"100\")  # 8 cores × 2 workers × 6 = 96\n",
    "         .config(\"spark.default.parallelism\", \"96\")\n",
    "         .config(\"spark.memory.fraction\", \"0.8\")\n",
    "         .config(\"spark.memory.storageFraction\", \"0.3\")\n",
    "         .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b48f26e-3453-4755-a9f1-6d179b2fff54",
   "metadata": {},
   "source": [
    "# Spark сессия с максимальной производительностью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf2c84-cc02-44c4-8be7-d3c41904a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"Full Power\")\n",
    "         .master(\"spark://spark-master:7077\")\n",
    "         .config(\"spark.executor.instances\", \"2\")\n",
    "         .config(\"spark.executor.cores\", \"10\")\n",
    "         .config(\"spark.executor.memory\", \"16g\")\n",
    "         .config(\"spark.driver.memory\", \"4g\")\n",
    "         .config(\"spark.cores.max \", \"20\")\n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b59ac7-c074-4fb8-bef9-4fddf4dea952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестовая задача\n",
    "df = spark.range(10000000) \\\n",
    "    .selectExpr(\"id\", \"id * 2 as value\") \\\n",
    "    .groupBy(\"id\") \\\n",
    "    .count()\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e92dad-a234-4a4a-b2b7-b0e38057a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7f2160-bba6-44a6-9f2e-b8a94d81a4c5",
   "metadata": {},
   "source": [
    "```python\n",
    "# Создание SparkSession с настройками для максимальной производительности\n",
    "spark = (SparkSession.builder\n",
    "         # Имя приложения для идентификации в Spark UI и логах\n",
    "         .appName(\"Full Power\")\n",
    "         \n",
    "         # Подключение к Spark кластеру\n",
    "         # spark-master:7077 - главный узел кластера, который управляет распределенными вычислениями\n",
    "         .master(\"spark://spark-master:7077\")\n",
    "         \n",
    "         # КОНФИГУРАЦИЯ ИСПОЛНИТЕЛЕЙ (EXECUTORS)\n",
    "         # Executor - процесс, выполняющий задачи на рабочих узлах кластера\n",
    "         \n",
    "         # Количество исполнителей на рабочем узле\n",
    "         # 2 исполнителя будут запущены на каждом worker node\n",
    "         # Это позволяет лучше изолировать задачи и управлять памятью\n",
    "         .config(\"spark.executor.instances\", \"2\")  \n",
    "         \n",
    "         # Количество CPU ядер на каждый исполнитель\n",
    "         # 10 ядер позволяют выполнять до 10 параллельных задач в каждом executor\n",
    "         # Оптимально для узлов с большим количеством процессорных ядер\n",
    "         .config(\"spark.executor.cores\", \"10\")     \n",
    "         \n",
    "         # Объем оперативной памяти на каждый исполнитель\n",
    "         # 16GB RAM для каждого executor процесса\n",
    "         # Включает память для выполнения задач и хранения данных в памяти\n",
    "         # Структура памяти executor:\n",
    "         # - Execution Memory (шаффлинг, joins, агрегации)\n",
    "         # - Storage Memory (кэшированные DataFrame/RDD)\n",
    "         # - User Memory (пользовательские структуры данных)\n",
    "         # - Reserved Memory (системные нужды Spark ~300MB)\n",
    "         .config(\"spark.executor.memory\", \"16g\")   \n",
    "         \n",
    "         # КОНФИГУРАЦИЯ ДРАЙВЕРА\n",
    "         # Driver - главный процесс, координирующий выполнение приложения\n",
    "         \n",
    "         # Память драйвера - 4GB для:\n",
    "         # - Хранения метаданных приложения\n",
    "         # - Сбора результатов (collect())\n",
    "         # - Broadcast переменных\n",
    "         # - Управления задачами и планирования\n",
    "         .config(\"spark.driver.memory\", \"4g\")      \n",
    "         \n",
    "         # Создание или получение существующей сессии\n",
    "         .getOrCreate()\n",
    "        )\n",
    "```\n",
    "\n",
    "## Детальное объяснение архитектуры:\n",
    "\n",
    "### **Распределение ресурсов:**\n",
    "```\n",
    "Worker Node (физическая/виртуальная машина)\n",
    "├── Executor 1 (16GB RAM, 10 cores)\n",
    "│   ├── Task Slot 1\n",
    "│   ├── Task Slot 2\n",
    "│   └── ... Task Slot 10\n",
    "└── Executor 2 (16GB RAM, 10 cores)\n",
    "    ├── Task Slot 1\n",
    "    ├── Task Slot 2\n",
    "    └── ... Task Slot 10\n",
    "```\n",
    "\n",
    "### **Производительность и масштабирование:**\n",
    "\n",
    "1. **Параллелизм задач:**\n",
    "   - Всего слотов для задач: `2 executors × 10 cores = 20 параллельных задач`\n",
    "   - Это позволяет обрабатывать до 20 партиций данных одновременно\n",
    "\n",
    "2. **Распределение памяти:**\n",
    "   ```python\n",
    "   # Примерная структура памяти executor (16GB):\n",
    "   - Spark Memory: ~60% (9.6GB)\n",
    "     * Storage Memory: кэшированные данные\n",
    "     * Execution Memory: операции шаффлинга\n",
    "   - User Memory: ~25% (4GB) - пользовательские структуры\n",
    "   - Reserved: ~5% (0.8GB) - системные нужды\n",
    "   ```\n",
    "\n",
    "3. **Рекомендации для продакшена:**\n",
    "   ```python\n",
    "   # Дополнительные оптимизации для \"Full Power\":\n",
    "   .config(\"spark.sql.adaptive.enabled\", \"true\")          # Адаптивное выполнение запросов\n",
    "   .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") # Объединение партиций\n",
    "   .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") # Быстрая сериализация\n",
    "   .config(\"spark.sql.shuffle.partitions\", \"200\")         # Партиции для шаффлинга\n",
    "   .config(\"spark.default.parallelism\", \"40\")             # Параллелизм по умолчанию\n",
    "   ```\n",
    "\n",
    "### **Типичные сценарии использования:**\n",
    "- **Обработка больших данных** (сотни GB - TB)\n",
    "- **Сложные ETL-пайплайны** с множеством преобразований\n",
    "- **Машинное обучение на больших датасетах**\n",
    "- **Аналитика в реальном времени** с высокими требованиями к производительности\n",
    "\n",
    "Такая конфигурация подходит для мощных продакшен-кластеров с значительными вычислительными ресурсами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55082922-4377-45ba-9ea9-3d2cbfe49355",
   "metadata": {},
   "source": [
    "Отличная конфигурация! С вашим железом и текущим setup вы можете обрабатывать значительные объемы данных. Давайте разберем детально:\n",
    "\n",
    "## **Текущие ресурсы кластера:**\n",
    "\n",
    "### Вычислительная мощность:\n",
    "```\n",
    "Всего в кластере:\n",
    "- 2 worker × 10 cores = 20 CPU ядер\n",
    "- 2 worker × 18GB RAM = 36GB оперативной памяти\n",
    "```\n",
    "\n",
    "### Память для обработки данных:\n",
    "```python\n",
    "# Доступная память для данных (приблизительно):\n",
    "Общая RAM: 36GB\n",
    "- Системные нужды Spark: ~2GB\n",
    "- Резерв: ~4GB\n",
    "= Доступно для данных: ~30GB\n",
    "```\n",
    "\n",
    "## **Объемы данных для обработки:**\n",
    "\n",
    "### **1. Оптимальные объемы (комфортная работа):**\n",
    "- **В памяти:** 15-25 GB данных\n",
    "- **На диске (с шаффлингом):** 50-100 GB данных\n",
    "- **Ежедневная обработка:** 200-500 GB (с разбивкой на батчи)\n",
    "\n",
    "### **2. Максимальные объемы (с оптимизацией):**\n",
    "- **Единоразово в памяти:** до 30 GB\n",
    "- **С промежуточной записью на диск:** 200-300 GB\n",
    "- **Ежедневно:** 1-2 TB (с правильным партиционированием)\n",
    "\n",
    "## **Рекомендации по оптимизации:**\n",
    "\n",
    "### Конфигурация Spark для вашего железа:\n",
    "```python\n",
    "spark = (SparkSession.builder\n",
    "    .appName(\"Optimized for i5-14600K\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .config(\"spark.executor.instances\", \"2\")  \n",
    "    .config(\"spark.executor.cores\", \"8\")      # Оставляем 2 ядра на систему\n",
    "    .config(\"spark.executor.memory\", \"14g\")   # Оставляем 4GB на систему\n",
    "    .config(\"spark.driver.memory\", \"8g\")      # Увеличиваем для больших collect()\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "    .config(\"spark.sql.adaptive.advisoryPartitionSizeInBytes\", \"128MB\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"100\")  # 8 cores × 2 workers × 6 = 96\n",
    "    .config(\"spark.default.parallelism\", \"96\")\n",
    "    .config(\"spark.memory.fraction\", \"0.8\")\n",
    "    .config(\"spark.memory.storageFraction\", \"0.3\")\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "```\n",
    "\n",
    "## **Типичные сценарии обработки:**\n",
    "\n",
    "### **1. Аналитические запросы:**\n",
    "```python\n",
    "# Мгновенная обработка: 5-10 GB\n",
    "# Запросы до 1 минуты: 10-20 GB  \n",
    "# Длительные ETL: 50-100 GB за запуск\n",
    "```\n",
    "\n",
    "### **2. Машинное обучение:**\n",
    "```python\n",
    "# Обучение моделей:\n",
    "# - До 10M строк × 100 фич: комфортно\n",
    "# - До 50M строк × 50 фич: с оптимизацией\n",
    "# - Feature engineering: 20-30 GB наборов данных\n",
    "```\n",
    "\n",
    "### **3. Стриминг данных:**\n",
    "```python\n",
    "# Потоковая обработка:\n",
    "# - До 50,000 событий/секунду\n",
    "# - Микробатчи по 10-30 секунд\n",
    "# - Окна агрегации: 1-60 минут\n",
    "```\n",
    "\n",
    "## **Мониторинг и ограничения:**\n",
    "\n",
    "### Признаки нехватки ресурсов:\n",
    "```python\n",
    "# Тревожные сигналы:\n",
    "- Frequent GC pauses (> 10% времени)\n",
    "- Spill на диск (Disk spill bytes > 0)\n",
    "- OOM errors\n",
    "- Tasks taking > 5-10 minutes\n",
    "```\n",
    "\n",
    "### Практические примеры объемов:\n",
    "```\n",
    "✅ Легко:     Анализ 10GB CSV (~100M строк)\n",
    "✅ Комфортно: ETL 50GB данных ежедневно  \n",
    "⚠️ Возможно:  Обработка 150GB с оптимизацией\n",
    "❌ Сложно:    Единовременная обработка >200GB\n",
    "```\n",
    "\n",
    "## **Рекомендации для вашего setup:**\n",
    "\n",
    "1. **Используйте партиционирование** для больших datasets\n",
    "2. **Кэшируйте часто используемые DataFrames**\n",
    "3. **Настройте правильные типы данных** (меньше памяти)\n",
    "4. **Используйте формат Parquet/ORC** вместо CSV/JSON\n",
    "5. **Мониторьте Spark UI** на портах 8085-8087\n",
    "\n",
    "Ваша система отлично подходит для серьезных data engineering задач и может обрабатывать гигабайты данных ежедневно!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0727377-116f-4aad-912e-bb97193bcfb4",
   "metadata": {},
   "source": [
    "# Коннектор к `MinIO`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d3da70-4079-403f-92f1-e24ea018886c",
   "metadata": {},
   "source": [
    "### Использовать конфиг `MinIO` из `\"\\etl_project_v1\\spark\\conf\\spark-defaults.conf\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f13db5-47f5-441d-b635-71ae5f9781e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "drivers = [\n",
    "    \"/home/jovyan/work/spark-jars/hadoop-aws-3.3.4.jar\",             # S3\n",
    "    \"/home/jovyan/work/spark-jars/aws-java-sdk-bundle-1.12.262.jar\", # S3\n",
    "    \"/home/jovyan/work/spark-jars/wildfly-openssl-1.0.7.Final.jar\",  # S3\n",
    "]\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"MinIO Test\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars\", \",\".join(drivers))\n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50bb7f0-f3ce-4037-b894-188ae905cfdc",
   "metadata": {},
   "source": [
    "### Скачать дравера из интернета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2585304-472f-48a7-9831-e3084336194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName(\"MinIO Test\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars.packages\", \n",
    "                 \"org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262\")     \n",
    "         .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\")\n",
    "         .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
    "         .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "         .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \n",
    "         .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \n",
    "         .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295f0738-f099-4383-a4a6-ad0e26707fef",
   "metadata": {},
   "source": [
    "### Использовать скачанное из `\"/home/jovyan/work/spark-jars\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a360ee9-e85d-485e-a008-078161fa0e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "drivers = [\n",
    "    \"/home/jovyan/work/spark-jars/hadoop-aws-3.3.4.jar\",             # S3\n",
    "    \"/home/jovyan/work/spark-jars/aws-java-sdk-bundle-1.12.262.jar\", # S3\n",
    "    \"/home/jovyan/work/spark-jars/wildfly-openssl-1.0.7.Final.jar\",  # S3\n",
    "]\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"MinIO Test\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars\", \",\".join(drivers))\n",
    "         .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\")\n",
    "         .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
    "         .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "         .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \n",
    "         .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \n",
    "         .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \n",
    "         .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e9a8b7-2651-497e-98bf-c33ec912bba3",
   "metadata": {},
   "source": [
    "### Проверить запись"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6870b62-e099-4f26-805f-95b44631f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(10)\n",
    "df.write.mode(\"overwrite\").csv(\"s3a://learn-bucket/test_22\")\n",
    "print(\"✅ Успешно!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c6ed8-c68b-45a3-9070-95298a5acb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c79079f-a42e-4f56-8efa-c55946d3e797",
   "metadata": {},
   "source": [
    "```python\n",
    "# Создание SparkSession - основной точки входа для работы с Spark\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"MinIO Test\")\n",
    "         \n",
    "         # Задаем URL мастер-ноды Spark кластера\n",
    "         # spark://spark-master:7077 - означает, что Spark работает в кластерном режиме\n",
    "         # spark-master - имя хоста мастер-ноды (обычно задается в Docker Compose или Kubernetes)\n",
    "         # 7077 - стандартный порт для подключения драйверов к кластеру\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         \n",
    "         # Указываем необходимые JAR-пакеты для работы с S3-совместимыми хранилищами\n",
    "         # hadoop-aws:3.3.4 - библиотека Hadoop для работы с AWS S3\n",
    "         # aws-java-sdk-bundle:1.12.262 - AWS Java SDK для клиентских операций\n",
    "         # Spark автоматически скачает эти зависимости при запуске\n",
    "         .config(\"spark.jars.packages\", \n",
    "                 \"org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262\")\n",
    "         \n",
    "         .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\")\n",
    "         .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
    "         \n",
    "         # Указываем endpoint MinIO сервера\n",
    "         # http://minio:9000 - MinIO работает по HTTP на порту 9000\n",
    "         # 'minio' - имя сервиса в Docker-сети\n",
    "         .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "         \n",
    "         # Включаем path-style доступ к бакетам (требуется для MinIO)\n",
    "         # В отличие от virtual-hosted style, где бакет в домене: bucket.host.com\n",
    "         # Path-style: host.com/bucket/path/to/file\n",
    "         .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \n",
    "         \n",
    "         # Указываем реализацию файловой системы для S3\n",
    "         # S3AFileSystem - Hadoop файловая система для работы с S3-совместимыми хранилищами\n",
    "         .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \n",
    "         \n",
    "         # Отключаем SSL/TLS шифрование соединения\n",
    "         # Так как мы используем HTTP (не HTTPS) для подключения к MinIO\n",
    "         .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "         .getOrCreate()\n",
    "        )\n",
    "```\n",
    "\n",
    "## Ключевые моменты конфигурации:\n",
    "\n",
    "### 1. **Архитектура подключения**\n",
    "- Spark драйвер подключается к кластеру через мастер-ноду\n",
    "- Executor'ы в кластере получат те же конфигурации S3/MinIO\n",
    "\n",
    "### 2. **Работа с MinIO**\n",
    "- MinIO эмулирует S3 API, поэтому используем S3A connector\n",
    "- Path-style access обязателен для MinIO\n",
    "- Отключен SSL т.к. используется HTTP\n",
    "\n",
    "### 3. **Зависимости**\n",
    "- `hadoop-aws` предоставляет S3A файловую систему  \n",
    "- `aws-java-sdk` обеспечивает низкоуровневые S3 операции\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5af523-75e9-4bd8-ac9d-ca5f006307e2",
   "metadata": {},
   "source": [
    "# Коннектор к `PostgreSQL`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f150bbc-7553-43d0-9520-fd289694019e",
   "metadata": {},
   "source": [
    "### Скачать из интернета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a562722b-96b7-427a-a2bb-f2f776cfceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение из PostgreSQL\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"PostgreSQL\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.5.0\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03c1f06-1b8c-4c90-9afe-ed7d046b2658",
   "metadata": {},
   "source": [
    "### Взять с локального диска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311841e3-9be9-4d41-aa04-28d5effd5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение из PostgreSQL\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"PostgreSQL\")\n",
    "         .master(\"spark://spark-master:7077\") \n",
    "         .config(\"spark.jars\", \"/home/jovyan/work/spark-jars/postgresql-42.6.0.jar\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e131a-79a9-40e4-9fc8-e7909c0fab2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f50c2f6-ecc4-4818-9f2c-c0336d510200",
   "metadata": {},
   "source": [
    "# Качаем драйвера один раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5afdb96-beff-46c9-b17e-7a87990fa559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def download_spark_jars():\n",
    "    \"\"\"Скачивает необходимые JAR файлы в папку spark-jars\"\"\"\n",
    "    \n",
    "    jars_dir = \"/home/jovyan/work/spark-jars\"\n",
    "    os.makedirs(jars_dir, exist_ok=True)\n",
    "    \n",
    "    jars = {\n",
    "        \"hadoop-aws-3.3.4.jar\": \"https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar\",\n",
    "        \"aws-java-sdk-bundle-1.12.262.jar\": \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar\",\n",
    "        \"wildfly-openssl-1.0.7.Final.jar\": \"https://repo1.maven.org/maven2/org/wildfly/openssl/wildfly-openssl/1.0.7.Final/wildfly-openssl-1.0.7.Final.jar\",\n",
    "        \"postgresql-42.6.0.jar\": \"https://jdbc.postgresql.org/download/postgresql-42.6.0.jar\"\n",
    "    }\n",
    "    \n",
    "    for filename, url in jars.items():\n",
    "        filepath = os.path.join(jars_dir, filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"📥 Скачиваем {filename}...\")\n",
    "            response = requests.get(url)\n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"✅ {filename} загружен\")\n",
    "        else:\n",
    "            print(f\"✅ {filename} уже существует\")\n",
    "\n",
    "# Запустите эту функцию один раз\n",
    "download_spark_jars()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eea1ca-60c4-4821-8228-f78625c5b9fd",
   "metadata": {},
   "source": [
    "### Вывести параметры конфигурации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d899d725-48ac-4c28-b1d9-b8e823035d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = spark.sparkContext.getConf()\n",
    "print(\"Executor instances:\", conf.get(\"spark.executor.instances\"))  # → 2\n",
    "print(\"Executor cores:\", conf.get(\"spark.executor.cores\"))          # → 10\n",
    "print(\"Executor memory:\", conf.get(\"spark.executor.memory\"))        # → 16g\n",
    "print(\"Driver memory:\", conf.get(\"spark.driver.memory\"))            # → 4g\n",
    "print(\"Cores max:\", conf.get(\"spark.cores.max\"))                    # → 20\n",
    "print(\"S3A endpoint:\", conf.get(\"spark.hadoop.fs.s3a.endpoint\"))    # → http://minio:9000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
