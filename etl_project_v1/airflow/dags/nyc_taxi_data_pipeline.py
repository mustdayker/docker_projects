from airflow import DAG
from airflow.operators.python import PythonOperator

from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
from airflow.operators.bash import BashOperator

from datetime import datetime, timedelta
from minio import Minio
from minio.error import S3Error
import requests
from tqdm import tqdm
import os
import tempfile


# -------------------- –§—É–Ω–∫—Ü–∏–∏ –∏–∑ –≤–∞—à–µ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞ --------------------

def get_available_remote_files(base_url, filename_template, year):
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞–∫–∏–µ —Ñ–∞–π–ª—ã —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –Ω–∞ —Å–∞–π—Ç–µ"""
    available_files = []

    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –Ω–∞ —Å–∞–π—Ç–µ...")

    for month in tqdm(range(1, 13), desc="–ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Å—è—Ü–∞"):
        filename = filename_template.format(year=year, month=month)
        url = f"{base_url}/{filename}"

        try:
            response = requests.head(url, timeout=10)
            if response.status_code == 200:
                available_files.append(filename)
                print(f"  ‚úì {filename} - –¥–æ—Å—Ç—É–ø–µ–Ω")
            else:
                print(f"  ‚úó {filename} - –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–∫–æ–¥: {response.status_code})")

        except requests.exceptions.RequestException as e:
            print(f"  ‚úó {filename} - –æ—à–∏–±–∫–∞: {e}")

    return available_files


def get_local_minio_files(minio_client, bucket_name, prefix):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ MinIO"""
    local_files = []
    try:
        objects = minio_client.list_objects(bucket_name, prefix=prefix, recursive=True)
        for obj in objects:
            filename = obj.object_name.replace(f"{prefix}/", "")
            local_files.append(filename)
    except S3Error as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –±–∞–∫–µ—Ç–∞: {e}")

    return local_files


def download_missing_files(**kwargs):
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–ª—å–∫–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –≤ MinIO"""

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ op_kwargs
    bucket_name = kwargs.get('bucket_name', 'bronze')
    prefix = kwargs.get('prefix', 'nyc-taxi-data')
    base_url = kwargs.get('base_url', 'https://d37ci6vzurychx.cloudfront.net/trip-data')
    filename_template = kwargs.get('filename_template', 'yellow_tripdata_{year}-{month:02d}.parquet')

    # –ì–æ–¥ –∏–∑ execution context —á–µ—Ä–µ–∑ Jinja
    execution_year = kwargs.get('year')
    if not execution_year:
        # –ï—Å–ª–∏ –≥–æ–¥ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â–∏–π –≥–æ–¥ –∏–∑ execution_date
        execution_date = kwargs['execution_date']
        execution_year = execution_date.year

    print(f"üéØ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≥–æ–¥: {execution_year}")

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞ MinIO
    minio_client = Minio(
        "minio:9000",
        access_key="minioadmin",
        secret_key="minioadmin",
        secure=False
    )

    # –°–æ–∑–¥–∞–µ–º –±–∞–∫–µ—Ç –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    try:
        if not minio_client.bucket_exists(bucket_name):
            minio_client.make_bucket(bucket_name)
            print(f"‚úì –ë–∞–∫–µ—Ç {bucket_name} —Å–æ–∑–¥–∞–Ω")
    except S3Error as e:
        return [f"‚úó –û—à–∏–±–∫–∞ –±–∞–∫–µ—Ç–∞: {e}"]

    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–∫–∏ —Ñ–∞–π–ª–æ–≤
    remote_files = get_available_remote_files(base_url, filename_template, execution_year)
    local_files = get_local_minio_files(minio_client, bucket_name, prefix)

    # –ù–∞—Ö–æ–¥–∏–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã
    missing_files = list(set(remote_files) - set(local_files))

    # –ë–ª–æ–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤ MinIO: {len(local_files)} —Ñ–∞–π–ª(–æ–≤)")
    print(f"‚Ä¢ –î–æ—Å—Ç—É–ø–Ω–æ –Ω–∞ —Å–∞–π—Ç–µ: {len(remote_files)} —Ñ–∞–π–ª(–æ–≤)")

    for file in sorted(remote_files):
        print(f"     - {file}")

    print()
    if missing_files:
        print(f"‚Ä¢ –ò–∑ –Ω–∏—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ MinIO: {len(missing_files)} —Ñ–∞–π–ª(–æ–≤)")
        for file in sorted(missing_files):
            print(f"     - {file}")

    if not missing_files:
        print("‚úÖ –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∞–π–ª—ã —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        return {"status": "success", "message": "–í—Å–µ —Ñ–∞–π–ª—ã —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã", "downloaded_files": []}

    results = []
    downloaded_files = []

    # –°–∫–∞—á–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã
    for filename in tqdm(missing_files, desc="–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö"):
        url = f"{base_url}/{filename}"

        try:
            response = requests.get(url, stream=True)
            response.raise_for_status()

            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            with tempfile.NamedTemporaryFile(delete=False, suffix='.parquet') as temp_file:
                temp_path = temp_file.name

                # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª –Ω–∞ –¥–∏—Å–∫
                total_size = int(response.headers.get('content-length', 0))
                for chunk in response.iter_content(chunk_size=8192 * 8):
                    if chunk:
                        temp_file.write(chunk)

            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file_size = os.path.getsize(temp_path)

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ MinIO
            minio_client.fput_object(
                bucket_name=bucket_name,
                object_name=f"{prefix}/{filename}",
                file_path=temp_path
            )

            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            os.unlink(temp_path)

            result_msg = f"‚úì {filename} ({file_size / (1024 * 1024):.1f} MB)"
            results.append(result_msg)
            downloaded_files.append(filename)
            print(result_msg)

        except Exception as e:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            if 'temp_path' in locals():
                try:
                    os.unlink(temp_path)
                except:
                    pass
            error_msg = f"‚úó {filename}: {e}"
            results.append(error_msg)
            print(error_msg)

    return {
        "status": "success" if downloaded_files else "partial_success",
        "message": f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(downloaded_files)} –∏–∑ {len(missing_files)} —Ñ–∞–π–ª–æ–≤",
        "downloaded_files": downloaded_files,
        "details": results
    }



# -------------------- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ DAG --------------------
# -------------------- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ DAG --------------------
# -------------------- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ DAG --------------------
# -------------------- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ DAG --------------------
# -------------------- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ DAG --------------------




default_args = {
    'owner': 'mustdayker',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 0,
    'retry_delay': timedelta(minutes=5),
}

with DAG(
        'nyc_taxi_data_pipeline',
        default_args=default_args,
        description='–ü–∞–π–ø–ª–∞–π–Ω –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö NYC Taxi',
        schedule_interval='@monthly',  # –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –µ–∂–µ–º–µ—Å—è—á–Ω–æ
        start_date=datetime(2024, 1, 1),  # –ù–∞—á–∏–Ω–∞–µ–º —Å 1 —è–Ω–≤–∞—Ä—è 2024
        catchup=False,  # –ù–µ –∑–∞–ø—É—Å–∫–∞—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –¥–∞–≥–∏
        tags=['nyc_taxi', 'data_pipeline'],
) as dag:

    # -------------------  –¢–ê–°–ö–ò ------------------------
    # -------------------  –¢–ê–°–ö–ò ------------------------
    # -------------------  –¢–ê–°–ö–ò ------------------------


    download_nyc_taxi_data = PythonOperator(
        task_id='download_nyc_taxi_data',
        python_callable=download_missing_files,
        op_kwargs={
            'bucket_name': 'bronze',
            'prefix': 'nyc-taxi-data',
            'base_url': 'https://d37ci6vzurychx.cloudfront.net/trip-data',
            'filename_template': 'yellow_tripdata_{year}-{month:02d}.parquet',
            # 'year': 2024,
            # –ì–æ–¥ –±—É–¥–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥—Å—Ç–∞–≤–ª—è—Ç—å—Å—è —á–µ—Ä–µ–∑ {{ data_interval_end.year }}
        },
        provide_context=True,  # –ü–µ—Ä–µ–¥–∞–µ–º execution context –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ execution_date
    )

    spark_drivers = [
        "/opt/spark/external-jars/hadoop-aws-3.3.4.jar",
        "/opt/spark/external-jars/aws-java-sdk-bundle-1.12.262.jar",
        "/opt/spark/external-jars/wildfly-openssl-1.0.7.Final.jar",
        "/opt/spark/external-jars/postgresql-42.6.0.jar",
    ]


    bronze_to_silver_norm = SparkSubmitOperator(
        task_id='bronze_to_silver_norm',
        application='/opt/spark/apps/nyc_taxi_bronze_to_silver_norm.py',
        conn_id='spark_cluster',
        jars=','.join(spark_drivers),
        name='airflow-distributed-test',
        verbose=True,
        retries=0
    )


    silver_norm_to_eda = SparkSubmitOperator(
        task_id='silver_norm_to_eda',
        application='/opt/spark/apps/nyc_taxi_silver_norm_to_eda.py',
        conn_id='spark_cluster',
        jars=','.join(spark_drivers),
        name='airflow-distributed-test',
        verbose=True,
        retries=0
    )

    agg_write_to_postgres = SparkSubmitOperator(
        task_id='agg_write_to_postgres',
        application='/opt/spark/apps/nyc_taxi_agg_write_to_postgre.py',
        conn_id='spark_cluster',
        jars=','.join(spark_drivers),
        name='airflow-distributed-test',
        verbose=True,
        retries=0
    )

    # –ó–¥–µ—Å—å –≤ –±—É–¥—É—â–µ–º –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ —Ç–∞—Å–∫–∏:
    # - data_cleaning_task
    # - data_aggregation_task
    # - load_to_postgres_task
    # - update_superset_dashboard_task

    (
            download_nyc_taxi_data >>
            bronze_to_silver_norm >>
            silver_norm_to_eda >>
            agg_write_to_postgres
     )

# –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è DAG
dag.doc_md = """
## NYC Taxi Data Pipeline

–≠—Ç–æ—Ç DAG –∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ NYC Taxi –∏–∑ –ø—É–±–ª–∏—á–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –≤ MinIO.

### –ó–∞–¥–∞—á–∏:
1. **download_nyc_taxi_data** - –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö —Ç–∞–∫—Å–∏ NYC –∑–∞ —Ç–µ–∫—É—â–∏–π –≥–æ–¥

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≥–æ–¥ –∏–∑ execution_date
- –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞–∫–∏–µ —Ñ–∞–π–ª—ã —É–∂–µ –µ—Å—Ç—å –≤ MinIO
- –°–∫–∞—á–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ –±–∞–∫–µ—Ç `bronze` —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º `nyc-taxi-data`

### –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ:
- –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –µ–∂–µ–º–µ—Å—è—á–Ω–æ (@monthly)
"""