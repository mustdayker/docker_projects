from pyspark.sql import functions as F
from pyspark.sql.types import DoubleType, IntegerType
from pyspark.sql import SparkSession
import re
from minio import Minio
from minio.error import S3Error
import time

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è MinIO
MINIO_ENDPOINT = 'minio:9000'
MINIO_ACCESS_KEY = 'minioadmin'
MINIO_SECRET_KEY = 'minioadmin'


def get_minio_client():
    """–°–æ–∑–¥–∞–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–ª–∏–µ–Ω—Ç MinIO"""
    return Minio(
        MINIO_ENDPOINT,
        access_key=MINIO_ACCESS_KEY,
        secret_key=MINIO_SECRET_KEY,
        secure=False
    )


def extract_month_from_filename(file_path):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Å—è—Ü –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM"""
    match = re.search(r'(\d{4}-\d{2})', file_path)
    return match.group(1) if match else None


def get_processed_slices(output_bucket, output_prefix):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—Ä–µ–∑–æ–≤ –∏–∑ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –±–∞–∫–µ—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É—è MinIO"""
    try:
        client = get_minio_client()
        processed_slices = set()

        objects = client.list_objects(output_bucket, prefix=output_prefix, recursive=True)

        for obj in objects:
            month = extract_month_from_filename(obj.object_name)
            if month:
                processed_slices.add(month)

        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—Ä–µ–∑–æ–≤ –≤ {output_bucket}/{output_prefix}: {len(processed_slices)}")
        return processed_slices

    except S3Error as e:
        if e.code == 'NoSuchBucket':
            print(f"‚ö†Ô∏è –ë–∞–∫–µ—Ç {output_bucket} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—É—Å—Ç–æ–π")
        else:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {output_bucket} –±–∞–∫–µ—Ç–∞: {e}")
        return set()
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å {output_bucket} –±–∞–∫–µ—Ç: {e}")
        return set()


def get_input_files_with_months(input_bucket, input_prefix):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤/–ø–∞–ø–æ–∫ –∏–∑ –≤—Ö–æ–¥–Ω–æ–≥–æ –±–∞–∫–µ—Ç–∞ —Å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–º–∏ –º–µ—Å—è—Ü–∞–º–∏ –∏—Å–ø–æ–ª—å–∑—É—è MinIO"""
    try:
        client = get_minio_client()
        input_files = []

        objects = client.list_objects(input_bucket, prefix=input_prefix, recursive=False)

        for obj in objects:
            object_name = obj.object_name

            is_parquet_file = object_name.endswith('.parquet')
            is_folder = not is_parquet_file and object_name.endswith('/')

            if is_parquet_file or is_folder:
                month = extract_month_from_filename(object_name)
                if month:
                    s3_path = f"s3a://{input_bucket}/{object_name}"
                    input_files.append({
                        'path': s3_path,
                        'month': month,
                        'file_name': object_name.split('/')[-1] if is_parquet_file else object_name.split('/')[-2] + '/'
                    })

        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ {input_bucket}/{input_prefix}: {len(input_files)}")
        return input_files

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {input_bucket} –±–∞–∫–µ—Ç–∞: {e}")
        return []


def eda_nyc_taxi_data(spark, input_path, output_path):
    """
    –û—á–∏—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ NYC Taxi
    """
    df = spark.read.format("parquet").load(input_path)

    df_with_duration = df.withColumn(
        "trip_duration_minutes",
        (F.unix_timestamp("tpep_dropoff_datetime") - F.unix_timestamp("tpep_pickup_datetime")) / 60
    )

    # –°–æ–∑–¥–∞–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º
    df_clean = df_with_duration.filter(
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏: –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±–æ–ª—å—à–µ 1 –º–∏–Ω—É—Ç—ã –∏ –º–µ–Ω—å—à–µ –≤–µ—Ä—Ö–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü—ã
        (F.col("passenger_count") >= 0) &
        (F.col("passenger_count") <= 6) &

        (F.col("trip_duration_minutes") > 1) &
        (F.col("trip_duration_minutes") < 90) &

        # –ü–ª–∞—Ç–µ–∂–∏
        (F.col("fare_amount") > 0) &
        (F.col("fare_amount") < 110) &
        (F.col("extra") >= 0) &
        (F.col("mta_tax") >= 0) &
        (F.col("improvement_surcharge") >= 0) &
        (F.col("tip_amount") >= 0) &
        (F.col("tip_amount") < 30) &
        (F.col("tolls_amount") >= 0) &
        (F.col("tolls_amount") < 30) &
        (F.col("total_amount") > 0) &
        (F.col("total_amount") < 110) &

        (F.col("trip_distance") > 0) &
        (F.col("trip_distance") < 100) &

        (F.year("tpep_pickup_datetime") >= 2022) &
        (F.year("tpep_pickup_datetime") < 2026)
        # –î–æ–±–∞–≤—å—Ç–µ –¥—Ä—É–≥–∏–µ —É—Å–ª–æ–≤–∏—è –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    )

    # –û–±–æ–≥–∞—â–∞–µ–º

    df_clean = (df_clean
                .withColumn("date_month", F.date_trunc("month", "tpep_pickup_datetime"))
                .withColumn("year", F.year("tpep_pickup_datetime"))  # –ì–æ–¥
                .withColumn("month", F.month("tpep_pickup_datetime"))  # –ú–µ—Å—è—Ü
                .withColumn("day", F.dayofmonth("tpep_pickup_datetime"))
                .withColumn("day_of_week", F.dayofweek("tpep_pickup_datetime"))
                .withColumn("hour", F.hour("tpep_pickup_datetime"))
                .withColumn("is_weekend", F.when(F.dayofweek("tpep_pickup_datetime").isin(1, 7), 1).otherwise(0))
                .withColumn("time_of_day",
                            F.when((F.col("hour") >= 5) & (F.col("hour") < 12), "–£—Ç—Ä–æ")
                            .when((F.col("hour") >= 12) & (F.col("hour") < 17), "–î–µ–Ω—å")
                            .when((F.col("hour") >= 17) & (F.col("hour") < 21), "–í–µ—á–µ—Ä")
                            .otherwise("–ù–æ—á—å"))
                .withColumn("is_rush_hour",
                            F.when(
                                ((F.col("hour") >= 7) & (F.col("hour") <= 10)) |  # –£—Ç—Ä–µ–Ω–Ω–∏–π –ø–∏–∫
                                ((F.col("hour") >= 16) & (F.col("hour") <= 19)),  # –í–µ—á–µ—Ä–Ω–∏–π –ø–∏–∫
                                1
                            ).otherwise(0))
                .withColumn("avg_speed_kmh",
                            F.when(F.col("trip_duration_minutes") > 0,
                                   (F.col("trip_distance") * 1.60934) / (F.col("trip_duration_minutes") / 60.0)
                                   ).otherwise(None))
                .withColumn("tip_ratio", F.col("tip_amount") / F.col("fare_amount"))
                .withColumn("has_tip", F.when(F.col("tip_amount") > 0, 1).otherwise(0))  # –ë–∏–Ω–∞—Ä–Ω—ã–π —Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫
                .withColumn("revenue_per_minute",
                            F.when(F.col("trip_duration_minutes") > 0,
                                   F.col("total_amount") / F.col("trip_duration_minutes")
                                   ).otherwise(None))
                )
    # –£–¥–∞–ª—è–µ–º –ø–æ–ª—è —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–æ–ø—É—Å–∫–æ–≤
    df_clean = df_clean.drop("store_and_fwd_flag")

    print(f"–ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {df.count()}")
    print(f"–†–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {df_clean.count()}")
    print(f"–£–¥–∞–ª–µ–Ω–æ {df.count() - df_clean.count()} —Å—Ç—Ä–æ–∫ ({(1 - df_clean.count() / df.count()) * 100:.2f}%)")

    # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
    (df_clean
     .coalesce(1)
     .write
     .mode("overwrite")
     .option("compression", "snappy")
     .parquet(output_path)
     )

    print(f"‚úÖ –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {input_path} -> {output_path}")
    return df_clean


def eda_incremental_nyc_taxi_files(spark, input_bucket, input_prefix, output_bucket, output_prefix):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã NYC Taxi –∏–∑ –≤—Ö–æ–¥–Ω–æ–≥–æ –±–∞–∫–µ—Ç–∞ –≤ –≤—ã—Ö–æ–¥–Ω–æ–π"""

    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ MinIO
    processed_slices = get_processed_slices(output_bucket, output_prefix)
    input_files = get_input_files_with_months(input_bucket, input_prefix)

    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã
    new_files = [f for f in input_files if f['month'] not in processed_slices]

    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   - –í—Å–µ–≥–æ –≤–æ –≤—Ö–æ–¥–Ω–æ–º –±–∞–∫–µ—Ç–µ: {len(input_files)}")
    print(f"   - –£–∂–µ –≤ –≤—ã—Ö–æ–¥–Ω–æ–º –±–∞–∫–µ—Ç–µ: {len(processed_slices)}")
    print(f"   - –ù–æ–≤—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(new_files)}")

    if not new_files:
        print("üéâ –í—Å–µ —Å—Ä–µ–∑—ã —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã! –ù–∏—á–µ–≥–æ –¥–µ–ª–∞—Ç—å –Ω–µ –Ω—É–∂–Ω–æ.")
        return



    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã
    for i, file_info in enumerate(new_files, 1):
        input_path = file_info['path']
        file_name = file_info['file_name']

        # –§–æ—Ä–º–∏—Ä—É–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π –ø—É—Ç—å, —Å–æ—Ö—Ä–∞–Ω—è—è —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–æ—Å–ª–µ –ø—Ä–µ—Ñ–∏–∫—Å–∞
        # –ü—Ä–∏–º–µ—Ä: –≤—Ö–æ–¥–Ω–æ–π –ø—É—Ç—å s3a://bronze/nyc-taxi-data/yellow_tripdata_2022-01
        # –í—ã—Ö–æ–¥–Ω–æ–π –ø—É—Ç—å: s3a://silver/nyc-taxi-data/yellow_tripdata_2022-01
        output_path = f"s3a://{output_bucket}/{output_prefix}{file_name}".replace('.parquet', '')

        print(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –Ω–æ–≤—ã–π —Å—Ä–µ–∑ ({i}/{len(new_files)}): {file_info['month']}")

        try:
            eda_nyc_taxi_data(spark, input_path, output_path)
            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {file_info['month']}")
            print()
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_info['month']}: {e}")

    print(f"üéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(new_files)} –Ω–æ–≤—ã—Ö —Å—Ä–µ–∑–æ–≤.")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è Spark –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""

    print("\n\n")
    start_time = time.time()

    spark = SparkSession.builder \
        .appName("nyc-taxi-eda-ready") \
        .getOrCreate()

    execution_time = time.time() - start_time
    print(f"‚è±Ô∏è  Spark —Å–µ—Å—Å–∏—è —Å—Ç–∞—Ä—Ç–æ–≤–∞–ª–∞ –∑–∞: {execution_time:.2f} —Å–µ–∫—É–Ω–¥ ({execution_time / 60:.2f} –º–∏–Ω—É—Ç)")

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è Spark
    spark.sparkContext.setLogLevel("WARN")  # –∏–ª–∏ "ERROR"

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è Py4J (–±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è —Å–≤—è–∑–∏ Python-Java)
    logger = spark.sparkContext._jvm.org.apache.log4j
    logger.LogManager.getLogger("org").setLevel(logger.Level.WARN)
    logger.LogManager.getLogger("akka").setLevel(logger.Level.WARN)
    logger.LogManager.getLogger("io").setLevel(logger.Level.WARN)

    start_time = time.time()

    print()
    try:
        eda_incremental_nyc_taxi_files(
            spark=spark,
            input_bucket='silver',
            input_prefix='nyc-taxi-data-norm/',
            output_bucket='silver',
            output_prefix='nyc-taxi-data-eda/'
        )

        execution_time = time.time() - start_time

        print()
        print("üéä –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–∏–ª–æ —Ä–∞–±–æ—Ç—É!")
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è ETL –ø—Ä–æ—Ü–µ—Å—Å–∞: {execution_time:.2f} —Å–µ–∫—É–Ω–¥ ({execution_time / 60:.2f} –º–∏–Ω—É—Ç)")

        print("\n\n")
    except Exception as e:
        print(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏: {e}")
        print("\n\n\n")
        raise


if __name__ == "__main__":
    main()