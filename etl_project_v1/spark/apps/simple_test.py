from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType, IntegerType


def main():
    print("üöÄ Starting test Spark application...")

    # –ü—Ä–æ—Å—Ç–∞—è —Å–µ—Å—Å–∏—è –±–µ–∑ –ª–∏—à–Ω–∏—Ö –∫–æ–Ω—Ñ–∏–≥–æ–≤
    spark = SparkSession.builder \
        .appName("airflow-test-app") \
        .getOrCreate()

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º
    schema = StructType([
        StructField("id", IntegerType(), True),
        StructField("name", StringType(), True),
        StructField("value", IntegerType(), True)
    ])

    data = [
        (1, "Alice", 100),
        (2, "Bob", 200),
        (3, "Charlie", 300),
        (4, "David", 400),
        (5, "Eve", 500)
    ]

    df = spark.createDataFrame(data, schema=schema)

    print("‚úÖ Spark session created successfully!")
    print("üìä Test DataFrame:")
    df.show()

    # –ü—Ä–æ—Å—Ç–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    result = df.groupBy().sum("value").collect()
    total_value = result[0][0]
    print(f"üí∞ Total value: {total_value}")

    print("‚úÖ Spark application completed successfully!")


if __name__ == "__main__":
    main()